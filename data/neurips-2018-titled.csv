conference,year,index,paper_id,given_name,family_name,org,institution,email,title
neurips,2018,0,610,Hexiang,Hu,usc,University of Southern California,hexiangh@usc.edu,Synthesized Policies for Transfer and Adaptation across Tasks and Environments
neurips,2018,1,610,Liyu,Chen,usc,University of Southern California,liyuc@usc.edu,Synthesized Policies for Transfer and Adaptation across Tasks and Environments
neurips,2018,2,610,Boqing,Gong,outlook,Tencent AI Lab,boqinggo@outlook.com,Synthesized Policies for Transfer and Adaptation across Tasks and Environments
neurips,2018,3,610,Fei,Sha,netflix,University of Southern California (USC),fsha@netflix.com,Synthesized Policies for Transfer and Adaptation across Tasks and Environments
neurips,2018,0,236,Pedro,Morgado,,"University of California, San Diego",,Self-Supervised Generation of Spatial Audio for 360° Video
neurips,2018,1,236,Nuno,Nvasconcelos,,UC San Diego,,Self-Supervised Generation of Spatial Audio for 360° Video
neurips,2018,2,236,Timothy,Langlois,,Adobe Systems Inc,,Self-Supervised Generation of Spatial Audio for 360° Video
neurips,2018,3,236,Oliver,Wang,,Adobe Research,,Self-Supervised Generation of Spatial Audio for 360° Video
neurips,2018,0,2822,Eitan,Richardson,huji,The Hebrew University of Jerusalem,eitanrich@cs.huji.ac.il,On GANs and GMMs
neurips,2018,1,2822,Yair,Weiss,huji,Hebrew University,yweiss@cs.huji.ac.il,On GANs and GMMs
neurips,2018,0,1283,Hyeonseob,Nam,lunit,Lunit Inc.,hsnam@lunit.io,Batch-Instance Normalization for Adaptively Style-Invariant Neural Networks
neurips,2018,1,1283,Hyo-Eun,Kim,lunit,Lunit Inc,hekim@lunit.io,Batch-Instance Normalization for Adaptively Style-Invariant Neural Networks
neurips,2018,0,3550,Sungryull,Sohn,umich,University of Michigan,srsohn@umich.edu,Hierarchical Reinforcement Learning for Zero-shot Generalization with Subtask Dependencies
neurips,2018,1,3550,Junhyuk,Oh,google,DeepMind,junhyuk@google.com,Hierarchical Reinforcement Learning for Zero-shot Generalization with Subtask Dependencies
neurips,2018,2,3550,Honglak,Lee,google,Google / U. Michigan,honglak@google.com,Hierarchical Reinforcement Learning for Zero-shot Generalization with Subtask Dependencies
neurips,2018,0,433,Xiaojie,Wang,gmail,The University of Melbourne,xiaojiew94@gmail.com,KDGAN: Knowledge Distillation with Generative Adversarial Networks
neurips,2018,1,433,Rui,Zhang,twitter,""" University of Melbourne, Australia""",ysun@twitter.com,KDGAN: Knowledge Distillation with Generative Adversarial Networks
neurips,2018,2,433,Yu,Sun,unimelb,Twitter Inc.,rui.zhang@unimelb.edu.au,KDGAN: Knowledge Distillation with Generative Adversarial Networks
neurips,2018,3,433,Jianzhong,Qi,unimelb,The University of Melbourne,jianzhong.qi@unimelb.edu.au,KDGAN: Knowledge Distillation with Generative Adversarial Networks
neurips,2018,0,2491,Alexandre,Marques,mit,Massachusetts Institute of Technology,noll@mit.edu,Contour location via entropy reduction leveraging multiple information sources
neurips,2018,1,2491,Remi,Lam,mit,MIT,rlam@mit.edu,Contour location via entropy reduction leveraging multiple information sources
neurips,2018,2,2491,Karen,Willcox,utexas,MIT,kwillcox@ices.utexas.edu,Contour location via entropy reduction leveraging multiple information sources
neurips,2018,0,1329,Dylan,Foster,cornell,Cornell University,djfoster@cs.cornell.edu,Contextual bandits with surrogate losses: Margin bounds and efficient algorithms
neurips,2018,1,1329,Akshay,Krishnamurthy,umass,Microsoft,akshay@cs.umass.edu,Contextual bandits with surrogate losses: Margin bounds and efficient algorithms
neurips,2018,0,2226,Wenbing,Huang,126,Tencent AI Lab,hwenbing@126.com,Adaptive Sampling Towards Fast Graph Representation Learning
neurips,2018,1,2226,Tong,Zhang,anu,The Australian National University,tong.zhang@anu.edu.au,Adaptive Sampling Towards Fast Graph Representation Learning
neurips,2018,2,2226,Yu,Rong,hotmail,Tencent AI Lab,yu.rong@hotmail.com,Adaptive Sampling Towards Fast Graph Representation Learning
neurips,2018,3,2226,Junzhou,Huang,tencent,University of Texas at Arlington / Tencent AI Lab,joehhuang@tencent.com,Adaptive Sampling Towards Fast Graph Representation Learning
neurips,2018,0,1467,Tom,Michoel,uib,University of Bergen,tom.michoel@uib.no,Analytic solution and stationary phase approximation for the Bayesian lasso and elastic net
neurips,2018,0,5729,Eli,Sherman,jhu,Johns Hopkins University,esherman@jhu.edu,Identification and Estimation of Causal Effects from Dependent Data
neurips,2018,1,5729,Ilya,Shpitser,jhu,Johns Hopkins University,ilyas@cs.jhu.edu,Identification and Estimation of Causal Effects from Dependent Data
neurips,2018,0,6749,Aditya,Grover,stanford,Stanford University,adityag@cs.stanford.edu,Streamlining Variational Inference for Constraint Satisfaction Problems
neurips,2018,1,6749,Tudor,Achim,stanford,Helm.ai,tachim@cs.stanford.edu,Streamlining Variational Inference for Constraint Satisfaction Problems
neurips,2018,2,6749,Stefano,Ermon,stanford,Stanford,ermon@cs.stanford.edu,Streamlining Variational Inference for Constraint Satisfaction Problems
neurips,2018,0,6514,Shivam,Garg,stanford,Stanford University,shivamgarg@stanford.edu,A Spectral View of Adversarially Robust Features
neurips,2018,1,6514,Vatsal,Sharan,stanford,Stanford University,vsharan@stanford.edu,A Spectral View of Adversarially Robust Features
neurips,2018,2,6514,Brian,Zhang,stanford,Stanford University,bhz@stanford.edu,A Spectral View of Adversarially Robust Features
neurips,2018,3,6514,Gregory,Valiant,stanford,Stanford University,gvaliant@stanford.edu,A Spectral View of Adversarially Robust Features
neurips,2018,0,5123,Kry,Lui,borealisai,BorealisAI,yikchau.y.lui@borealisai.com,Dimensionality Reduction has Quantifiable Imperfections: Two Geometric Bounds
neurips,2018,1,5123,Gavin Weiguang,Ding,borealisai,Borealis AI,gavin.ding@borealisai.com,Dimensionality Reduction has Quantifiable Imperfections: Two Geometric Bounds
neurips,2018,2,5123,Ruitong,Huang,borealisai,Borealis AI,ruitong.huang@borealisai.com,Dimensionality Reduction has Quantifiable Imperfections: Two Geometric Bounds
neurips,2018,3,5123,Robert,McCann,toronto,University of Toronto,mccann@math.toronto.edu,Dimensionality Reduction has Quantifiable Imperfections: Two Geometric Bounds
neurips,2018,0,5484,Vikas,Garg,mit,MIT,vgarg@csail.mit.edu,Learning SMaLL Predictors
neurips,2018,1,5484,Ofer,Dekel,microsoft,Microsoft Research,oferd@microsoft.com,Learning SMaLL Predictors
neurips,2018,2,5484,Lin,Xiao,microsoft,Microsoft Research,lin.xiao@microsoft.com,Learning SMaLL Predictors
neurips,2018,0,3035,Hongzhou,Lin,mit,MIT,hongzhou@mit.edu,ResNet with one-neuron hidden layers is a Universal Approximator
neurips,2018,1,3035,Stefanie,Jegelka,mit,MIT,stefje@mit.edu,ResNet with one-neuron hidden layers is a Universal Approximator
neurips,2018,0,252,Simon,Du,,Carnegie Mellon University,,How Many Samples are Needed to Estimate a Convolutional Neural Network?
neurips,2018,1,252,Yining,Wang,,CMU,,How Many Samples are Needed to Estimate a Convolutional Neural Network?
neurips,2018,2,252,Xiyu,Zhai,,MIT,,How Many Samples are Needed to Estimate a Convolutional Neural Network?
neurips,2018,3,252,Sivaraman,Balakrishnan,,Carnegie Mellon University,,How Many Samples are Needed to Estimate a Convolutional Neural Network?
neurips,2018,4,252,Russ,Salakhutdinov,,Carnegie Mellon University,,How Many Samples are Needed to Estimate a Convolutional Neural Network?
neurips,2018,5,252,Aarti,Singh,,CMU,,How Many Samples are Needed to Estimate a Convolutional Neural Network?
neurips,2018,0,2400,Yu,Terada,riken,RIKEN,yu.terada@riken.jp,Objective and efficient inference for couplings in neuronal networks
neurips,2018,1,2400,Tomoyuki,Obuchi,titech,Tokyo Institute of Technology,obuchi@c.titech.ac.jp,Objective and efficient inference for couplings in neuronal networks
neurips,2018,2,2400,Takuya,Isomura,riken,RIKEN Brain Science Institute,takuya.isomura@riken.jp,Objective and efficient inference for couplings in neuronal networks
neurips,2018,3,2400,Yoshiyuki,Kabashima,titech,Tokyo Institute of Technology,kaba@c.titech.ac.jp,Objective and efficient inference for couplings in neuronal networks
neurips,2018,0,2454,Ayush,Jaiswal,isi,USC Information Sciences Institute,ajaiswal@isi.edu,Unsupervised Adversarial Invariance
neurips,2018,1,2454,Rex Yue,Wu,isi,USC ISI,yue_wu@isi.edu,Unsupervised Adversarial Invariance
neurips,2018,2,2454,Wael,Abd-Almageed,isi,Information Sciences Institute,wamageed@isi.edu,Unsupervised Adversarial Invariance
neurips,2018,3,2454,Prem,Natarajan,isi,USC ISI,pnataraj@isi.edu,Unsupervised Adversarial Invariance
neurips,2018,0,2766,Arnu,Pretorius,,Stellenbosch University,,Critical initialisation for deep signal propagation in noisy rectifier neural networks
neurips,2018,1,2766,Elan,van Biljon,,Stellenbosch University,,Critical initialisation for deep signal propagation in noisy rectifier neural networks
neurips,2018,2,2766,Steve,Kroon,,Stellenbosch University,,Critical initialisation for deep signal propagation in noisy rectifier neural networks
neurips,2018,3,2766,Herman,Kamper,,Stellenbosch University,,Critical initialisation for deep signal propagation in noisy rectifier neural networks
neurips,2018,0,1911,Enzo,Tartaglione,,Politecnico di Torino,,Learning sparse neural networks via sensitivity-driven regularization
neurips,2018,1,1911,Skjalg,Lepsøy,,Telecom Italia,,Learning sparse neural networks via sensitivity-driven regularization
neurips,2018,2,1911,Attilio,Fiandrotti,,POLITO,,Learning sparse neural networks via sensitivity-driven regularization
neurips,2018,3,1911,Gianluca,Francini,,Telecom Italia,,Learning sparse neural networks via sensitivity-driven regularization
neurips,2018,0,2048,Harsh,Shrivastava,gatech,Georgia Institute of Technology,hshrivastava3@gatech.edu,Cooperative neural networks (CoNN): Exploiting prior independence structure for improved classification
neurips,2018,1,2048,Eugene,Bart,parc,Palo Alto Research Center,bart@parc.com,Cooperative neural networks (CoNN): Exploiting prior independence structure for improved classification
neurips,2018,2,2048,Bob,Price,parc,PARC,bprice@parc.com,Cooperative neural networks (CoNN): Exploiting prior independence structure for improved classification
neurips,2018,3,2048,Hanjun,Dai,gatech,Georgia Tech,hanjundai@gatech.edu,Cooperative neural networks (CoNN): Exploiting prior independence structure for improved classification
neurips,2018,4,2048,Bo,Dai,gatech,Google Brain,bodai@gatech.edu,Cooperative neural networks (CoNN): Exploiting prior independence structure for improved classification
neurips,2018,5,2048,Srinivas,Aluru,gatech,Georgia Institute of Technology,aluru@cc.gatech.edu,Cooperative neural networks (CoNN): Exploiting prior independence structure for improved classification
neurips,2018,0,1895,Nevena,Lazic,google,Google,nevena@google.com,Data center cooling using model-predictive control
neurips,2018,1,1895,Craig,Boutilier,google,Google,tylerlu@google.com,Data center cooling using model-predictive control
neurips,2018,2,1895,Tyler,Lu,google,Google,cboutilier@google.com,Data center cooling using model-predictive control
neurips,2018,3,1895,Eehern,Wong,google,Google,mkryu@google.com,Data center cooling using model-predictive control
neurips,2018,4,1895,Binz,Roy,google,Google,ejwong@google.com,Data center cooling using model-predictive control
neurips,2018,5,1895,MK,Ryu,google,Google,binzroy@google.com,Data center cooling using model-predictive control
neurips,2018,6,1895,Greg,Imwalle,google,Google,gregi@google.com,Data center cooling using model-predictive control
neurips,2018,0,6396,Vitaly,Feldman,,Google Brain,,Generalization Bounds for Uniformly Stable Algorithms
neurips,2018,1,6396,Jan,Vondrak,,Stanford University,,Generalization Bounds for Uniformly Stable Algorithms
neurips,2018,0,2212,Lie,He,,EPFL,,COLA: Decentralized Linear Learning
neurips,2018,1,2212,An,Bian,,ETH Zürich,,COLA: Decentralized Linear Learning
neurips,2018,2,2212,Martin,Jaggi,,EPFL,,COLA: Decentralized Linear Learning
neurips,2018,0,1909,Pierre-Alexandre,Mattei,itu,ITU Copenhagen,pima@itu.dk,Leveraging the Exact Likelihood of Deep Latent Variable Models
neurips,2018,1,1909,Jes,Frellsen,itu,IT University of Copenhagen,jefr@itu.dk,Leveraging the Exact Likelihood of Deep Latent Variable Models
neurips,2018,0,4890,Joseph,Marino,caltech,California Institute of Technology,jmarino@caltech.edu,A General Method for Amortizing Variational Filtering
neurips,2018,1,4890,Milan,Cvitkovic,caltech,California Institute of Technology,mcvitkovic@caltech.edu,A General Method for Amortizing Variational Filtering
neurips,2018,2,4890,Yisong,Yue,caltech,Caltech,yyue@caltech.edu,A General Method for Amortizing Variational Filtering
neurips,2018,0,1077,Sagie,Benaim,,Tel Aviv University,,One-Shot Unsupervised Cross Domain Translation
neurips,2018,1,1077,Lior,Wolf,,Facebook AI Research,,One-Shot Unsupervised Cross Domain Translation
neurips,2018,0,3346,I,Chien,illinois,UIUC,ichien3@illinois.edu,Query K-means Clustering and the Double Dixie Cup Problem
neurips,2018,1,3346,Chao,Pan,illinois,University of Illinois Urbana-Champaign,chaopan2@illinois.edu,Query K-means Clustering and the Double Dixie Cup Problem
neurips,2018,2,3346,Olgica,Milenkovic,illinois,University of Illinois at Urbana-Champaign,milenkov@illinois.edu,Query K-means Clustering and the Double Dixie Cup Problem
neurips,2018,0,1997,Zhiwei,Deng,sfu,Simon Fraser University,zhiweid@sfu.ca,Probabilistic Neural Programmed Networks for Scene Generation
neurips,2018,1,1997,Jiacheng,Chen,sfu,Simon Fraser University,jca348@sfu.ca,Probabilistic Neural Programmed Networks for Scene Generation
neurips,2018,2,1997,YIFANG,FU,sfu,Simon Fraser University,yifangf@sfu.ca,Probabilistic Neural Programmed Networks for Scene Generation
neurips,2018,3,1997,Greg,Mori,sfu,Borealis AI,mori@cs.sfu.ca,Probabilistic Neural Programmed Networks for Scene Generation
neurips,2018,0,1830,Aryan,Mokhtari,,MIT,,Escaping Saddle Points in Constrained Optimization
neurips,2018,1,1830,Asuman,Ozdaglar,,Massachusetts Institute of Technology,,Escaping Saddle Points in Constrained Optimization
neurips,2018,2,1830,Ali,Jadbabaie,,MIT,,Escaping Saddle Points in Constrained Optimization
neurips,2018,0,2273,Liqun,Chen,,Duke University,,Adversarial Text Generation via Feature-Mover's Distance
neurips,2018,1,2273,Shuyang,Dai,,Duke University,,Adversarial Text Generation via Feature-Mover's Distance
neurips,2018,2,2273,Chenyang,Tao,,Duke University,,Adversarial Text Generation via Feature-Mover's Distance
neurips,2018,3,2273,Haichao,Zhang,,Baidu Research,,Adversarial Text Generation via Feature-Mover's Distance
neurips,2018,4,2273,Zhe,Gan,,Microsoft,,Adversarial Text Generation via Feature-Mover's Distance
neurips,2018,5,2273,Dinghan,Shen,,Duke University,,Adversarial Text Generation via Feature-Mover's Distance
neurips,2018,6,2273,Yizhe,Zhang,,Microsoft Research,,Adversarial Text Generation via Feature-Mover's Distance
neurips,2018,7,2273,Guoyin,Wang,,Duke University,,Adversarial Text Generation via Feature-Mover's Distance
neurips,2018,8,2273,Ruiyi,Zhang,,Duke University,,Adversarial Text Generation via Feature-Mover's Distance
neurips,2018,9,2273,Lawrence,Carin,,Duke University,,Adversarial Text Generation via Feature-Mover's Distance
neurips,2018,0,3366,Michael,Arbel,gmail,UCL,dougal@gmail.com,On gradient regularizers for MMD GANs
neurips,2018,1,3366,Dougal,Sutherland,gmail,"Gatsby Unit, UCL",michael.n.arbel@gmail.com,On gradient regularizers for MMD GANs
neurips,2018,2,3366,Mikoaj,Bikowski,gmail,Imperial College London,mikbinkowski@gmail.com,On gradient regularizers for MMD GANs
neurips,2018,3,3366,Arthur,Gretton,gmail,"Gatsby Unit, UCL",arthur.gretton@gmail.com,On gradient regularizers for MMD GANs
neurips,2018,0,1532,Garrett,Bernstein,umass,University of Massachusetts Amherst,gbernstein@cs.umass.edu,Differentially Private Bayesian Inference for Exponential Families
neurips,2018,1,1532,Daniel,Sheldon,umass,University of Massachusetts Amherst,sheldon@cs.umass.edu,Differentially Private Bayesian Inference for Exponential Families
neurips,2018,0,5067,Conghui,Tan,cuhk,The Chinese University of Hong Kong,chtan@se.cuhk.edu.hk,Stochastic Primal-Dual Method for Empirical Risk Minimization with O(1) Per-Iteration Complexity
neurips,2018,1,5067,Tong,Zhang,tongzhang-ml,Tencent AI Lab,tongzhang@tongzhang-ml.org,Stochastic Primal-Dual Method for Empirical Risk Minimization with O(1) Per-Iteration Complexity
neurips,2018,2,5067,Shiqian,Ma,ucdavis,,sqma@math.ucdavis.edu,Stochastic Primal-Dual Method for Empirical Risk Minimization with O(1) Per-Iteration Complexity
neurips,2018,3,5067,Ji,Liu,gmail,"University of Rochester, Tencent AI lab",ji.liu.uwisc@gmail.com,Stochastic Primal-Dual Method for Empirical Risk Minimization with O(1) Per-Iteration Complexity
neurips,2018,0,1289,Sang-Woo,Lee,,Naver Corp.,,Answerer in Questioner's Mind: Information Theoretic Approach to Goal-Oriented Visual Dialog
neurips,2018,1,1289,Yu-Jung,Heo,,Seoul National University,,Answerer in Questioner's Mind: Information Theoretic Approach to Goal-Oriented Visual Dialog
neurips,2018,2,1289,Byoung-Tak,Zhang,,Seoul National University & Surromind Robotics,,Answerer in Questioner's Mind: Information Theoretic Approach to Goal-Oriented Visual Dialog
neurips,2018,0,5271,Thanard,Kurutach,,University of California Berkeley,,Learning Plannable Representations with Causal InfoGAN
neurips,2018,1,5271,Aviv,Tamar,,UC Berkeley,,Learning Plannable Representations with Causal InfoGAN
neurips,2018,2,5271,Ge,Yang,,Berkeley,,Learning Plannable Representations with Causal InfoGAN
neurips,2018,3,5271,Stuart,Russell,,UC Berkeley,,Learning Plannable Representations with Causal InfoGAN
neurips,2018,4,5271,Pieter,Abbeel,,UC Berkeley | Gradescope | Covariant,,Learning Plannable Representations with Causal InfoGAN
neurips,2018,0,597,Christopher,Tosh,,Columbia University,,Interactive Structure Learning with Structural Query-by-Committee
neurips,2018,1,597,Sanjoy,Dasgupta,,UC San Diego,,Interactive Structure Learning with Structural Query-by-Committee
neurips,2018,0,2000,Volker,Fischer,bosch,"Robert Bosch GmbH, Bosch Center for Artificial Intelligence",volker.fischer@de.bosch.com,The streaming rollout of deep networks - towards fully model-parallel execution
neurips,2018,1,2000,Jan,Koehler,bosch,Robert Bosch GmbH,jan.koehler@de.bosch.com,The streaming rollout of deep networks - towards fully model-parallel execution
neurips,2018,2,2000,Thomas,Pfeil,bosch,Robert Bosch GmbH,thomas.pfeil@de.bosch.com,The streaming rollout of deep networks - towards fully model-parallel execution
neurips,2018,0,5172,Yash,Deshpande,,Massachusetts Institute of Technology,,Contextual Stochastic Block Models
neurips,2018,1,5172,Subhabrata,Sen,,Massachusetts Institute of Technology,,Contextual Stochastic Block Models
neurips,2018,2,5172,Andrea,Montanari,,Stanford,,Contextual Stochastic Block Models
neurips,2018,3,5172,Elchanan,Mossel,,MIT,,Contextual Stochastic Block Models
neurips,2018,0,3313,Daan,Wynen,,INRIA,,Unsupervised Learning of Artistic Styles with Archetypal Style Analysis
neurips,2018,1,3313,Cordelia,Schmid,,Inria / Google,,Unsupervised Learning of Artistic Styles with Archetypal Style Analysis
neurips,2018,2,3313,Julien,Mairal,,Inria,,Unsupervised Learning of Artistic Styles with Archetypal Style Analysis
neurips,2018,0,3743,Robert,Geirhos,,University of Tübingen,,Generalisation in humans and deep neural networks
neurips,2018,1,3743,Carlos R. M.,Temme,,University of Tübingen,,Generalisation in humans and deep neural networks
neurips,2018,2,3743,Jonas,Rauber,,University of Tübingen,,Generalisation in humans and deep neural networks
neurips,2018,3,3743,Heiko H.,Schütt,,University of Tübingen,,Generalisation in humans and deep neural networks
neurips,2018,4,3743,Matthias,Bethge,,University of Tübingen,,Generalisation in humans and deep neural networks
neurips,2018,5,3743,Felix A.,Wichmann,,University of Tübingen,,Generalisation in humans and deep neural networks
neurips,2018,0,2029,Patrick,McClure,nih,NIH,patrick.mcclure@nih.gov,Distributed Weight Consolidation: A Brain Segmentation Case Study
neurips,2018,1,2029,Charles,Zheng,nih,National Institute of Mental Health,charles.zheng@nih.gov,Distributed Weight Consolidation: A Brain Segmentation Case Study
neurips,2018,2,2029,Jakub,Kaczmarzyk,mit,MIT,jakubk@mit.edu,Distributed Weight Consolidation: A Brain Segmentation Case Study
neurips,2018,3,2029,John,Rogers-Lee,mit,NIMH,satra@mit.edu,Distributed Weight Consolidation: A Brain Segmentation Case Study
neurips,2018,4,2029,Satra,Ghosh,nih,MIT,bandettini@nih.gov,Distributed Weight Consolidation: A Brain Segmentation Case Study
neurips,2018,5,2029,Dylan,Nielson,nih,NIMH,john.rodgers-lee@nih.gov,Distributed Weight Consolidation: A Brain Segmentation Case Study
neurips,2018,6,2029,Peter,Bandettini,nih,National Institute of Mental Health,dylann.nielson@nih.gov,Distributed Weight Consolidation: A Brain Segmentation Case Study
neurips,2018,7,2029,Francisco,Pereira,nih,National Institute of Mental Health,francisco.pereira@nih.gov,Distributed Weight Consolidation: A Brain Segmentation Case Study
neurips,2018,0,59,Huaibo,Huang,ia,"Institute of Automation, Chinese Academy of Science",huaibo.huang@cripac.ia.ac.cn,IntroVAE: Introspective Variational Autoencoders for Photographic Image Synthesis
neurips,2018,1,59,zhihang,li,ia,"Institute of Automation, Chinese Academy of Science",zhihang.li@nlpr.ia.ac.cn,IntroVAE: Introspective Variational Autoencoders for Photographic Image Synthesis
neurips,2018,2,59,Ran,He,ia,"NLPR, CASIA",rhe@nlpr.ia.ac.cn,IntroVAE: Introspective Variational Autoencoders for Photographic Image Synthesis
neurips,2018,3,59,Zhenan,Sun,ia,"Institute of Automation, Chinese Academy of Sciences (CASIA)",znsun@nlpr.ia.ac.cn,IntroVAE: Introspective Variational Autoencoders for Photographic Image Synthesis
neurips,2018,4,59,Tieniu,Tan,ia,Chinese Academy of Sciences,tnt@nlpr.ia.ac.cn,IntroVAE: Introspective Variational Autoencoders for Photographic Image Synthesis
neurips,2018,0,6961,Ian En-Hsu,Yen,,Carnegie Mellon University,,MixLasso: Generalized Mixed Regression via Convex Atomic-Norm Regularization
neurips,2018,1,6961,Wei-Cheng,Lee,,National Taiwan University,,MixLasso: Generalized Mixed Regression via Convex Atomic-Norm Regularization
neurips,2018,2,6961,Kai,Zhong,,Amazon,,MixLasso: Generalized Mixed Regression via Convex Atomic-Norm Regularization
neurips,2018,3,6961,Sung-En,Chang,,Northeastern University,,MixLasso: Generalized Mixed Regression via Convex Atomic-Norm Regularization
neurips,2018,4,6961,Pradeep,Ravikumar,,Carnegie Mellon University,,MixLasso: Generalized Mixed Regression via Convex Atomic-Norm Regularization
neurips,2018,5,6961,Shou-De,Lin,,National Taiwan University,,MixLasso: Generalized Mixed Regression via Convex Atomic-Norm Regularization
neurips,2018,0,2639,Madhav,Nimishakavi,iisc,Indian Institute of Science,madhav@iisc.ac.in,A Dual Framework for Low-rank Tensor Completion
neurips,2018,1,2639,Pratik Kumar,Jawanpuria,microsoft,Microsoft,pratik.jawanpuria@microsoft.com,A Dual Framework for Low-rank Tensor Completion
neurips,2018,2,2639,Bamdev,Mishra,microsoft,Microsoft,bamdevm@microsoft.com,A Dual Framework for Low-rank Tensor Completion
neurips,2018,0,3023,David,Madras,toronto,University of Toronto,madras@cs.toronto.edu,Predict Responsibly: Improving Fairness and Accuracy by Learning to Defer
neurips,2018,1,3023,Toni,Pitassi,toronto,University of Toronto,toni@cs.toronto.edu,Predict Responsibly: Improving Fairness and Accuracy by Learning to Defer
neurips,2018,2,3023,Richard,Zemel,toronto,Vector Institute/University of Toronto,zemel@cs.toronto.edu,Predict Responsibly: Improving Fairness and Accuracy by Learning to Defer
neurips,2018,0,888,Isabel,Valera,,Max Planck Institute for Intelligent Systems,,Enhancing the Accuracy and Fairness of Human Decision Making
neurips,2018,1,888,Adish,Singla,,MPI-SWS,,Enhancing the Accuracy and Fairness of Human Decision Making
neurips,2018,2,888,Manuel,Gomez Rodriguez,,Max Planck Institute for Software Systems,,Enhancing the Accuracy and Fairness of Human Decision Making
neurips,2018,0,1455,Soeren,Laue,uni-jena,Universitaet Jena,soeren.laue@uni-jena.de,Computing Higher Order Derivatives of Matrix and Tensor Expressions
neurips,2018,1,1455,Matthias,Mitterreiter,uni-jena,Friedrich Schiller University Jena,matthias.mitterreiter@uni-jena.de,Computing Higher Order Derivatives of Matrix and Tensor Expressions
neurips,2018,2,1455,Joachim,Giesen,uni-jena,Friedrich-Schiller-Universitat Jena,joachim.giesen@uni-jena.de,Computing Higher Order Derivatives of Matrix and Tensor Expressions
neurips,2018,0,3496,Pierre,Gaillard,inria,"INRIA Paris, DI ENS",pierre.gaillard@inria.fr,Efficient online algorithms for fast-rate regret bounds under sparsity
neurips,2018,1,3496,Olivier,Wintenberger,upmc,,olivier.wintenberger@upmc.fr,Efficient online algorithms for fast-rate regret bounds under sparsity
neurips,2018,0,6531,Isaac,Lage,harvard,Harvard,isaaclage@g.harvard.edu,Human-in-the-Loop Interpretability Prior
neurips,2018,1,6531,Andrew,Ross,harvard,Harvard University,andrew_ross@g.harvard.edu,Human-in-the-Loop Interpretability Prior
neurips,2018,2,6531,Samuel,Gershman,google,Harvard University,beenkim@google.com,Human-in-the-Loop Interpretability Prior
neurips,2018,3,6531,Been,Kim,harvard,Google,gershman@fas.harvard.edu,Human-in-the-Loop Interpretability Prior
neurips,2018,4,6531,Finale,Doshi-Velez,harvard,Harvard,finale@seas.harvard.edu,Human-in-the-Loop Interpretability Prior
neurips,2018,0,191,Wenqi,Ren,,Chinese Academy of Sciences,,Deep Non-Blind Deconvolution via Generalized Low-Rank Approximation
neurips,2018,1,191,Jiawei,Zhang,,Sensetime Research,,Deep Non-Blind Deconvolution via Generalized Low-Rank Approximation
neurips,2018,2,191,Lin,Ma,,Tencent AI Lab,,Deep Non-Blind Deconvolution via Generalized Low-Rank Approximation
neurips,2018,3,191,Jinshan,Pan,,Nanjing University of Science and Technology,,Deep Non-Blind Deconvolution via Generalized Low-Rank Approximation
neurips,2018,4,191,Xiaochun,Cao,,Chinese Academy of Sciences,,Deep Non-Blind Deconvolution via Generalized Low-Rank Approximation
neurips,2018,5,191,Wangmeng,Zuo,,Harbin Institute of Technology,,Deep Non-Blind Deconvolution via Generalized Low-Rank Approximation
neurips,2018,6,191,Wei,Liu,,Tencent AI Lab,,Deep Non-Blind Deconvolution via Generalized Low-Rank Approximation
neurips,2018,7,191,Ming-Hsuan,Yang,,UC Merced / Google,,Deep Non-Blind Deconvolution via Generalized Low-Rank Approximation
neurips,2018,0,2065,Sarah,Dean,,,,Regret Bounds for Robust Adaptive Control of the Linear Quadratic Regulator
neurips,2018,1,2065,Horia,Mania,,UC Berkeley,,Regret Bounds for Robust Adaptive Control of the Linear Quadratic Regulator
neurips,2018,2,2065,Nikolai,Matni,,UC Berkeley,,Regret Bounds for Robust Adaptive Control of the Linear Quadratic Regulator
neurips,2018,3,2065,Benjamin,Recht,,UC Berkeley,,Regret Bounds for Robust Adaptive Control of the Linear Quadratic Regulator
neurips,2018,4,2065,Stephen,Tu,,UC Berkeley,,Regret Bounds for Robust Adaptive Control of the Linear Quadratic Regulator
neurips,2018,0,2091,Kwangjun,Ahn,kaist,Korean Augmentation To the United States Army (KATUSA),kjahnkorea@kaist.ac.kr,Binary Rating Estimation with Graph Side Information
neurips,2018,1,2091,Kangwook,Lee,kaist,KAIST,kw1jjang@kaist.ac.kr,Binary Rating Estimation with Graph Side Information
neurips,2018,2,2091,Hyunseung,Cha,kakaobrain,Kakao Brain,tony.cha@kakaobrain.com,Binary Rating Estimation with Graph Side Information
neurips,2018,3,2091,Changho,Suh,kaist,KAIST,chsuh@kaist.ac.kr,Binary Rating Estimation with Graph Side Information
neurips,2018,0,5284,Diana,Cai,princeton,Princeton University,dcai@cs.princeton.edu,A Bayesian Nonparametric View on Count-Min Sketch
neurips,2018,1,5284,Michael,Mitzenmacher,harvard,Harvard University,michaelm@eecs.harvard.edu,A Bayesian Nonparametric View on Count-Min Sketch
neurips,2018,2,5284,Ryan,Adams,princeton,Google Brain and Princeton University,rpa@princeton.edu,A Bayesian Nonparametric View on Count-Min Sketch
neurips,2018,0,1388,Josip,Djolonga,ethz,Google Brain,josipd@inf.ethz.ch,Provable Variational Inference for Constrained Log-Submodular Models
neurips,2018,1,1388,Stefanie,Jegelka,mit,MIT,stefje@csail.mit.edu,Provable Variational Inference for Constrained Log-Submodular Models
neurips,2018,2,1388,Andreas,Krause,ethz,ETH Zurich,krausea@ethz.ch,Provable Variational Inference for Constrained Log-Submodular Models
neurips,2018,0,2652,Shikib,Mehri,cmu,Carnegie Mellon University,amehri@cs.cmu.edu,Middle-Out Decoding
neurips,2018,1,2652,Leonid,Sigal,ubc,University of British Columbia,lsigal@cs.ubc.ca,Middle-Out Decoding
neurips,2018,0,369,Abhimanyu,Dubey,mit,MIT,dubeya@mit.edu,Maximum-Entropy Fine Grained Classification
neurips,2018,1,369,Otkrist,Gupta,mit,MIT,otkrist@mit.edu,Maximum-Entropy Fine Grained Classification
neurips,2018,2,369,Ramesh,Raskar,mit,MIT,raskar@mit.edu,Maximum-Entropy Fine Grained Classification
neurips,2018,3,369,Nikhil,Naik,mit,Massachusetts Institute of Technology,naik@mit.edu,Maximum-Entropy Fine Grained Classification
neurips,2018,0,3031,Florian,Schmidt,ethz,ETH Zürich,florian.schmidt@inf.ethz.ch,Deep State Space Models for Unconditional Word Generation
neurips,2018,1,3031,Thomas,Hofmann,ethz,ETH Zurich,thomas.hofmann@inf.ethz.ch,Deep State Space Models for Unconditional Word Generation
neurips,2018,0,6556,Paavo,Parmas,oist,Okinawa Institute of Science and Technology Graduate University,paavo.parmas@oist.jp,Total stochastic gradient algorithms and applications in reinforcement learning
neurips,2018,0,4959,Andrew,Trask,google,DeepMind,atrask@google.com,Neural Arithmetic Logic Units
neurips,2018,1,4959,Felix,Hill,google,Deepmind,felixhill@google.com,Neural Arithmetic Logic Units
neurips,2018,2,4959,Scott,Reed,google,Google DeepMind,reedscot@google.com,Neural Arithmetic Logic Units
neurips,2018,3,4959,Jack,Rae,google,"DeepMind, UCL",jwrae@google.com,Neural Arithmetic Logic Units
neurips,2018,4,4959,Chris,Dyer,google,DeepMind,cdyer@google.com,Neural Arithmetic Logic Units
neurips,2018,5,4959,Phil,Blunsom,google,DeepMind and Oxford University,pblunsom@google.com,Neural Arithmetic Logic Units
neurips,2018,0,5749,Suriya,Gunasekar,ttic,TTI Chicago,suriya@ttic.edu,Implicit Bias of Gradient Descent on Linear Convolutional Networks
neurips,2018,1,5749,Jason,Lee,usc,University of Southern California,jasonlee@marshall.usc.edu,Implicit Bias of Gradient Descent on Linear Convolutional Networks
neurips,2018,2,5749,Daniel,Soudry,gmail,Technion,daniel.soudry@gmail.com,Implicit Bias of Gradient Descent on Linear Convolutional Networks
neurips,2018,3,5749,Nati,Srebro,ttic,TTI-Chicago,nati@ttic.edu,Implicit Bias of Gradient Descent on Linear Convolutional Networks
neurips,2018,0,1594,Hamid,JALALZAI,,Télécom ParisTech,,On Binary Classification in Extreme Regions
neurips,2018,1,1594,Stephan,Clémençon,,Telecom ParisTech,,On Binary Classification in Extreme Regions
neurips,2018,2,1594,Anne,Sabourin,,"LTCI,  Telecom ParisTech, Université Paris-Saclay",,On Binary Classification in Extreme Regions
neurips,2018,0,6418,Alexander,Neitz,,Max Planck Institute for Intelligent Systems,,Adaptive Skip Intervals: Temporal Abstraction for Recurrent Dynamical Models
neurips,2018,1,6418,Giambattista,Parascandolo,,Max Planck Insitute for Intelligent Systems & ETH,,Adaptive Skip Intervals: Temporal Abstraction for Recurrent Dynamical Models
neurips,2018,2,6418,Stefan,Bauer,,MPI for Intelligent Systems,,Adaptive Skip Intervals: Temporal Abstraction for Recurrent Dynamical Models
neurips,2018,3,6418,Bernhard,Schölkopf,,MPI for Intelligent Systems,,Adaptive Skip Intervals: Temporal Abstraction for Recurrent Dynamical Models
neurips,2018,0,4975,Jonghwan,Mun,postech,POSTECH,1choco1916@postech.ac.kr,Learning to Specialize with Knowledge Distillation for Visual Question Answering
neurips,2018,1,4975,Kimin,Lee,kaist,Korea Advanced Institute of Science and Technology,2kiminlee@kaist.ac.kr,Learning to Specialize with Knowledge Distillation for Visual Question Answering
neurips,2018,2,4975,Jinwoo,Shin,kaist,KAIST; AITRICS,jinwoos@kaist.ac.kr,Learning to Specialize with Knowledge Distillation for Visual Question Answering
neurips,2018,3,4975,Bohyung,Han,snu,Seoul National University,3bhhan@snu.ac.kr,Learning to Specialize with Knowledge Distillation for Visual Question Answering
neurips,2018,0,283,Michael,Mitzenmacher,harvard,Harvard University,michaelm@eecs.harvard.edu,A Model for Learned Bloom Filters and Optimizing by Sandwiching
neurips,2018,0,959,Jonathan,Huggins,mit,Massachusetts Institute of Technology,jhuggins@mit.edu,Random Feature Stein Discrepancies
neurips,2018,1,959,Lester,Mackey,microsoft,Microsoft Research,lmackey@microsoft.com,Random Feature Stein Discrepancies
neurips,2018,0,2433,Quan,Zhang,utexas,"McCombs School of Business, University of Texas at Austin",quan.zhang@mccombs.utexas.edu,Nonparametric Bayesian Lomax delegate racing for survival analysis with competing risks
neurips,2018,1,2433,Mingyuan,Zhou,utexas,University of Texas at Austin,mingyuan.zhou@mccombs.utexas.edu,Nonparametric Bayesian Lomax delegate racing for survival analysis with competing risks
neurips,2018,0,2391,Zhewei,Yao,,UC Berkeley,,Hessian-based Analysis of Large Batch Training and Robustness to Adversaries
neurips,2018,1,2391,Amir,Gholami,,"University of California, Berkeley",,Hessian-based Analysis of Large Batch Training and Robustness to Adversaries
neurips,2018,2,2391,Qi,Lei,,University of Texas at Austin,,Hessian-based Analysis of Large Batch Training and Robustness to Adversaries
neurips,2018,3,2391,Kurt,Keutzer,,"EECS, UC Berkeley",,Hessian-based Analysis of Large Batch Training and Robustness to Adversaries
neurips,2018,4,2391,Michael,Mahoney,,UC Berkeley,,Hessian-based Analysis of Large Batch Training and Robustness to Adversaries
neurips,2018,0,691,Lijun,Zhang,nju,Nanjing University (NJU),zhanglj@lamda.nju.edu.cn,Adaptive Online Learning in Dynamic Environments
neurips,2018,1,691,Shiyin,Lu,nju,Nanjing University,lusy@lamda.nju.edu.cn,Adaptive Online Learning in Dynamic Environments
neurips,2018,2,691,Zhi-Hua,Zhou,nju,Nanjing University,zhouzh@lamda.nju.edu.cn,Adaptive Online Learning in Dynamic Environments
neurips,2018,0,2462,Zhengyuan,Zhou,stanford,Stanford University,zyzhou@stanford.edu,Learning in Games with Lossy Feedback
neurips,2018,1,2462,Panayotis,Mertikopoulos,imag,CNRS (French National Center for Scientific Research),panayotis.mertikopoulos@imag.fr,Learning in Games with Lossy Feedback
neurips,2018,2,2462,Susan,Athey,stanford,Stanford University,athey@stanford.edu,Learning in Games with Lossy Feedback
neurips,2018,3,2462,Nicholas,Bambos,stanford,,bambos@stanford.edu,Learning in Games with Lossy Feedback
neurips,2018,4,2462,Peter,Glynn,stanford,Stanford University,glynn@stanford.edu,Learning in Games with Lossy Feedback
neurips,2018,5,2462,Yinyu,Ye,stanford,,yinyu-ye@stanford.edu,Learning in Games with Lossy Feedback
neurips,2018,0,4978,Loucas,Pillaud-Vivien,inria,INRIA - Ecole Normale Supérieure,loucas.pillaud-vivien@inria.fr,Statistical Optimality of Stochastic Gradient Descent on Hard Learning Problems through Multiple Passes
neurips,2018,1,4978,Alessandro,Rudi,inria,"INRIA, Ecole Normale Superieure",alessandro.rudi@inria.fr,Statistical Optimality of Stochastic Gradient Descent on Hard Learning Problems through Multiple Passes
neurips,2018,2,4978,Francis,Bach,inria,INRIA - Ecole Normale Superieure,francis.bach@inria.fr,Statistical Optimality of Stochastic Gradient Descent on Hard Learning Problems through Multiple Passes
neurips,2018,0,2666,Mike,Wu,stanford,Stanford University,wumike@stanford.edu,Multimodal Generative Models for Scalable Weakly-Supervised Learning
neurips,2018,1,2666,Noah,Goodman,stanford,Stanford University,ngoodman@stanford.edu,Multimodal Generative Models for Scalable Weakly-Supervised Learning
neurips,2018,0,802,Jian,Li,,"Institute of Information Engineering, CAS",,Multi-Class Learning: From Theory to Algorithm
neurips,2018,1,802,Yong,Liu,,"Institute of Information Engineering, CAS",,Multi-Class Learning: From Theory to Algorithm
neurips,2018,2,802,Rong,Yin,,"School of Cyber Security, University of Chinese Academy of Sciences",,Multi-Class Learning: From Theory to Algorithm
neurips,2018,3,802,Hua,Zhang,,"Institute of Information Engineering,Chinese Academy of Sciences",,Multi-Class Learning: From Theory to Algorithm
neurips,2018,4,802,Lizhong,Ding,,KAUST,,Multi-Class Learning: From Theory to Algorithm
neurips,2018,5,802,Weiping,Wang,,"Institute of Information Engineering, CAS, China",,Multi-Class Learning: From Theory to Algorithm
neurips,2018,0,6611,Siddarth,Srinivasan,gatech,Georgia Institute of Technology,sidsrini@gatech.edu,Learning and Inference in Hilbert Space with Quantum Graphical Models
neurips,2018,1,6611,Carlton,Downey,cmu,Carnegie Mellon University,cmdowney@cs.cmu.edu,Learning and Inference in Hilbert Space with Quantum Graphical Models
neurips,2018,2,6611,Byron,Boots,gatech,Georgia Tech / Google Brain,bboots@cc.gatech.edu,Learning and Inference in Hilbert Space with Quantum Graphical Models
neurips,2018,0,6730,Raanan,Rohekar,intel,Intel Corporation,raanan.yehezkel@intel.com,Bayesian Structure Learning by Recursive Bootstrap
neurips,2018,1,6730,Yaniv,Gurwicz,intel,Intel AI Lab,yaniv.gurwicz@intel.com,Bayesian Structure Learning by Recursive Bootstrap
neurips,2018,2,6730,Shami,Nisimov,intel,intel,shami.nisimov@intel.com,Bayesian Structure Learning by Recursive Bootstrap
neurips,2018,3,6730,Guy,Koren,intel,Intel,guy.koren@intel.com,Bayesian Structure Learning by Recursive Bootstrap
neurips,2018,4,6730,Gal,Novik,intel,Intel,gal.novik@intel.com,Bayesian Structure Learning by Recursive Bootstrap
neurips,2018,0,3443,Kishan,Wimalawarne,gmail,Kyoto University,kishanwn@gmail.com,Efficient Convex Completion of Coupled Tensors using Coupled Nuclear Norms
neurips,2018,1,3443,Hiroshi,Mamitsuka,kyoto-u,Kyoto University,mami@kuicr.kyoto-u.ac.jp,Efficient Convex Completion of Coupled Tensors using Coupled Nuclear Norms
neurips,2018,0,5317,Qiang,Liu,utexas,UT Austin,lqiang@cs.utexas.edu,Stein Variational Gradient Descent as Moment Matching
neurips,2018,1,5317,Dilin,Wang,utexas,UT Austin,dilin@cs.utexas.edu,Stein Variational Gradient Descent as Moment Matching
neurips,2018,0,6782,Maria-Florina,Balcan,cmu,Carnegie Mellon University,ninamf@cs.cmu.edu,Data-Driven Clustering via Parameterized Lloyd's Families
neurips,2018,1,6782,Travis,Dick,cmu,Carnegie Mellon University,tdick@cs.cmu.edu,Data-Driven Clustering via Parameterized Lloyd's Families
neurips,2018,2,6782,Colin,White,cmu,Carnegie Mellon University,crwhite@cs.cmu.edu,Data-Driven Clustering via Parameterized Lloyd's Families
neurips,2018,0,2179,Haitian,Sun,cmu,Carnegie Mellon University,haitians@cs.cmu.edu,Semi-Supervised Learning with Declaratively Specified Entropy Constraints
neurips,2018,1,2179,William,Cohen,alibaba-inc,Google AI,l.bing@alibaba-inc.com,Semi-Supervised Learning with Declaratively Specified Entropy Constraints
neurips,2018,2,2179,Lidong,Bing,cmu,Tencent AI Lab,wcohen@cs.cmu.edu,Semi-Supervised Learning with Declaratively Specified Entropy Constraints
neurips,2018,0,1891,Ankit,Shah,mit,Massachusetts Institute of Technology,ajshah@mit.edu,Bayesian Inference of Temporal Task Specifications from Demonstrations
neurips,2018,1,1891,Pritish,Kamath,mit,MIT,pritish@mit.edu,Bayesian Inference of Temporal Task Specifications from Demonstrations
neurips,2018,2,1891,Julie,Shah,mit,MIT,shenli@mit.edu,Bayesian Inference of Temporal Task Specifications from Demonstrations
neurips,2018,3,1891,Shen,Li,mit,MIT,julie_a_shah@mit.edu,Bayesian Inference of Temporal Task Specifications from Demonstrations
neurips,2018,0,1937,Dongruo,Zhou,ucla,UCLA,drzhou@cs.ucla.edu,Stochastic Nested Variance Reduction for Nonconvex Optimization
neurips,2018,1,1937,Pan,Xu,ucla,UCLA,panxu@cs.ucla.edu,Stochastic Nested Variance Reduction for Nonconvex Optimization
neurips,2018,2,1937,Quanquan,Gu,ucla,UCLA,qgu@cs.ucla.edu,Stochastic Nested Variance Reduction for Nonconvex Optimization
neurips,2018,0,6438,Tao,Sun,163,National university of defense technology,nudtsuntao@163.com,On Markov Chain Gradient Descent
neurips,2018,1,6438,Yuejiao,Sun,ucla,"University of California, Los Angeles",sunyj@math.ucla.edu,On Markov Chain Gradient Descent
neurips,2018,2,6438,Wotao,Yin,ucla,"University of California, Los Angeles",wotaoyin@math.ucla.edu,On Markov Chain Gradient Descent
neurips,2018,0,5568,Constantinos,Daskalakis,mit,MIT,costis@csail.mit.edu,The Limit Points of (Optimistic) Gradient Descent in Min-Max Optimization
neurips,2018,1,5568,Ioannis,Panageas,sutd,Singapore University of Technology and Design,ioannis@sutd.edu.sg,The Limit Points of (Optimistic) Gradient Descent in Min-Max Optimization
neurips,2018,0,527,Di,Wang,buffalo,State University of New York at Buffalo,dwang45@buffalo.edu,Empirical Risk Minimization in Non-interactive Local Differential Privacy Revisited
neurips,2018,1,527,Marco,Gaboardi,buffalo,Univeristy at Buffalo,gaboardi@buffalo.edu,Empirical Risk Minimization in Non-interactive Local Differential Privacy Revisited
neurips,2018,2,527,Jinhui,Xu,buffalo,SUNY at Buffalo,jinhui@buffalo.edu,Empirical Risk Minimization in Non-interactive Local Differential Privacy Revisited
neurips,2018,0,443,Shupeng,Su,pku,Peking University,sushupeng@pku.edu.cn,Greedy Hash: Towards Fast Optimization for Accurate Hash Coding in CNN
neurips,2018,1,443,Chao,Zhang,pku,Peking University,c.zhang@pku.edu.cn,Greedy Hash: Towards Fast Optimization for Accurate Hash Coding in CNN
neurips,2018,2,443,Kai,Han,pku,"Noah's Ark Laboratory, Huawei",hankai@pku.edu.cn,Greedy Hash: Towards Fast Optimization for Accurate Hash Coding in CNN
neurips,2018,3,443,Yonghong,Tian,pku,Peking University,yhtian@pku.edu.cn,Greedy Hash: Towards Fast Optimization for Accurate Hash Coding in CNN
neurips,2018,0,346,Boris,Hanin,tamu,Texas A&M,bhanin@math.tamu.edu,Which Neural Net Architectures Give Rise to Exploding and Vanishing Gradients?
neurips,2018,0,1496,Jie,Cao,ia,"Center for Research on Intelligent Perception and Computing (CRIPAC) at Institute of Automation, Chinese Academy of Sciences.",jie.cao@cripac.ia.ac.cn,Learning a High Fidelity Pose Invariant Model for High-resolution Face Frontalization
neurips,2018,1,1496,Yibo,Hu,ia,"Institute of Automation, Chinese Academy of Sciences",yibo.hu@cripac.ia.ac.cn,Learning a High Fidelity Pose Invariant Model for High-resolution Face Frontalization
neurips,2018,2,1496,Hongwen,Zhang,ia,CASIA,hongwen.zhang@cripac.ia.ac.cn,Learning a High Fidelity Pose Invariant Model for High-resolution Face Frontalization
neurips,2018,3,1496,Ran,He,ia,"NLPR, CASIA",rhe@nlpr.ia.ac.cn,Learning a High Fidelity Pose Invariant Model for High-resolution Face Frontalization
neurips,2018,4,1496,Zhenan,Sun,ia,"Institute of Automation, Chinese Academy of Sciences (CASIA)",znsun@nlpr.ia.ac.cn,Learning a High Fidelity Pose Invariant Model for High-resolution Face Frontalization
neurips,2018,0,3539,Sham,Kakade,washington,University of Washington,sham@cs.washington.edu,Provably Correct Automatic Sub-Differentiation for Qualified Programs
neurips,2018,1,3539,Jason,Lee,usc,University of Southern California,jasonlee@marshall.usc.edu,Provably Correct Automatic Sub-Differentiation for Qualified Programs
neurips,2018,0,3342,Liudmila,Prokhorenkova,yandex-team,Yandex,ostroumova-la@yandex-team.ru,CatBoost: unbiased boosting with categorical features
neurips,2018,1,3342,Gleb,Gusev,yandex-team,Yandex LLC,gleb57@yandex-team.ru,CatBoost: unbiased boosting with categorical features
neurips,2018,2,3342,Aleksandr,Vorobev,yandex-team,Yandex LLC,alvor88@yandex-team.ru,CatBoost: unbiased boosting with categorical features
neurips,2018,3,3342,Anna Veronika,Dorogush,yandex-team,Yandex,annaveronika@yandex-team.ru,CatBoost: unbiased boosting with categorical features
neurips,2018,4,3342,Andrey,Gulin,yandex-team,Yandex,gulin@yandex-team.ru,CatBoost: unbiased boosting with categorical features
neurips,2018,0,3538,Tengfei,Ma,ibm,IBM Research,Tengfei.Ma1@ibm.com,Constrained Generation of Semantically Valid Graphs via Regularizing Variational Autoencoders
neurips,2018,1,3538,Jie,Chen,ibm,IBM Research,chenjie@us.ibm.com,Constrained Generation of Semantically Valid Graphs via Regularizing Variational Autoencoders
neurips,2018,2,3538,Cao,Xiao,ibm,IBM Research,cxiao@us.ibm.com,Constrained Generation of Semantically Valid Graphs via Regularizing Variational Autoencoders
neurips,2018,0,1670,Oisín,Moran,inscribe,Inscribe.ai,oisin@inscribe.ai,"Deep, complex, invertible  networks for inversion of transmission effects in multimode optical fibres"
neurips,2018,1,1670,Piergiorgio,Caramazza,glasgow,University of Glasgow,Roderick.Murray-Smith@glasgow.ac.uk,"Deep, complex, invertible  networks for inversion of transmission effects in multimode optical fibres"
neurips,2018,2,1670,Daniele,Faccio,gmail,University of Glasgow,piergiorgio.caramazza@gmail.com,"Deep, complex, invertible  networks for inversion of transmission effects in multimode optical fibres"
neurips,2018,3,1670,Roderick,Murray-Smith,glasgow,University of Glasgow,Daniele.Faccio@glasgow.ac.uk,"Deep, complex, invertible  networks for inversion of transmission effects in multimode optical fibres"
neurips,2018,0,3434,Valerio,Perrone,amazon,University of Warwick,vperrone@amazon.com,Scalable Hyperparameter Transfer Learning
neurips,2018,1,3434,Rodolphe,Jenatton,amazon,Amazon Research,jenatton@amazon.com,Scalable Hyperparameter Transfer Learning
neurips,2018,2,3434,Matthias,Seeger,amazon,Amazon Development Center,matthis@amazon.com,Scalable Hyperparameter Transfer Learning
neurips,2018,3,3434,Cedric,Archambeau,amazon,Amazon,cedrica@amazon.com,Scalable Hyperparameter Transfer Learning
neurips,2018,0,5129,Soroosh,Shafieezadeh Abadeh,,EPFL,,Wasserstein Distributionally Robust Kalman Filtering
neurips,2018,1,5129,Viet Anh,Nguyen,,Ecole Polytechnique Federale de Lausanne,,Wasserstein Distributionally Robust Kalman Filtering
neurips,2018,2,5129,Daniel,Kuhn,,EPFL,,Wasserstein Distributionally Robust Kalman Filtering
neurips,2018,3,5129,Peyman,Mohajerin Esfahani,,TU Delft,,Wasserstein Distributionally Robust Kalman Filtering
neurips,2018,0,395,Cong,Fang,pku,Peking University,fangcong@pku.edu.cn,SPIDER: Near-Optimal Non-Convex Optimization via Stochastic Path-Integrated Differential Estimator
neurips,2018,1,395,Chris Junchi,Li,pku,Tencent AI Lab,zlin@pku.edu.cn,SPIDER: Near-Optimal Non-Convex Optimization via Stochastic Path-Integrated Differential Estimator
neurips,2018,2,395,Zhouchen,Lin,gmail,Peking University,junchi.li.duke@gmail.com,SPIDER: Near-Optimal Non-Convex Optimization via Stochastic Path-Integrated Differential Estimator
neurips,2018,3,395,Tong,Zhang,tongzhang-ml,Tencent AI Lab,tongzhang@tongzhang-ml.org,SPIDER: Near-Optimal Non-Convex Optimization via Stochastic Path-Integrated Differential Estimator
neurips,2018,0,1008,Shichen,Liu,gmail,Tsinghua University,liushichen95@gmail.com,Generalized Zero-Shot Learning with Deep Calibration Network
neurips,2018,1,1008,Mingsheng,Long,tsinghua,Tsinghua University,mingsheng@tsinghua.edu.cn,Generalized Zero-Shot Learning with Deep Calibration Network
neurips,2018,2,1008,Jianmin,Wang,tsinghua,Tsinghua University,jimwang@tsinghua.edu.cn,Generalized Zero-Shot Learning with Deep Calibration Network
neurips,2018,3,1008,Michael,Jordan,berkeley,UC Berkeley,jordan@berkeley.edu,Generalized Zero-Shot Learning with Deep Calibration Network
neurips,2018,0,3510,Wen,Sun,cmu,Carnegie Mellon University,wensun@cs.cmu.edu,Dual Policy Iteration
neurips,2018,1,3510,Geoffrey,Gordon,cmu,MSR Montréal & CMU,ggordon@cs.cmu.edu,Dual Policy Iteration
neurips,2018,2,3510,Byron,Boots,cmu,Georgia Tech / Google Brain,dbagnell@cs.cmu.edu,Dual Policy Iteration
neurips,2018,3,3510,J.,Bagnell,gatech,Carnegie Mellon University,bboots@cc.gatech.edu,Dual Policy Iteration
neurips,2018,0,2295,Yi,Tay,ntu,Nanyang Technological University,ytay017@e.ntu.edu.sg1,Recurrently Controlled Recurrent Networks
neurips,2018,1,2295,Anh Tuan,Luu,a-star,Institute for Infocomm Research,at.luu@i2r.a-star.edu.sg2,Recurrently Controlled Recurrent Networks
neurips,2018,2,2295,Siu Cheung,Hui,ntu,Nanyang Technological University,asschui@ntu.edu.sg3,Recurrently Controlled Recurrent Networks
neurips,2018,0,1190,Xenia,Miscouridou,ox,University of Oxford,miscouri@stats.ox.ac.uk,"Modelling sparsity, heterogeneity, reciprocity and community structure in temporal interaction data"
neurips,2018,1,1190,Francois,Caron,ox,Oxford,caron@stats.ox.ac.uk,"Modelling sparsity, heterogeneity, reciprocity and community structure in temporal interaction data"
neurips,2018,2,1190,Yee Whye,Teh,ox,"University of Oxford, DeepMind",y.w.teh@stats.ox.ac.uk,"Modelling sparsity, heterogeneity, reciprocity and community structure in temporal interaction data"
neurips,2018,0,6859,Pavel,Dvurechenskii,wias-berlin,WIAS im Forschungsverbund Berlin e. V.,pavel.dvurechensky@wias-berlin.de,Decentralize and Randomize: Faster Algorithm for Wasserstein Barycenters
neurips,2018,1,6859,Darina,Dvinskikh,wias-berlin,WIAS im Forschungsverbund Berlin e. V.,darina.dvinskikh@wias-berlin.de,Decentralize and Randomize: Faster Algorithm for Wasserstein Barycenters
neurips,2018,2,6859,Alexander,Gasnikov,yandex,SkolTech,gasnikov@yandex.ru,Decentralize and Randomize: Faster Algorithm for Wasserstein Barycenters
neurips,2018,3,6859,Cesar,Uribe,mit,Massachusetts Institute of Technology,cauribe@mit.edu,Decentralize and Randomize: Faster Algorithm for Wasserstein Barycenters
neurips,2018,4,6859,Angelia,Nedich,asu,Arizona State University,angelia.nedich@asu.edu,Decentralize and Randomize: Faster Algorithm for Wasserstein Barycenters
neurips,2018,0,3368,Pablo,Moreno-Muñoz,uc3m,Universidad Carlos III de Madrid,pmoreno@tsc.uc3m.es,Heterogeneous Multi-output Gaussian Process Prediction
neurips,2018,1,3368,Antonio,Artés,uc3m,Universidad Carlos III de Madrid,antonio@tsc.uc3m.es,Heterogeneous Multi-output Gaussian Process Prediction
neurips,2018,2,3368,Mauricio,Álvarez,sheffield,University of Sheffield,mauricio.alvarez@sheffield.ac.uk,Heterogeneous Multi-output Gaussian Process Prediction
neurips,2018,0,5679,Bharat,Singh,umd,"University of Maryland, College Park",bharat@cs.umd.edu,SNIPER: Efficient Multi-Scale Training
neurips,2018,1,5679,Mahyar,Najibi,umd,University of Maryland,najibi@cs.umd.edu,SNIPER: Efficient Multi-Scale Training
neurips,2018,2,5679,Larry,Davis,umd,University of Maryland,lsd@cs.umd.edu,SNIPER: Efficient Multi-Scale Training
neurips,2018,0,292,Haoye,Dong,,Sun Yat-sen University,donghy7@mail2,Soft-Gated Warping-GAN for Pose-Guided Person Image Synthesis
neurips,2018,1,292,Xiaodan,Liang,,Sun Yat-sen University,laihanj3@mail,Soft-Gated Warping-GAN for Pose-Guided Person Image Synthesis
neurips,2018,2,292,Ke,Gong,sysu,Sun Yat-sen University,issjyin@mail.sysu.edu.cn,Soft-Gated Warping-GAN for Pose-Guided Person Image Synthesis
neurips,2018,3,292,Hanjiang,Lai,gmail,Sun Yat-Sen university,xdliang328@gmail.com,Soft-Gated Warping-GAN for Pose-Guided Person Image Synthesis
neurips,2018,4,292,Jia,Zhu,gmail,South China Normal University,kegong936@gmail.com,Soft-Gated Warping-GAN for Pose-Guided Person Image Synthesis
neurips,2018,5,292,Jian,Yin,scun,Sun Yat-Sen University,jzhu@m.scun.edu.cn,Soft-Gated Warping-GAN for Pose-Guided Person Image Synthesis
neurips,2018,0,1493,Eli,Schwartz,,IBM-Research,,Delta-encoder: an effective sample synthesis method for few-shot object recognition
neurips,2018,1,1493,Leonid,Karlinsky,,IBM-Research,,Delta-encoder: an effective sample synthesis method for few-shot object recognition
neurips,2018,2,1493,Joseph,Shtok,,IBM-Reseach,,Delta-encoder: an effective sample synthesis method for few-shot object recognition
neurips,2018,3,1493,Sivan,Harary,,IBM-Research,,Delta-encoder: an effective sample synthesis method for few-shot object recognition
neurips,2018,4,1493,Mattias,Marder,,IBM-Research,,Delta-encoder: an effective sample synthesis method for few-shot object recognition
neurips,2018,5,1493,Abhishek,Kumar,,Google,,Delta-encoder: an effective sample synthesis method for few-shot object recognition
neurips,2018,6,1493,Rogerio,Feris,,IBM Research AI,,Delta-encoder: an effective sample synthesis method for few-shot object recognition
neurips,2018,7,1493,Raja,Giryes,,Tel Aviv University,,Delta-encoder: an effective sample synthesis method for few-shot object recognition
neurips,2018,8,1493,Alex,Bronstein,,Technion,,Delta-encoder: an effective sample synthesis method for few-shot object recognition
neurips,2018,0,1261,Peng,Jiang,osu,The Ohio State University,jiang.952@osu.edu,A Linear Speedup Analysis of Distributed Deep Learning with Sparse and Quantized Communication
neurips,2018,1,1261,Gagan,Agrawal,ohio-state,Ohio State University,agrawal@cse.ohio-state.edu,A Linear Speedup Analysis of Distributed Deep Learning with Sparse and Quantized Communication
neurips,2018,0,5106,Han,Shao,cuhk,The Chinese University of Hong Kong,hshao@cse.cuhk.edu.hk,Almost Optimal Algorithms for Linear Stochastic Bandits with Heavy-Tailed Payoffs
neurips,2018,1,5106,Xiaotian,Yu,cuhk,The Chinese University of Hong Kong,xtyu@cse.cuhk.edu.hk,Almost Optimal Algorithms for Linear Stochastic Bandits with Heavy-Tailed Payoffs
neurips,2018,2,5106,Irwin,King,cuhk,Chinese University of Hong Kong,king@cse.cuhk.edu.hk,Almost Optimal Algorithms for Linear Stochastic Bandits with Heavy-Tailed Payoffs
neurips,2018,3,5106,Michael,Lyu,cuhk,CUHK,lyu@cse.cuhk.edu.hk,Almost Optimal Algorithms for Linear Stochastic Bandits with Heavy-Tailed Payoffs
neurips,2018,0,3053,Weiyang,Liu,,Georgia Institute of Technology,,Learning towards Minimum Hyperspherical Energy
neurips,2018,1,3053,Rongmei,Lin,,Emory University,,Learning towards Minimum Hyperspherical Energy
neurips,2018,2,3053,Zhen,Liu,,Georgia Institute of Technology,,Learning towards Minimum Hyperspherical Energy
neurips,2018,3,3053,Lixin,Liu,,SCUT,,Learning towards Minimum Hyperspherical Energy
neurips,2018,4,3053,Zhiding,Yu,,NVIDIA,,Learning towards Minimum Hyperspherical Energy
neurips,2018,5,3053,Bo,Dai,,Google Brain,,Learning towards Minimum Hyperspherical Energy
neurips,2018,6,3053,Le,Song,,Ant Financial & Georgia Institute of Technology,,Learning towards Minimum Hyperspherical Energy
neurips,2018,0,2580,Anqi,Wu,princeton,Princeton University,anqiw@princeton.edu,Learning a latent manifold of odor representations from neural responses in piriform cortex
neurips,2018,1,2580,Stan,Pashkovski,princeton,harvard university,pillow@princeton.edu,Learning a latent manifold of odor representations from neural responses in piriform cortex
neurips,2018,2,2580,Sandeep,Datta,harvard,harvard university,pashkovs@hms.harvard.edu,Learning a latent manifold of odor representations from neural responses in piriform cortex
neurips,2018,3,2580,Jonathan,Pillow,harvard,Princeton University,srdatta@hms.harvard.edu,Learning a latent manifold of odor representations from neural responses in piriform cortex
neurips,2018,0,670,Qilong,Wang,tju,Tianjin University,qlwang@tju.edu.cn,Global Gated Mixture of Second-order Pooling for Improving Deep Convolutional Neural Networks
neurips,2018,1,670,Zilin,Gao,dlut,Dalian University of Technology,gzl@mail.dlut.edu.cn,Global Gated Mixture of Second-order Pooling for Improving Deep Convolutional Neural Networks
neurips,2018,2,670,Jiangtao,Xie,dlut,Dalian University of Technology,jiangtaoxie@mail.dlut.edu.cn,Global Gated Mixture of Second-order Pooling for Improving Deep Convolutional Neural Networks
neurips,2018,3,670,Wangmeng,Zuo,hit,Harbin Institute of Technology,wmzuo@hit.edu.cn,Global Gated Mixture of Second-order Pooling for Improving Deep Convolutional Neural Networks
neurips,2018,4,670,Peihua,Li,dlut,Dalian University of Technology,peihuali@dlut.edu.cn,Global Gated Mixture of Second-order Pooling for Improving Deep Convolutional Neural Networks
neurips,2018,0,1819,Tal,Ben-Nun,ethz,ETH Zurich,talbn@inf.ethz.ch,Neural Code Comprehension: A Learnable Representation of Code Semantics
neurips,2018,1,1819,Alice Shoshana,Jakobovits,ethz,ETH Zurich,alicej@student.ethz.ch,Neural Code Comprehension: A Learnable Representation of Code Semantics
neurips,2018,2,1819,Torsten,Hoefler,ethz,ETH Zurich,htor@inf.ethz.ch,Neural Code Comprehension: A Learnable Representation of Code Semantics
neurips,2018,0,5763,Tin,Nguyen,mit,MIT,tdn@mit.edu,PAC-Bayes Tree: weighted subtrees with guarantees
neurips,2018,1,5763,Samory,Kpotufe,princeton,Princeton University,samory@princeton.edu,PAC-Bayes Tree: weighted subtrees with guarantees
neurips,2018,0,2160,Rui,Shu,stanford,Stanford University,ruishu@stanford.edu,Amortized Inference Regularization
neurips,2018,1,2160,Hung,Bui,google,Google DeepMind,buih@google.com,Amortized Inference Regularization
neurips,2018,2,2160,Shengjia,Zhao,stanford,Stanford University,sjzhao@stanford.edu,Amortized Inference Regularization
neurips,2018,3,2160,Mykel,Kochenderfer,stanford,Stanford University,mykel@stanford.edu,Amortized Inference Regularization
neurips,2018,4,2160,Stefano,Ermon,stanford,Stanford,ermon@cs.stanford.edu,Amortized Inference Regularization
neurips,2018,0,33,Jianlong,Chang,ia,"National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences",jianlong.chang@nlpr.ia.ac.cn,Structure-Aware Convolutional Neural Networks
neurips,2018,1,33,Jie,Gu,ia,"National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences",jie.gu@nlpr.ia.ac.cn,Structure-Aware Convolutional Neural Networks
neurips,2018,2,33,Lingfeng,Wang,ia,"Institute of Automation, Chinese Academy of Sciences",lfwang@nlpr.ia.ac.cn,Structure-Aware Convolutional Neural Networks
neurips,2018,3,33,GAOFENG,MENG,ia,"Institute of Automation, Chinese Academy of Sciences",gfmeng@nlpr.ia.ac.cn,Structure-Aware Convolutional Neural Networks
neurips,2018,4,33,SHIMING,XIANG,ia,"Chinese Academy of Sciences, China",smxiang@nlpr.ia.ac.cn,Structure-Aware Convolutional Neural Networks
neurips,2018,5,33,Chunhong,Pan,ia,"Institute of Automation, Chinese Academy of Sciences",chpan@nlpr.ia.ac.cn,Structure-Aware Convolutional Neural Networks
neurips,2018,0,627,Miguel,Carreira-Perpinan,ucmerced,"University of California, Merced",mcarreira-perpinan@ucmerced.edu,"Alternating optimization of decision trees, with application to learning sparse oblique trees"
neurips,2018,1,627,Pooya,Tavallali,ucmerced,UC Merced,ptavallali@ucmerced.edu,"Alternating optimization of decision trees, with application to learning sparse oblique trees"
neurips,2018,0,746,Dongsung,Huh,salk,MIT-IBM AI Center,huh@salk.edu,Gradient Descent for Spiking Neural Networks
neurips,2018,1,746,Terrence,Sejnowski,salk,Salk Institute,terry@salk.edu,Gradient Descent for Spiking Neural Networks
neurips,2018,0,5707,Daniele,Calandriello,,LCSL IIT/MIT,,Statistical and Computational Trade-Offs in Kernel K-Means
neurips,2018,1,5707,Lorenzo,Rosasco,,University of Genova- MIT - IIT,,Statistical and Computational Trade-Offs in Kernel K-Means
neurips,2018,0,2592,Jeffrey,Pennington,,Google Brain,,The Spectrum of the Fisher Information Matrix of a Single-Hidden-Layer Neural Network
neurips,2018,1,2592,Pratik,Worah,,Google,,The Spectrum of the Fisher Information Matrix of a Single-Hidden-Layer Neural Network
neurips,2018,0,3543,Grant,Rotskoff,nyu,New York University,eve2@cims.nyu.edu,Parameters as interacting particles: long time convergence and asymptotic error scaling of neural networks
neurips,2018,1,3543,Eric,Vanden-Eijnden,nyu,New York University,rotskoff@cims.nyu.edu,Parameters as interacting particles: long time convergence and asymptotic error scaling of neural networks
neurips,2018,0,6456,Ikko,Yamane,,The University of Tokyo/RIKEN,,Uplift Modeling from Separate Labels
neurips,2018,1,6456,Florian,Yger,,Université Paris-Dauphine,,Uplift Modeling from Separate Labels
neurips,2018,2,6456,Jamal,Atif,,Université Paris-Dauphine,,Uplift Modeling from Separate Labels
neurips,2018,3,6456,Masashi,Sugiyama,,RIKEN / University of Tokyo,,Uplift Modeling from Separate Labels
neurips,2018,0,2111,Risheng,Liu,,Dalian University of Technology,,A Bridging Framework for Model Optimization and Deep Propagation
neurips,2018,1,2111,Shichao,Cheng,,Dalian University of Technology,,A Bridging Framework for Model Optimization and Deep Propagation
neurips,2018,2,2111,xiaokun,liu,,DUT,,A Bridging Framework for Model Optimization and Deep Propagation
neurips,2018,3,2111,Long,Ma,,"School of Software Technology, Dalian University of Technology",,A Bridging Framework for Model Optimization and Deep Propagation
neurips,2018,4,2111,Xin,Fan,,Dalian University of Technology,,A Bridging Framework for Model Optimization and Deep Propagation
neurips,2018,5,2111,Zhongxuan,Luo,,DALIAN UNIVERSITY OF TECHNOLOGY,,A Bridging Framework for Model Optimization and Deep Propagation
neurips,2018,0,2242,Haidar,Khan,rpi,Rensselaer Polytechnic Institute,khanh2@rpi.edu,Learning filter widths of spectral decompositions with wavelets
neurips,2018,1,2242,Bulent,Yener,rpi,Rensselaer Polytechnic Institute (RPI),yener@rpi.edu,Learning filter widths of spectral decompositions with wavelets
neurips,2018,0,6739,Abubakar,Abid,,Stanford,,Learning a Warping Distance from Unlabeled Time Series Using Sequence Autoencoders
neurips,2018,1,6739,James,Zou,,Stanford University,,Learning a Warping Distance from Unlabeled Time Series Using Sequence Autoencoders
neurips,2018,0,3489,Kush,Bhatia,berkeley,UC Berkeley,kushbhatia@berkeley.edu,Gen-Oja: Simple & Efficient Algorithm for Streaming Generalized Eigenvector Computation
neurips,2018,1,3489,Aldo,Pacchiano,berkeley,UC Berkeley,flammarion@berkeley.edu,Gen-Oja: Simple & Efficient Algorithm for Streaming Generalized Eigenvector Computation
neurips,2018,2,3489,Nicolas,Flammarion,berkeley,UC Berkeley,pacchiano@berkeley.edu,Gen-Oja: Simple & Efficient Algorithm for Streaming Generalized Eigenvector Computation
neurips,2018,3,3489,Peter,Bartlett,berkeley,UC Berkeley,peter@berkeley.edu,Gen-Oja: Simple & Efficient Algorithm for Streaming Generalized Eigenvector Computation
neurips,2018,4,3489,Michael,Jordan,berkeley,UC Berkeley,jordan@cs.berkeley.edu,Gen-Oja: Simple & Efficient Algorithm for Streaming Generalized Eigenvector Computation
neurips,2018,0,1984,Joshua,Fromm,uw,University of Washington,jwfromm@uw.edu,Heterogeneous Bitwidth Binarization in Convolutional Neural Networks
neurips,2018,1,1984,Shwetak,Patel,washington,University of Washington,shwetak@cs.washington.edu,Heterogeneous Bitwidth Binarization in Convolutional Neural Networks
neurips,2018,2,1984,Matthai,Philipose,microsoft,Microsoft Research,matthaip@microsoft.com,Heterogeneous Bitwidth Binarization in Convolutional Neural Networks
neurips,2018,0,3574,Iryna,Korshunova,ugent,Ghent University,iryna.korshunova@ugent.be,BRUNO: A Deep Recurrent Model for Exchangeable Data
neurips,2018,1,3574,Jonas,Degrave,ugent,Deepmind,jonas.degrave@ugent.be,BRUNO: A Deep Recurrent Model for Exchangeable Data
neurips,2018,2,3574,Ferenc,Huszar,twitter,Twitter,fhuszar@twitter.com,BRUNO: A Deep Recurrent Model for Exchangeable Data
neurips,2018,3,3574,Yarin,Gal,ox,University of OXford,yarin@cs.ox.ac.uk,BRUNO: A Deep Recurrent Model for Exchangeable Data
neurips,2018,4,3574,Arthur,Gretton,gmail,"Gatsby Unit, UCL",arthur.gretton@gmail.com,BRUNO: A Deep Recurrent Model for Exchangeable Data
neurips,2018,5,3574,Joni,Dambre,ugent,Ghent University,joni.dambre@ugent.be,BRUNO: A Deep Recurrent Model for Exchangeable Data
neurips,2018,0,1602,François,Portier,univ-rennes1,Télécom ParisTech,bernard.delyon@univ-rennes1.fr,Asymptotic optimality of adaptive importance sampling
neurips,2018,1,1602,Bernard,Delyon,gmail,University of Rennes 1,francois.portier@gmail.com,Asymptotic optimality of adaptive importance sampling
neurips,2018,0,5491,Paul,Hand,northeastern,Northeastern University,p.hand@northeastern.edu,Phase Retrieval Under a Generative Prior
neurips,2018,1,5491,Oscar,Leong,rice,Rice University,oscar.f.leong@rice.edu,Phase Retrieval Under a Generative Prior
neurips,2018,2,5491,Vlad,Voroninski,helm,Helm.ai,vlad@helm.ai,Phase Retrieval Under a Generative Prior
neurips,2018,0,6628,Francesco Paolo,Casale,,Microsoft Research,,Gaussian Process Prior Variational Autoencoders
neurips,2018,1,6628,Adrian,Dalca,,MIT,,Gaussian Process Prior Variational Autoencoders
neurips,2018,2,6628,Luca,Saglietti,,"Microsoft Research New England (visitor)  Italian Institute for Genomic Medicine, Torino, Italy",,Gaussian Process Prior Variational Autoencoders
neurips,2018,3,6628,Jennifer,Listgarten,,UC Berkeley,,Gaussian Process Prior Variational Autoencoders
neurips,2018,4,6628,Nicolo,Fusi,,Microsoft Research,,Gaussian Process Prior Variational Autoencoders
neurips,2018,0,5541,Kuan,Han,,Purdue University,,Deep Predictive Coding Network with Local Recurrent Processing for Object Recognition
neurips,2018,1,5541,Haiguang,Wen,,Purdue University,,Deep Predictive Coding Network with Local Recurrent Processing for Object Recognition
neurips,2018,2,5541,Yizhen,Zhang,,Purdue University,,Deep Predictive Coding Network with Local Recurrent Processing for Object Recognition
neurips,2018,3,5541,Di,Fu,,Purdue University,,Deep Predictive Coding Network with Local Recurrent Processing for Object Recognition
neurips,2018,4,5541,Eugenio,Culurciello,,FWDNXT,,Deep Predictive Coding Network with Local Recurrent Processing for Object Recognition
neurips,2018,5,5541,Zhongming,Liu,,Purdue University,,Deep Predictive Coding Network with Local Recurrent Processing for Object Recognition
neurips,2018,0,2189,Zelda,Mariet,,MIT,,Exponentiated Strongly Rayleigh Distributions
neurips,2018,1,2189,Suvrit,Sra,,MIT,,Exponentiated Strongly Rayleigh Distributions
neurips,2018,2,2189,Stefanie,Jegelka,,MIT,,Exponentiated Strongly Rayleigh Distributions
neurips,2018,0,2774,Dilin,Wang,utexas,UT Austin,dilin@cs.utexas.edu,Variational Inference with Tail-adaptive f-Divergence
neurips,2018,1,2774,Hao,Liu,gmail,UT Austin,uestcliuhao@gmail.com,Variational Inference with Tail-adaptive f-Divergence
neurips,2018,2,2774,Qiang,Liu,utexas,UT Austin,lqiang@cs.utexas.edu,Variational Inference with Tail-adaptive f-Divergence
neurips,2018,0,5005,James,Thewlis,ox,University of Oxford,jdt@robots.ox.ac.uk,Modelling and unsupervised learning of symmetric deformable object categories
neurips,2018,1,5005,Hakan,Bilen,ox,University of Edinburgh,vedaldi@robots.ox.ac.uk,Modelling and unsupervised learning of symmetric deformable object categories
neurips,2018,2,5005,Andrea,Vedaldi,ed,Facebook AI Research and University of Oxford,hbilen@ed.ac.uk,Modelling and unsupervised learning of symmetric deformable object categories
neurips,2018,0,2556,Riccardo,Volpi,,Istituto Italiano di Tecnologia,,Generalizing to Unseen Domains via Adversarial Data Augmentation
neurips,2018,1,2556,Hongseok,Namkoong,,Stanford University,,Generalizing to Unseen Domains via Adversarial Data Augmentation
neurips,2018,2,2556,Ozan,Sener,,Intel Labs,,Generalizing to Unseen Domains via Adversarial Data Augmentation
neurips,2018,3,2556,John,Duchi,,Stanford,,Generalizing to Unseen Domains via Adversarial Data Augmentation
neurips,2018,4,2556,Vittorio,Murino,,Istituto Italiano di Tecnologia,,Generalizing to Unseen Domains via Adversarial Data Augmentation
neurips,2018,5,2556,Silvio,Savarese,,Stanford University,,Generalizing to Unseen Domains via Adversarial Data Augmentation
neurips,2018,0,5047,Chuyang,Ke,purdue,Purdue University,jhonorio@purdue.edu,Information-theoretic Limits for Community Detection in Network Models
neurips,2018,1,5047,Jean,Honorio,purdue,Purdue University,cke@purdue.edu,Information-theoretic Limits for Community Detection in Network Models
neurips,2018,0,5269,João,Sacramento,unibe,University of Bern,sacramento@pyl.unibe.ch,Dendritic cortical microcircuits approximate the backpropagation algorithm
neurips,2018,1,5269,Rui,Ponte Costa,mila,Univeristy of Bern,yoshua.bengio@mila.quebec,Dendritic cortical microcircuits approximate the backpropagation algorithm
neurips,2018,2,5269,Yoshua,Bengio,unibe,U. Montreal,costa@pyl.unibe.ch,Dendritic cortical microcircuits approximate the backpropagation algorithm
neurips,2018,3,5269,Walter,Senn,unibe,University of Bern,senn@pyl.unibe.ch,Dendritic cortical microcircuits approximate the backpropagation algorithm
neurips,2018,0,1169,Yuqian,Zhang,columbia,Cornell University,yz2409@columbia.edu,Structured Local Minima in Sparse Blind Deconvolution
neurips,2018,1,1169,Han-wen,Kuo,columbia,Columbia University,hk2673@columbia.edu,Structured Local Minima in Sparse Blind Deconvolution
neurips,2018,2,1169,John,Wright,columbia,Columbia University,jw2966@columbia.edu,Structured Local Minima in Sparse Blind Deconvolution
neurips,2018,0,1983,Xiaohan,Wei,usc,USC,xiaohanw@usc.edu,Solving Non-smooth Constrained Programs with Lower Complexity than $\mathcal{O}(1/\varepsilon)$: A Primal-Dual Homotopy Smoothing Approach
neurips,2018,1,1983,Hao,Yu,alibaba-inc,Alibaba Group (US) Inc,hao.yu@alibaba-inc.com,Solving Non-smooth Constrained Programs with Lower Complexity than $\mathcal{O}(1/\varepsilon)$: A Primal-Dual Homotopy Smoothing Approach
neurips,2018,2,1983,Qing,Ling,sysu,Sun Yat-Sen University,lingqing556@mail.sysu.edu.cn,Solving Non-smooth Constrained Programs with Lower Complexity than $\mathcal{O}(1/\varepsilon)$: A Primal-Dual Homotopy Smoothing Approach
neurips,2018,3,1983,Michael,Neely,gmail,USC,mikejneely@gmail.com,Solving Non-smooth Constrained Programs with Lower Complexity than $\mathcal{O}(1/\varepsilon)$: A Primal-Dual Homotopy Smoothing Approach
neurips,2018,0,3666,Yu-An,Chung,mit,Massachusetts Institute of Technology,andyyuan@mit.edu,Unsupervised Cross-Modal Alignment of Speech and Text Embedding Spaces
neurips,2018,1,3666,Wei-Hung,Weng,mit,Massachusetts Institute of Technology,ckbjimmy@mit.edu,Unsupervised Cross-Modal Alignment of Speech and Text Embedding Spaces
neurips,2018,2,3666,Schrasing,Tong,mit,MIT CSAIL,st9@mit.edu,Unsupervised Cross-Modal Alignment of Speech and Text Embedding Spaces
neurips,2018,3,3666,James,Glass,mit,Massachusetts Institute of Technology,glass@mit.edu,Unsupervised Cross-Modal Alignment of Speech and Text Embedding Spaces
neurips,2018,0,1319,Ricky T. Q.,Chen,,University of Toronto,,Isolating Sources of Disentanglement in Variational Autoencoders
neurips,2018,1,1319,Xuechen,Li,,University of Toronto,,Isolating Sources of Disentanglement in Variational Autoencoders
neurips,2018,2,1319,Roger,Grosse,,University of Toronto,,Isolating Sources of Disentanglement in Variational Autoencoders
neurips,2018,3,1319,David,Duvenaud,,University of Toronto,,Isolating Sources of Disentanglement in Variational Autoencoders
neurips,2018,0,6580,DJ,Strouse,,Princeton University,,Learning to Share and Hide Intentions using Information Regularization
neurips,2018,1,6580,Max,Kleiman-Weiner,,Harvard,,Learning to Share and Hide Intentions using Information Regularization
neurips,2018,2,6580,Josh,Tenenbaum,,MIT,,Learning to Share and Hide Intentions using Information Regularization
neurips,2018,3,6580,Matt,Botvinick,,Google DeepMind / University College London,,Learning to Share and Hide Intentions using Information Regularization
neurips,2018,4,6580,David,Schwab,,"ITS, CUNY Graduate Center",,Learning to Share and Hide Intentions using Information Regularization
neurips,2018,0,1807,Irene,Chen,mit,MIT,iychen@mit.edu,Why Is My Classifier Discriminatory?
neurips,2018,1,1807,Fredrik,Johansson,mit,MIT,fredrikj@mit.edu,Why Is My Classifier Discriminatory?
neurips,2018,2,1807,David,Sontag,mit,MIT,dsontag@csail.mit.edu,Why Is My Classifier Discriminatory?
neurips,2018,0,1985,Tomas,Jakab,ox,University of Oxford,tomj@robots.ox.ac.uk,Unsupervised Learning of Object Landmarks through Conditional Image Generation
neurips,2018,1,1985,Ankush,Gupta,ox,University of Oxford,ankush@robots.ox.ac.uk,Unsupervised Learning of Object Landmarks through Conditional Image Generation
neurips,2018,2,1985,Hakan,Bilen,ox,University of Edinburgh,vedaldi@robots.ox.ac.uk,Unsupervised Learning of Object Landmarks through Conditional Image Generation
neurips,2018,3,1985,Andrea,Vedaldi,ed,Facebook AI Research and University of Oxford,hbilen@ed.ac.uk,Unsupervised Learning of Object Landmarks through Conditional Image Generation
neurips,2018,0,2074,Maria,Dimakopoulou,stanford,Stanford University,madima@stanford.edu,Scalable Coordinated Exploration in Concurrent Reinforcement Learning
neurips,2018,1,2074,Ian,Osband,google,Google Deepmind,iosband@google.com,Scalable Coordinated Exploration in Concurrent Reinforcement Learning
neurips,2018,2,2074,Benjamin,Van Roy,stanford,Stanford University,bvr@stanford.edu,Scalable Coordinated Exploration in Concurrent Reinforcement Learning
neurips,2018,0,864,Yin Cheng,Ng,ucl,University College London,y.ng.12@ucl.ac.uk,Bayesian Semi-supervised Learning with Graph Gaussian Processes
neurips,2018,1,864,Nicolò,Colombo,ucl,University College London,nicolo.colombo@ucl.ac.uk,Bayesian Semi-supervised Learning with Graph Gaussian Processes
neurips,2018,2,864,Ricardo,Silva,ucl,University College London,ricardo.silva@ucl.ac.uk,Bayesian Semi-supervised Learning with Graph Gaussian Processes
neurips,2018,0,3771,Dustin,Tran,,Google Brain,,"Simple, Distributed, and Accelerated Probabilistic Programming"
neurips,2018,1,3771,Matthew,Hoffman,,Google,,"Simple, Distributed, and Accelerated Probabilistic Programming"
neurips,2018,2,3771,Dave,Moore,,Google,,"Simple, Distributed, and Accelerated Probabilistic Programming"
neurips,2018,3,3771,Christopher,Suter,,"Google, Inc",,"Simple, Distributed, and Accelerated Probabilistic Programming"
neurips,2018,4,3771,Srinivas,Vasudevan,,Google,,"Simple, Distributed, and Accelerated Probabilistic Programming"
neurips,2018,5,3771,Alexey,Radul,,Google,,"Simple, Distributed, and Accelerated Probabilistic Programming"
neurips,2018,0,1547,Cheng,Tang,gwu,George Washington University,tangch@gwu.edu,When do random forests fail?
neurips,2018,1,1547,Damien,Garreau,mpg,Max Planck Institute,damien.garreau@tuebingen.mpg.de,When do random forests fail?
neurips,2018,2,1547,Ulrike,von Luxburg,uni-tuebingen,University of Tübingen,luxburg@informatik.uni-tuebingen.de,When do random forests fail?
neurips,2018,0,1652,Lixing,Chen,miami,University of Miami,lx.chen@miami.edu,Contextual Combinatorial Multi-armed Bandits with Volatile Arms and Submodular Reward
neurips,2018,1,1652,Jie,Xu,miami,University of Miami,jiexu@miami.edu,Contextual Combinatorial Multi-armed Bandits with Volatile Arms and Submodular Reward
neurips,2018,2,1652,Zhuo,Lu,usf,University of South Florida,zhuolu@usf.edu,Contextual Combinatorial Multi-armed Bandits with Volatile Arms and Submodular Reward
neurips,2018,0,1143,Xiuming,Zhang,,MIT CSAIL,,Learning to Reconstruct Shapes from Unseen Classes
neurips,2018,1,1143,Zhoutong,Zhang,,MIT,,Learning to Reconstruct Shapes from Unseen Classes
neurips,2018,2,1143,Chengkai,Zhang,,Massachusetts Institute of Technology,,Learning to Reconstruct Shapes from Unseen Classes
neurips,2018,3,1143,Josh,Tenenbaum,,MIT,,Learning to Reconstruct Shapes from Unseen Classes
neurips,2018,4,1143,Bill,Freeman,,MIT/Google,,Learning to Reconstruct Shapes from Unseen Classes
neurips,2018,5,1143,Jiajun,Wu,,MIT,,Learning to Reconstruct Shapes from Unseen Classes
neurips,2018,0,1112,Daniel,Pimentel-Alarcon,gsu,Georgia State University,pimentel@gsu.edu,Mixture Matrix Completion
neurips,2018,0,883,Romain,WARLOP,fifty-five,Inria,romain@fifty-five.com,Fighting Boredom in Recommender Systems with Linear Reinforcement Learning
neurips,2018,1,883,Alessandro,Lazaric,fb,INRIA,lazaric@fb.com,Fighting Boredom in Recommender Systems with Linear Reinforcement Learning
neurips,2018,2,883,Jérémie,Mary,criteo,,j.mary@criteo.com,Fighting Boredom in Recommender Systems with Linear Reinforcement Learning
neurips,2018,0,3765,Xinyuan,Zhang,duke,Duke University,xy.zhang@duke.edu,Diffusion Maps for Textual Network Embedding
neurips,2018,1,3765,Yitong,Li,duke,Duke University,yitong.li@duke.edu,Diffusion Maps for Textual Network Embedding
neurips,2018,2,3765,Dinghan,Shen,duke,Duke University,dinghan.shen@duke.edu,Diffusion Maps for Textual Network Embedding
neurips,2018,3,3765,Lawrence,Carin,duke,Duke University,lcarin@duke.edu,Diffusion Maps for Textual Network Embedding
neurips,2018,0,3678,Gabi,Shalev,gmail,"Dept. of Computer Science, Bar-Ilan University",shalev.gabi@gmail.com,Out-of-Distribution Detection using Multiple Semantic Label Representations
neurips,2018,1,3678,Yossi,Adi,gmail,Bar Ilan University,yossiadidrum@gmail.com,Out-of-Distribution Detection using Multiple Semantic Label Representations
neurips,2018,2,3678,Joseph,Keshet,biu,Bar-Ilan University,jkeshet@cs.biu.ac.il,Out-of-Distribution Detection using Multiple Semantic Label Representations
neurips,2018,0,2653,Yi,Xu,uiowa,The University of Iowa,yi-xu@uiowa.edu,First-order Stochastic Algorithms for Escaping From Saddle Points in Almost Linear Time
neurips,2018,1,2653,Rong,Jin,uiowa,Alibaba,tianbao-yang@uiowa.edu,First-order Stochastic Algorithms for Escaping From Saddle Points in Almost Linear Time
neurips,2018,2,2653,Tianbao,Yang,alibaba-inc,The University of Iowa,jinrong.jr@alibaba-inc.com,First-order Stochastic Algorithms for Escaping From Saddle Points in Almost Linear Time
neurips,2018,0,3751,Naman,Agarwal,google,princeton,namanagarwal@google.com,cpSGD: Communication-efficient and differentially-private distributed SGD
neurips,2018,1,3751,Ananda Theertha,Suresh,google,Google,theertha@google.com,cpSGD: Communication-efficient and differentially-private distributed SGD
neurips,2018,2,3751,Felix Xinnan,Yu,google,Google Research,felixyu@google.com,cpSGD: Communication-efficient and differentially-private distributed SGD
neurips,2018,3,3751,Sanjiv,Kumar,google,Google Research,sanjivk@google.com,cpSGD: Communication-efficient and differentially-private distributed SGD
neurips,2018,4,3751,Brendan,McMahan,google,Google,mcmahan@google.com,cpSGD: Communication-efficient and differentially-private distributed SGD
neurips,2018,0,1491,Julian,Zimmert,ku,University of Copenhagen,zimmert@di.ku.dk,Factored Bandits
neurips,2018,1,1491,Yevgeny,Seldin,ku,University of Copenhagen,seldin@di.ku.dk,Factored Bandits
neurips,2018,0,3010,Ali,Shafahi,,University of Maryland,,Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks
neurips,2018,1,3010,W. Ronny,Huang,,UMCP and EY,,Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks
neurips,2018,2,3010,Mahyar,Najibi,,University of Maryland,,Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks
neurips,2018,3,3010,Octavian,Suciu,,University of Maryland,,Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks
neurips,2018,4,3010,Christoph,Studer,,Cornell University,,Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks
neurips,2018,5,3010,Tudor,Dumitras,,University of Maryland,,Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks
neurips,2018,6,3010,Tom,Goldstein,,University of Maryland,,Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks
neurips,2018,0,3602,Onur,Teymur,,Imperial College London,,Implicit Probabilistic Integrators for ODEs
neurips,2018,1,3602,Han Cheng,Lie,,Freie Universität Berlin,,Implicit Probabilistic Integrators for ODEs
neurips,2018,2,3602,Tim,Sullivan,,Free University of Berlin,,Implicit Probabilistic Integrators for ODEs
neurips,2018,3,3602,Ben,Calderhead,,Imperial College,,Implicit Probabilistic Integrators for ODEs
neurips,2018,0,2294,Stanislav,Morozov,yandex,Yandex,stanis-morozov@yandex.ru,Non-metric Similarity Graphs for Maximum Inner Product Search
neurips,2018,1,2294,Artem,Babenko,phystech,MIPT/Yandex,artem.babenko@phystech.edu,Non-metric Similarity Graphs for Maximum Inner Product Search
neurips,2018,0,2743,Lee-Ad,Gottlieb,ariel,Ariel University,leead@ariel.ac.il,Learning convex polytopes with margin
neurips,2018,1,2743,Eran,Kaufman,gmail,Ariel University,erankfmn@gmail.com,Learning convex polytopes with margin
neurips,2018,2,2743,Aryeh,Kontorovich,sc,Ben Gurion University,karyeh@bgu.sc.il,Learning convex polytopes with margin
neurips,2018,3,2743,Gabriel,Nivasch,ariel,Ariel University,gabrieln@ariel.ac.il,Learning convex polytopes with margin
neurips,2018,0,870,Hongteng,Xu,,Infinia ML,,Distilled Wasserstein Learning for Word Embedding and Topic Modeling
neurips,2018,1,870,Wenlin,Wang,,Duke University,,Distilled Wasserstein Learning for Word Embedding and Topic Modeling
neurips,2018,2,870,Wei,Liu,,Tencent AI Lab,,Distilled Wasserstein Learning for Word Embedding and Topic Modeling
neurips,2018,3,870,Lawrence,Carin,,Duke University,,Distilled Wasserstein Learning for Word Embedding and Topic Modeling
neurips,2018,0,5377,Rico,Angell,umass,University of Massachusetts,rangell@cs.umass.edu,Inferring Latent Velocities from Weather Radar Data using Gaussian Processes
neurips,2018,1,5377,Daniel,Sheldon,umass,University of Massachusetts Amherst,sheldon@cs.umass.edu,Inferring Latent Velocities from Weather Radar Data using Gaussian Processes
neurips,2018,0,916,Yizhe,Zhang,microsoft,Microsoft Research,yizzhang@microsoft.com,Generating Informative and Diverse Conversational Responses via Adversarial Information Maximization
neurips,2018,1,916,Michel,Galley,microsoft,Microsoft Research,mgalley@microsoft.com,Generating Informative and Diverse Conversational Responses via Adversarial Information Maximization
neurips,2018,2,916,Jianfeng,Gao,microsoft,"Microsoft Research, Redmond, WA",jfgao@microsoft.com,Generating Informative and Diverse Conversational Responses via Adversarial Information Maximization
neurips,2018,3,916,Zhe,Gan,microsoft,Microsoft,zhgan@microsoft.com,Generating Informative and Diverse Conversational Responses via Adversarial Information Maximization
neurips,2018,4,916,Xiujun,Li,microsoft,Microsoft Research Redmond,xiul@microsoft.com,Generating Informative and Diverse Conversational Responses via Adversarial Information Maximization
neurips,2018,5,916,Chris,Brockett,microsoft,Microsoft Research AI,chrisbkt@microsoft.com,Generating Informative and Diverse Conversational Responses via Adversarial Information Maximization
neurips,2018,6,916,Bill,Dolan,microsoft,Microsoft,billdol@microsoft.com,Generating Informative and Diverse Conversational Responses via Adversarial Information Maximization
neurips,2018,0,3717,Jiaming,Song,stanford,Stanford University,tsong@cs.stanford.edu,Multi-Agent Generative Adversarial Imitation Learning
neurips,2018,1,3717,Hongyu,Ren,stanford,Stanford University,hyren@cs.stanford.edu,Multi-Agent Generative Adversarial Imitation Learning
neurips,2018,2,3717,Dorsa,Sadigh,stanford,Stanford,dorsa@cs.stanford.edu,Multi-Agent Generative Adversarial Imitation Learning
neurips,2018,3,3717,Stefano,Ermon,stanford,Stanford,ermon@cs.stanford.edu,Multi-Agent Generative Adversarial Imitation Learning
neurips,2018,0,1026,Supasorn,Suwajanakorn,vistec,VISTEC,supasorn@vistec.ac.th,Discovery of Latent 3D Keypoints via End-to-end Geometric Reasoning
neurips,2018,1,1026,Noah,Snavely,google,Google,snavely@google.com,Discovery of Latent 3D Keypoints via End-to-end Geometric Reasoning
neurips,2018,2,1026,Jonathan,Tompson,google,Google Brain,tompson@google.com,Discovery of Latent 3D Keypoints via End-to-end Geometric Reasoning
neurips,2018,3,1026,Mohammad,Norouzi,google,Google Brain,mnorouzi@google.com,Discovery of Latent 3D Keypoints via End-to-end Geometric Reasoning
neurips,2018,0,2992,Ho Chung,Law,,University of Oxford,,Variational Learning on Aggregate Outputs with Gaussian Processes
neurips,2018,1,2992,Dino,Sejdinovic,,University of Oxford,,Variational Learning on Aggregate Outputs with Gaussian Processes
neurips,2018,2,2992,Ewan,Cameron,,,,Variational Learning on Aggregate Outputs with Gaussian Processes
neurips,2018,3,2992,Tim,Lucas,,University of Oxford,,Variational Learning on Aggregate Outputs with Gaussian Processes
neurips,2018,4,2992,Seth,Flaxman,,Imperial College London,,Variational Learning on Aggregate Outputs with Gaussian Processes
neurips,2018,5,2992,Katherine,Battle,,University of Oxford,,Variational Learning on Aggregate Outputs with Gaussian Processes
neurips,2018,6,2992,Kenji,Fukumizu,,Institute of Statistical Mathematics,,Variational Learning on Aggregate Outputs with Gaussian Processes
neurips,2018,0,1521,Tobias Sommer,Thune,,University of Copenhagen,,Adaptation to Easy Data in Prediction with Limited Advice
neurips,2018,1,1521,Yevgeny,Seldin,,University of Copenhagen,,Adaptation to Easy Data in Prediction with Limited Advice
neurips,2018,0,2167,Kyungjae,Lee,snu,Seoul National University,kyungjae.lee@rllab.snu.ac.kr,Maximum Causal Tsallis Entropy Imitation Learning
neurips,2018,1,2167,Sungjoon,Choi,kakaobrain,Disney Research,sam.choi@kakaobrain.com,Maximum Causal Tsallis Entropy Imitation Learning
neurips,2018,2,2167,Songhwai,Oh,snu,Seoul National University,songhwai@snu.ac.kr,Maximum Causal Tsallis Entropy Imitation Learning
neurips,2018,0,2196,Justin,Domke,,"University of Massachusetts, Amherst",,Importance Weighting and Variational Inference
neurips,2018,1,2196,Daniel,Sheldon,,University of Massachusetts Amherst,,Importance Weighting and Variational Inference
neurips,2018,0,3585,Roei,Herzig,tau,Tel Aviv University,roeiherzig@mail.tau.ac.il,Mapping Images to Scene Graphs with Permutation-Invariant Structured Prediction
neurips,2018,1,3585,Moshiko,Raboh,biu,Tel Aviv University,gal.chechik@biu.ac.il,Mapping Images to Scene Graphs with Permutation-Invariant Structured Prediction
neurips,2018,2,3585,Gal,Chechik,tau,"Google, BIU",mosheraboh@mail.tau.ac.il,Mapping Images to Scene Graphs with Permutation-Invariant Structured Prediction
neurips,2018,3,3585,Jonathan,Berant,tau,Tel Aviv University,joberant@cs.tau.ac.il,Mapping Images to Scene Graphs with Permutation-Invariant Structured Prediction
neurips,2018,4,3585,Amir,Globerson,tau,"Tel Aviv University, Google",gamir@post.tau.ac.il,Mapping Images to Scene Graphs with Permutation-Invariant Structured Prediction
neurips,2018,0,298,Ohad,Shamir,weizmann,Weizmann Institute of Science,ohad.shamir@weizmann.ac.il,Are ResNets Provably Better than Linear Predictors?
neurips,2018,0,1219,Zhongwen,Xu,google,DeepMind,zhongwen@google.com,Meta-Gradient Reinforcement Learning
neurips,2018,1,1219,Hado,van Hasselt,google,DeepMind,hado@google.com,Meta-Gradient Reinforcement Learning
neurips,2018,2,1219,David,Silver,google,DeepMind,davidsilver@google.com,Meta-Gradient Reinforcement Learning
neurips,2018,0,3760,Jacob,Gardner,,Cornell University,,GPyTorch: Blackbox Matrix-Matrix Gaussian Process Inference with GPU Acceleration
neurips,2018,1,3760,Geoff,Pleiss,,Cornell University,,GPyTorch: Blackbox Matrix-Matrix Gaussian Process Inference with GPU Acceleration
neurips,2018,2,3760,Kilian,Weinberger,,Cornell University,,GPyTorch: Blackbox Matrix-Matrix Gaussian Process Inference with GPU Acceleration
neurips,2018,3,3760,David,Bindel,,Cornell University,,GPyTorch: Blackbox Matrix-Matrix Gaussian Process Inference with GPU Acceleration
neurips,2018,4,3760,Andrew,Wilson,,Cornell University,,GPyTorch: Blackbox Matrix-Matrix Gaussian Process Inference with GPU Acceleration
neurips,2018,0,4946,Brandon,Tran,mit,Massachusetts Institute of Technology,btran@mit.edu,Spectral Signatures in Backdoor Attacks
neurips,2018,1,4946,Jerry,Li,berkeley,Berkeley,jerryzli@berkeley.edu,Spectral Signatures in Backdoor Attacks
neurips,2018,2,4946,Aleksander,Madry,mit,MIT,madry@mit.edu,Spectral Signatures in Backdoor Attacks
neurips,2018,0,503,Jay,Heo,kaist,UNIST,jayheo@kaist.ac.kr,Uncertainty-Aware Attention for Reliable Interpretation and Prediction
neurips,2018,1,503,Hae Beom,Lee,kaist,KAIST,haebeom.lee@kaist.ac.kr,Uncertainty-Aware Attention for Reliable Interpretation and Prediction
neurips,2018,2,503,Saehoon,Kim,kaist,AITRICS,sjhwang82@kaist.ac.kr,Uncertainty-Aware Attention for Reliable Interpretation and Prediction
neurips,2018,3,503,Juho,Lee,kaist,University of Oxford,eunhoy@kaist.ac.kr,Uncertainty-Aware Attention for Reliable Interpretation and Prediction
neurips,2018,4,503,Kwang Joon,Kim,aitrics,Yonsei University College of Medicine,shkim@aitrics.com,Uncertainty-Aware Attention for Reliable Interpretation and Prediction
neurips,2018,5,503,Eunho,Yang,yuhs,Korea Advanced Institute of Science and Technology; AItrics,preppie@yuhs.ac,Uncertainty-Aware Attention for Reliable Interpretation and Prediction
neurips,2018,6,503,Sung Ju,Hwang,ox,"KAIST, AItrics",juho.lee@stats.ox.ac.uk,Uncertainty-Aware Attention for Reliable Interpretation and Prediction
neurips,2018,0,981,Liang,Zhang,xidian,"School of Computer Science and Technology, Xidian University, China",liangzhang@xidian.edu.cn,Attention in Convolutional LSTM for Gesture Recognition
neurips,2018,1,981,Guangming,Zhu,xidian,Xidian University,gmzhu@xidian.edu.cn,Attention in Convolutional LSTM for Gesture Recognition
neurips,2018,2,981,Lin,Mei,hotmail,"The Third Research Institute of Ministry of Public Security, China",l_mei72@hotmail.com,Attention in Convolutional LSTM for Gesture Recognition
neurips,2018,3,981,Peiyi,Shen,xidian,"School of Software, Xidian University, China",pyshen@xidian.edu.cn,Attention in Convolutional LSTM for Gesture Recognition
neurips,2018,4,981,Syed Afaq Ali,Shah,uwa,"Department of Computer Science and Software Engineering, The University of Western Australia",afaq.shah@uwa.edu.au,Attention in Convolutional LSTM for Gesture Recognition
neurips,2018,5,981,Mohammed,Bennamoun,uwa,University of Western Australia,mohammed.bennamoun@uwa.edu.au,Attention in Convolutional LSTM for Gesture Recognition
neurips,2018,0,6843,Gabriel,Synnaeve,fb,Facebook,gab@fb.com,Forward Modeling for Partial Observation Strategy Games - A StarCraft Defogger
neurips,2018,1,6843,Zeming,Lin,fb,Facebook AI Research,zlin@fb.com,Forward Modeling for Partial Observation Strategy Games - A StarCraft Defogger
neurips,2018,2,6843,Jonas,Gehring,fb,Facebook AI Research,jgehring@fb.com,Forward Modeling for Partial Observation Strategy Games - A StarCraft Defogger
neurips,2018,3,6843,Dan,Gant,fb,Facebook AI Research,danielgant@fb.com,Forward Modeling for Partial Observation Strategy Games - A StarCraft Defogger
neurips,2018,4,6843,Vegard,Mella,fb,Facebook AI Research,vegardmella@fb.com,Forward Modeling for Partial Observation Strategy Games - A StarCraft Defogger
neurips,2018,5,6843,Vasil,Khalidov,fb,Facebook AI Research,vkhalidov@fb.com,Forward Modeling for Partial Observation Strategy Games - A StarCraft Defogger
neurips,2018,6,6843,Nicolas,Carion,fb,Facebook AI Research Paris,alcinos@fb.com,Forward Modeling for Partial Observation Strategy Games - A StarCraft Defogger
neurips,2018,7,6843,Nicolas,Usunier,fb,Facebook AI Research,usunier@fb.com,Forward Modeling for Partial Observation Strategy Games - A StarCraft Defogger
neurips,2018,0,769,Zinan,Lin,,Carnegie Mellon University,,PacGAN: The power of two samples in generative adversarial networks
neurips,2018,1,769,Ashish,Khetan,,Amazon AI Labs,,PacGAN: The power of two samples in generative adversarial networks
neurips,2018,2,769,Giulia,Fanti,,CMU,,PacGAN: The power of two samples in generative adversarial networks
neurips,2018,3,769,Sewoong,Oh,,University of Washington,,PacGAN: The power of two samples in generative adversarial networks
neurips,2018,0,5458,Ehsan,Hajiramezanali,tamu,Texas A&M University,ehsanr@tamu.edu,Bayesian multi-domain learning for cancer subtype discovery from next-generation sequencing count data
neurips,2018,1,5458,Siamak,Zamani Dadaneh,tamu,Texas A&M University,siamak@tamu.edu,Bayesian multi-domain learning for cancer subtype discovery from next-generation sequencing count data
neurips,2018,2,5458,Alireza,Karbalayghareh,utexas,Texas A&M University,Mingyuan.Zhou@mccombs.utexas.edu,Bayesian multi-domain learning for cancer subtype discovery from next-generation sequencing count data
neurips,2018,3,5458,Mingyuan,Zhou,tamu,University of Texas at Austin,alireza.kg@tamu.edu,Bayesian multi-domain learning for cancer subtype discovery from next-generation sequencing count data
neurips,2018,4,5458,Xiaoning,Qian,tamu,Texas A&M,xqian@ece.tamu.edu,Bayesian multi-domain learning for cancer subtype discovery from next-generation sequencing count data
neurips,2018,0,5230,Michelle,Yuan,umd,"University of Maryland, College Park",myuan@cs.umd.edu,Multilingual Anchoring: Interactive Topic Modeling and Alignment Across Languages
neurips,2018,1,5230,Benjamin,Van Durme,jhu,Johns Hopkins University,vandurme@jhu.edu,Multilingual Anchoring: Interactive Topic Modeling and Alignment Across Languages
neurips,2018,2,5230,Jordan,Ying,umd,University of Maryland,jbg@umiacs.umd.edu,Multilingual Anchoring: Interactive Topic Modeling and Alignment Across Languages
neurips,2018,0,77,Chaosheng,Dong,pitt,University of Pittsburgh,chaosheng@pitt.edu,Generalized Inverse Optimization through Online Learning
neurips,2018,1,77,Yiran,Chen,duke,Duke University,yiran.chen@duke.edu,Generalized Inverse Optimization through Online Learning
neurips,2018,2,77,Bo,Zeng,pitt,pitt,bzeng@pitt.edu,Generalized Inverse Optimization through Online Learning
neurips,2018,0,5780,Julius,Adebayo,mit,MIT,juliusad@mit.edu,Sanity Checks for Saliency Maps
neurips,2018,1,5780,Justin,Gilmer,google,Google Brain,gilmer@google.com,Sanity Checks for Saliency Maps
neurips,2018,2,5780,Michael,Muelly,google,Google,muelly@google.com,Sanity Checks for Saliency Maps
neurips,2018,3,5780,Ian,Goodfellow,google,Google,goodfellow@google.com,Sanity Checks for Saliency Maps
neurips,2018,4,5780,Moritz,Hardt,google,Google Brain,mrtz@google.com,Sanity Checks for Saliency Maps
neurips,2018,5,5780,Been,Kim,google,Google,beenkim@google.com,Sanity Checks for Saliency Maps
neurips,2018,0,2070,Jordan,Awan,psu,Penn State University,awan@psu.edu,Differentially Private Uniformly Most Powerful Tests for Binomial Data
neurips,2018,1,2070,Aleksandra,Slavkovi,psu,Pennsylvania State University,sesa@psu.edu,Differentially Private Uniformly Most Powerful Tests for Binomial Data
neurips,2018,0,3472,Markus,Kaiser,siemens,Technical University Munich,markus.kaiser@siemens.com,Bayesian Alignments of Warped Multi-Output Gaussian Processes
neurips,2018,1,3472,Clemens,Otte,siemens,Siemens,clemens.otte@siemens.com,Bayesian Alignments of Warped Multi-Output Gaussian Processes
neurips,2018,2,3472,Thomas,Runkler,siemens,Technical University of Munich,thomas.runkler@siemens.com,Bayesian Alignments of Warped Multi-Output Gaussian Processes
neurips,2018,3,3472,Carl Henrik,Ek,bristol,University of Bristol,carlhenrik.ek@bristol.ac.uk,Bayesian Alignments of Warped Multi-Output Gaussian Processes
neurips,2018,0,6968,Aditi,Raghunathan,stanford,Stanford University,aditir@cs.stanford.edu,Semidefinite relaxations for certifying robustness to adversarial examples
neurips,2018,1,6968,Jacob,Steinhardt,stanford,UC Berkeley,jsteinhardt@cs.stanford.edu,Semidefinite relaxations for certifying robustness to adversarial examples
neurips,2018,2,6968,Percy,Liang,stanford,Stanford University,pliang@cs.stanford.edu,Semidefinite relaxations for certifying robustness to adversarial examples
neurips,2018,0,5220,Craig,Greenberg,umass,University of Massachusetts Amherst / NIST,csgreenberg@cs.umass.edu,Compact Representation of Uncertainty in Clustering
neurips,2018,1,5220,Nicholas,Monath,umass,University of Massachusetts Amherst,nmonath@cs.umass.edu,Compact Representation of Uncertainty in Clustering
neurips,2018,2,5220,Ari,Kobren,umass,UMass Amherst,akobren@cs.umass.edu,Compact Representation of Uncertainty in Clustering
neurips,2018,3,5220,Patrick,Flaherty,umass,"University of Massachusetts, Amherst",mcgregor@cs.umass.edu,Compact Representation of Uncertainty in Clustering
neurips,2018,4,5220,Andrew,McGregor,umass,University of Massachusetts Amherst,mccallum@cs.umass.edu,Compact Representation of Uncertainty in Clustering
neurips,2018,5,5220,Andrew,McCallum,umass,UMass Amherst,flaherty@math.umass.edu,Compact Representation of Uncertainty in Clustering
neurips,2018,0,5240,Yang,Lu,uw,University of Washington,ylu465@uw.edu,DeepPINK: reproducible feature selection in deep neural networks
neurips,2018,1,5240,Yingying,Fan,usc,University of Southern California,fanyingy@marshall.usc.edu,DeepPINK: reproducible feature selection in deep neural networks
neurips,2018,2,5240,Jinchi,Lv,usc,University of Southern California,jinchilv@marshall.usc.edu,DeepPINK: reproducible feature selection in deep neural networks
neurips,2018,3,5240,William,Stafford Noble,uw,University of Washington,william-noble@uw.edu,DeepPINK: reproducible feature selection in deep neural networks
neurips,2018,0,88,Lei,Le,iu,Indiana University Bloomington,leile@iu.edu,Supervised autoencoders: Improving generalization performance with unsupervised regularizers
neurips,2018,1,88,Andrew,Patterson,ualberta,University of Alberta,ap3@ualberta.ca,Supervised autoencoders: Improving generalization performance with unsupervised regularizers
neurips,2018,2,88,Martha,White,ualberta,University of Alberta,whitem@ualberta.ca,Supervised autoencoders: Improving generalization performance with unsupervised regularizers
neurips,2018,0,6781,Yilin,Zhang,wisc,University of Wisconsin-Madison,yilin.zhang@wisc.edu,Understanding Regularized Spectral Clustering via Graph Conductance
neurips,2018,1,6781,Karl,Rohe,wisc,UW-Madison,karl.rohe@wisc.edu,Understanding Regularized Spectral Clustering via Graph Conductance
neurips,2018,0,3707,Alyson,Fletcher,ucla,UCLA,akfletcher@ucla.edu,Plug-in Estimation in High-Dimensional Linear Inverse Problems: A Rigorous Analysis
neurips,2018,1,3707,Parthe,Pandit,ucla,UCLA,parthepandit@ucla.edu,Plug-in Estimation in High-Dimensional Linear Inverse Problems: A Rigorous Analysis
neurips,2018,2,3707,Sundeep,Rangan,nyu,NYU,srangan@nyu.edu,Plug-in Estimation in High-Dimensional Linear Inverse Problems: A Rigorous Analysis
neurips,2018,3,3707,Subrata,Sarkar,osu,The Ohio State University,sarkar.51@osu.edu,Plug-in Estimation in High-Dimensional Linear Inverse Problems: A Rigorous Analysis
neurips,2018,4,3707,Philip,Schniter,osu,The Ohio State University,schniter.1@osu.edu,Plug-in Estimation in High-Dimensional Linear Inverse Problems: A Rigorous Analysis
neurips,2018,0,719,Alexis,Bellot,ox,University of Oxford,alexis.bellot@eng.ox.ac.uk,Multitask Boosting for Survival Analysis with Competing Risks
neurips,2018,1,719,Mihaela,van der Schaar,turing,University of Oxford,mschaar@turing.ac.uk,Multitask Boosting for Survival Analysis with Competing Risks
neurips,2018,0,5603,Jeremy,Morton,stanford,Stanford University,jmorton2@stanford.edu,Deep Dynamical Modeling and Control of Unsteady Fluid Flows
neurips,2018,1,5603,Antony,Jameson,stanford,Texas A&M University,fdw@stanford.edu,Deep Dynamical Modeling and Control of Unsteady Fluid Flows
neurips,2018,2,5603,Mykel,Kochenderfer,tamu,Stanford University,antony.jameson@tamu.edu,Deep Dynamical Modeling and Control of Unsteady Fluid Flows
neurips,2018,3,5603,Freddie,Witherden,stanford,Imperial College London,mykel@stanford.edu,Deep Dynamical Modeling and Control of Unsteady Fluid Flows
neurips,2018,0,145,Karl,Ridgeway,colorado,"University of Colorado, Boulder",mozer@colorado.edu,Learning Deep Disentangled Embeddings With the F-Statistic Loss
neurips,2018,1,145,Michael,Mozer,colorado,Google Brain / U. Colorado,karl.ridgeway@colorado.edu,Learning Deep Disentangled Embeddings With the F-Statistic Loss
neurips,2018,0,3662,Mahyar,Khayatkhoei,rutgers,Rutgers University,m.khayatkhoei@cs.rutgers.edu,Disconnected Manifold Learning for Generative Adversarial Networks
neurips,2018,1,3662,Maneesh,Singh,rutgers,Verisk Analytics,elgammal@cs.rutgers.edu,Disconnected Manifold Learning for Generative Adversarial Networks
neurips,2018,2,3662,Ahmed,Elgammal,verisk,Rutgers University,maneesh.singh@verisk.com,Disconnected Manifold Learning for Generative Adversarial Networks
neurips,2018,0,2927,Gustavo,Malkomes,wustl,Washington University in St. Louis,luizgustavo@wustl.edu,Automating Bayesian optimization with Bayesian optimization
neurips,2018,1,2927,Roman,Garnett,wustl,Washington University in St. Louis,garnett@wustl.edu,Automating Bayesian optimization with Bayesian optimization
neurips,2018,0,1249,Michal,Derezinski,berkeley,UC Berkeley,mderezin@berkeley.edu,Leveraged volume sampling for linear regression
neurips,2018,1,1249,Manfred K.,Warmuth,ucsc,Univ. of Calif. at Santa Cruz,manfred@ucsc.edu,Leveraged volume sampling for linear regression
neurips,2018,2,1249,Daniel,Hsu,columbia,Columbia University,djhsu@cs.columbia.edu,Leveraged volume sampling for linear regression
neurips,2018,0,2447,Quanming,Yao,4paradigm,4Paradigm,yaoquanming@4paradigm.com,Scalable Robust Matrix Factorization with Nonconvex Loss
neurips,2018,1,2447,James,Kwok,ust,Hong Kong University of Science and Technology,jamesk@cse.ust.hk,Scalable Robust Matrix Factorization with Nonconvex Loss
neurips,2018,0,4965,Youjie,Li,,UIUC,,Pipe-SGD: A Decentralized Pipelined SGD Framework for Distributed Deep Net Training
neurips,2018,1,4965,Mingchao,Yu,,University of Southern California,,Pipe-SGD: A Decentralized Pipelined SGD Framework for Distributed Deep Net Training
neurips,2018,2,4965,Songze,Li,,University of Southern California,,Pipe-SGD: A Decentralized Pipelined SGD Framework for Distributed Deep Net Training
neurips,2018,3,4965,Salman,Avestimehr,,University of Southern California,,Pipe-SGD: A Decentralized Pipelined SGD Framework for Distributed Deep Net Training
neurips,2018,4,4965,Nam Sung,Kim,,University of Illinois at Urbana-Champaign,,Pipe-SGD: A Decentralized Pipelined SGD Framework for Distributed Deep Net Training
neurips,2018,5,4965,Alexander,Schwing,,University of Illinois at Urbana-Champaign,,Pipe-SGD: A Decentralized Pipelined SGD Framework for Distributed Deep Net Training
neurips,2018,0,1244,Luca,Ambrogioni,donders,Donders Institute,l.ambrogioni@donders.ru.nl,Wasserstein Variational Inference
neurips,2018,1,1244,Umut,Güçlü,donders,"Donders Institute for Brain, Cognition and Behaviour, Radboud University",u.guclu@donders.ru.nl,Wasserstein Variational Inference
neurips,2018,2,1244,Yamur,Güçlütürk,donders,"Donders Institute for Brain, Cognition and Behaviour, Radboud University",y.gucluturk@donders.ru.nl,Wasserstein Variational Inference
neurips,2018,3,1244,Max,Hinne,uva,University of Amsterdam,m.hinne@uva.nl,Wasserstein Variational Inference
neurips,2018,4,1244,Marcel,van Gerven,donders,Radboud Universiteit,e.maris@donders.ru.nl,Wasserstein Variational Inference
neurips,2018,5,1244,Eric,Maris,donders,Donders Institute,m.vangerven@donders.ru.nl,Wasserstein Variational Inference
neurips,2018,0,4998,Mahdi,Imani,tamu,Texas A&M University,m.imani88@tamu.edu,Bayesian Control of Large MDPs with Unknown Dynamics in Data-Poor Environments
neurips,2018,1,4998,Seyede Fatemeh,Ghoreishi,tamu,Texas A&M University,f.ghoreishi88@tamu.edu,Bayesian Control of Large MDPs with Unknown Dynamics in Data-Poor Environments
neurips,2018,2,4998,Ulisses M.,Braga-Neto,tamu,Texas A&M University,ulisses@ece.tamu.edu,Bayesian Control of Large MDPs with Unknown Dynamics in Data-Poor Environments
neurips,2018,0,1123,Sampath,Kannan,,University of Pennsylvania,,A Smoothed Analysis of the Greedy Algorithm for the Linear Contextual Bandit Problem
neurips,2018,1,1123,Jamie,Morgenstern,,Georgia Tech,,A Smoothed Analysis of the Greedy Algorithm for the Linear Contextual Bandit Problem
neurips,2018,2,1123,Aaron,Roth,,University of Pennsylvania,,A Smoothed Analysis of the Greedy Algorithm for the Linear Contextual Bandit Problem
neurips,2018,3,1123,Bo,Waggoner,,Microsoft,,A Smoothed Analysis of the Greedy Algorithm for the Linear Contextual Bandit Problem
neurips,2018,4,1123,Zhiwei  Steven,Wu,,University of Minnesota,,A Smoothed Analysis of the Greedy Algorithm for the Linear Contextual Bandit Problem
neurips,2018,0,2203,Jorge,Mendez,upenn,University of Pennsylvania,mendezme@seas.upenn.edu,Lifelong Inverse Reinforcement Learning
neurips,2018,1,2203,Shashank,Shivkumar,upenn,University of Pennsylvania,shashs@seas.upenn.edu,Lifelong Inverse Reinforcement Learning
neurips,2018,2,2203,Eric,Eaton,upenn,University of Pennsylvania,eeaton@seas.upenn.edu,Lifelong Inverse Reinforcement Learning
neurips,2018,0,1242,David,Ha,google,Google Brain,hadavid@google.com,Recurrent World Models Facilitate Policy Evolution
neurips,2018,1,1242,Jürgen,Schmidhuber,idsia,"Swiss AI Lab, IDSIA (USI & SUPSI) - NNAISENSE",juergen@idsia.ch,Recurrent World Models Facilitate Policy Evolution
neurips,2018,0,5034,Judy,Hoffman,berkeley,FAIR and Georgia Tech,jhoffman@eecs.berkeley.edu,Algorithms and Theory for Multiple-Source Adaptation
neurips,2018,1,5034,Mehryar,Mohri,nyu,Courant Inst. of Math. Sciences & Google Research,mohri@cims.nyu.edu,Algorithms and Theory for Multiple-Source Adaptation
neurips,2018,2,5034,Ningshan,Zhang,nyu,NYU,nzhang@stern.nyu.edu,Algorithms and Theory for Multiple-Source Adaptation
neurips,2018,0,5077,Avrim,Blum,ttic,Toyota Technological Institute at Chicago,avrim@ttic.edu,On preserving non-discrimination when combining expert advice
neurips,2018,1,5077,Suriya,Gunasekar,ttic,TTI Chicago,suriya@ttic.edu,On preserving non-discrimination when combining expert advice
neurips,2018,2,5077,Thodoris,Lykouris,cornell,Cornell University,teddlyk@cs.cornell.edu,On preserving non-discrimination when combining expert advice
neurips,2018,3,5077,Nati,Srebro,ttic,TTI-Chicago,nati@ttic.edu,On preserving non-discrimination when combining expert advice
neurips,2018,0,5189,Jeffrey,Chan,berkeley,UC Berkeley,chanjed@berkeley.edu,A Likelihood-Free Inference Framework for Population Genetic Data using Exchangeable Neural Networks
neurips,2018,1,5189,Valerio,Perrone,berkeley,University of Warwick,spence.jeffrey@berkeley.edu,A Likelihood-Free Inference Framework for Population Genetic Data using Exchangeable Neural Networks
neurips,2018,2,5189,Jeffrey,Spence,swarthmore,UC Berkeley,smathie1@swarthmore.edu,A Likelihood-Free Inference Framework for Population Genetic Data using Exchangeable Neural Networks
neurips,2018,3,5189,Paul,Jenkins,warwick,University of Warwick,v.perrone@warwick.ac.uk,A Likelihood-Free Inference Framework for Population Genetic Data using Exchangeable Neural Networks
neurips,2018,4,5189,Sara,Mathieson,warwick,Swarthmore College,p.jenkins@warwick.ac.uk,A Likelihood-Free Inference Framework for Population Genetic Data using Exchangeable Neural Networks
neurips,2018,5,5189,Yun,Song,berkeley,UC Berkeley,yss@berkeley.edu,A Likelihood-Free Inference Framework for Population Genetic Data using Exchangeable Neural Networks
neurips,2018,0,2059,Jalaj,Upadhyay,jhu,Johns Hopkins University,jalaj@jhu.edu,The Price of Privacy for Low-rank Factorization
neurips,2018,0,3136,Shiqi,Wang,columbia,Columbia University,tcwangshiqi@cs.columbia.edu,Efficient Formal Safety Analysis of Neural Networks
neurips,2018,1,3136,Kexin,Pei,columbia,Columbia University,kpei@cs.columbia.edu,Efficient Formal Safety Analysis of Neural Networks
neurips,2018,2,3136,Justin,Whitehouse,columbia,Columbia University,jaw2228@cs.columbia.edu,Efficient Formal Safety Analysis of Neural Networks
neurips,2018,3,3136,Junfeng,Yang,columbia,Columbia University,junfeng@cs.columbia.edu,Efficient Formal Safety Analysis of Neural Networks
neurips,2018,4,3136,Suman,Jana,columbia,Columbia University,suman@cs.columbia.edu,Efficient Formal Safety Analysis of Neural Networks
neurips,2018,0,1872,Jeremy,Hoskins,yale,Yale University,jeremy.hoskins@yale.edu,Inferring Networks From Random Walk-Based Node Similarities
neurips,2018,1,1872,Cameron,Musco,princeton,Massachusetts Institute of Technology,cmusco@cs.princeton.edu,Inferring Networks From Random Walk-Based Node Similarities
neurips,2018,2,1872,Christopher,Musco,microsoft,Mass. Institute of Technology,camusco@microsoft.com,Inferring Networks From Random Walk-Based Node Similarities
neurips,2018,3,1872,Babis,Tsourakakis,bu,Boston University,ctsourak@bu.edu,Inferring Networks From Random Walk-Based Node Similarities
neurips,2018,0,658,Junnan,Li,nus,National University of Singapore,lijunnan@u.nus.edu,Unsupervised Learning of View-invariant Action Representations
neurips,2018,1,658,Yongkang,Wong,nus,National University of Singapore,yongkang.wong@nus.edu.sg,Unsupervised Learning of View-invariant Action Representations
neurips,2018,2,658,Qi,Zhao,umn,University of Minnesota,qzhao@cs.umn.edu,Unsupervised Learning of View-invariant Action Representations
neurips,2018,3,658,Mohan,Kankanhalli,nus,"National University of Singapore,",mohan@comp.nus.edu.sg,Unsupervised Learning of View-invariant Action Representations
neurips,2018,0,3411,Yitong,Li,,Duke University,,Extracting Relationships by Multi-Domain Matching
neurips,2018,1,3411,michael,Murias,,Duke University,,Extracting Relationships by Multi-Domain Matching
neurips,2018,2,3411,geraldine,Dawson,,Duke University,,Extracting Relationships by Multi-Domain Matching
neurips,2018,3,3411,David,Carlson,,Duke University,,Extracting Relationships by Multi-Domain Matching
neurips,2018,0,4880,Shi,Li,buffalo,University at Buffalo,xiangyug@buffalo.edu,Distributed $k$-Clustering for Data with Heavy Noise
neurips,2018,1,4880,Xiangyu,Guo,buffalo,State University of New York at Buffalo,shil@buffalo.edu,Distributed $k$-Clustering for Data with Heavy Noise
neurips,2018,0,2367,Xin,Zhang,mit,Massachusetts Institute of Technology,xzhang@csail.mit.edu,"Interpreting Neural Network Judgments via Minimal, Stable, and Symbolic Corrections"
neurips,2018,1,2367,Armando,Solar-Lezama,mit,MIT,asolar@csail.mit.edu,"Interpreting Neural Network Judgments via Minimal, Stable, and Symbolic Corrections"
neurips,2018,2,2367,Rishabh,Singh,google,Google Brain,rising@google.com,"Interpreting Neural Network Judgments via Minimal, Stable, and Symbolic Corrections"
neurips,2018,0,2854,Tianyi,Zhou,uw,"University of Washington, Seattle",tianyizh@uw.edu,Diverse Ensemble Evolution: Curriculum Data-Model Marriage
neurips,2018,1,2854,Shengjie,Wang,uw,"""University of Washington, Seattle""",wangsj@uw.edu,Diverse Ensemble Evolution: Curriculum Data-Model Marriage
neurips,2018,2,2854,Jeff,Bilmes,uw,"University of Washington, Seattle",bilmes@uw.edu,Diverse Ensemble Evolution: Curriculum Data-Model Marriage
neurips,2018,0,1596,Devavrat,Shah,mit,Massachusetts Institute of Technology,qxie@mit.edu,Q-learning with Nearest Neighbors
neurips,2018,1,1596,Qiaomin,Xie,mit,Massachusetts Institute of Technology,devavrat@mit.edu,Q-learning with Nearest Neighbors
neurips,2018,0,1229,Louis,Kirsch,louiskirsch,University College London & IDSIA,mail@louiskirsch.com,Modular Networks: Learning to Decompose Neural Computation
neurips,2018,1,1229,Julius,Kunze,gmail,University College London,juliuskunze@gmail.com,Modular Networks: Learning to Decompose Neural Computation
neurips,2018,2,1229,David,Barber,ucl,University College London,david.barber@ucl.ac.uk,Modular Networks: Learning to Decompose Neural Computation
neurips,2018,0,2905,Dan,Alistarh,ist,IST Austria,dan.alistarh@ist.ac.at,The Convergence of Sparsified Gradient Methods
neurips,2018,1,2905,Torsten,Hoefler,ethz,ETH Zürich,htor@inf.ethz.ch,The Convergence of Sparsified Gradient Methods
neurips,2018,2,2905,Mikael,Johansson,kth,KTH - Royal Institute of Technology,mikaelj@kth.se,The Convergence of Sparsified Gradient Methods
neurips,2018,3,2905,Nikola,Konstantinov,kth,IST Austria,sarit@kth.se,The Convergence of Sparsified Gradient Methods
neurips,2018,4,2905,Sarit,Khirirat,ist,KTH Royal Institute of Technology,nikola.konstantinov@ist.ac.at,The Convergence of Sparsified Gradient Methods
neurips,2018,5,2905,Cedric,Renggli,ethz,ETH Zurich,cedric.renggli@inf.ethz.ch,The Convergence of Sparsified Gradient Methods
neurips,2018,0,5743,Hyeji,Kim,,Samsung AI Center Cambridge,,Deepcode: Feedback Codes via Deep Learning
neurips,2018,1,5743,Yihan,Jiang,,University of Washington Seattle,,Deepcode: Feedback Codes via Deep Learning
neurips,2018,2,5743,Sreeram,Kannan,,University of Washington,,Deepcode: Feedback Codes via Deep Learning
neurips,2018,3,5743,Sewoong,Oh,,University of Washington,,Deepcode: Feedback Codes via Deep Learning
neurips,2018,4,5743,Pramod,Viswanath,,UIUC,,Deepcode: Feedback Codes via Deep Learning
neurips,2018,0,187,Chenfei,Wu,bupt,Beijing University of Posts and Telecommunications,wuchenfei@bupt.edu.cn,Chain of Reasoning for Visual Question Answering
neurips,2018,1,187,Jinlai,Liu,bupt,Beijing University of Posts and Telecommunications,liujinlai@bupt.edu.cn,Chain of Reasoning for Visual Question Answering
neurips,2018,2,187,Xiaojie,Wang,bupt,Beijing University of Posts and Telecommunications,xjwang@bupt.edu.cn,Chain of Reasoning for Visual Question Answering
neurips,2018,3,187,Xuan,Dong,bupt,Beijing University of Posts and Telecommunications,dongxuan8811@bupt.edu.cn,Chain of Reasoning for Visual Question Answering
neurips,2018,0,5004,Anthony,Caterini,ox,University of Oxford,anthony.caterini@stats.ox.ac.uk,Hamiltonian Variational Auto-Encoder
neurips,2018,1,5004,Arnaud,Doucet,ox,Oxford,doucet@stats.ox.ac.uk,Hamiltonian Variational Auto-Encoder
neurips,2018,2,5004,Dino,Sejdinovic,ox,University of Oxford,dino.sejdinovic@stats.ox.ac.uk,Hamiltonian Variational Auto-Encoder
neurips,2018,0,3468,Ming,Pang,nju,Nanjing University,pangm@lamda.nju.edu.cn,Unorganized Malicious Attacks Detection
neurips,2018,1,3468,Wei,Gao,nju,Nanjing University,gaow@lamda.nju.edu.cn,Unorganized Malicious Attacks Detection
neurips,2018,2,3468,Min,Tao,nju,Nanjing University,zhouzh@lamda.nju.edu.cn,Unorganized Malicious Attacks Detection
neurips,2018,3,3468,Zhi-Hua,Zhou,nju,Nanjing University,taom@nju.edu.cn,Unorganized Malicious Attacks Detection
neurips,2018,0,2600,Uri,Stemmer,,Ben-Gurion University,,Differentially Private k-Means with Constant Multiplicative Error
neurips,2018,1,2600,Haim,Kaplan,,,,Differentially Private k-Means with Constant Multiplicative Error
neurips,2018,0,6913,Tong,Wang,uiowa,University of Iowa,tong-wang@uiowa.edu,Multi-value Rule Sets for Interpretable Classification with Feature-Efficient Representations
neurips,2018,0,3406,Ming,Yu,,"The University of Chicago, Booth School of Business",,Provable Gaussian Embedding with One Observation
neurips,2018,1,3406,Zhuoran,Yang,,Princeton University,,Provable Gaussian Embedding with One Observation
neurips,2018,2,3406,Tuo,Zhao,,Gatech,,Provable Gaussian Embedding with One Observation
neurips,2018,3,3406,Mladen,Kolar,,University of Chicago,,Provable Gaussian Embedding with One Observation
neurips,2018,4,3406,Zhaoran,Wang,,"Princeton, Phd student",,Provable Gaussian Embedding with One Observation
neurips,2018,0,3334,Jamie,Hayes,,University College London,,Contamination Attacks and Mitigation in Multi-Party Machine Learning
neurips,2018,1,3334,Olga,Ohrimenko,,Microsoft Research,,Contamination Attacks and Mitigation in Multi-Party Machine Learning
neurips,2018,0,685,Jianqiao,Wangni,upenn,University of Pennsylvania,wnjq@seas.upenn.edu,Gradient Sparsification for Communication-Efficient Distributed Optimization
neurips,2018,1,685,Jialei,Wang,twosigma,"Two Sigma Investments, University of Chicago",jialei.wang@twosigma.com,Gradient Sparsification for Communication-Efficient Distributed Optimization
neurips,2018,2,685,Ji,Liu,tongzhang-ml,"University of Rochester, Tencent AI lab",tongzhang@tongzhang-ml.org,Gradient Sparsification for Communication-Efficient Distributed Optimization
neurips,2018,3,685,Tong,Zhang,gmail,Tencent AI Lab,ji.liu.uwisc@gmail.com,Gradient Sparsification for Communication-Efficient Distributed Optimization
neurips,2018,0,5038,Nicolas,Brosse,polytechnique,"Ecole Polytechnique, Palaiseau, FRANCE",nicolas.brosse@polytechnique.edu,The promises and pitfalls of Stochastic Gradient Langevin Dynamics
neurips,2018,1,5038,Alain,Durmus,polytechnique,ENS,eric.moulines@polytechnique.edu,The promises and pitfalls of Stochastic Gradient Langevin Dynamics
neurips,2018,2,5038,Eric,Moulines,ens-cachan,Ecole Polytechnique,alain.durmus@cmla.ens-cachan.fr,The promises and pitfalls of Stochastic Gradient Langevin Dynamics
neurips,2018,0,3789,Naigang,Wang,ibm,IBM T. J. Watson Research Center,nwang@us.ibm.com,Training Deep Neural Networks with 8-bit Floating Point Numbers
neurips,2018,1,3789,Jungwook,Choi,ibm,IBM Research,choij@us.ibm.com,Training Deep Neural Networks with 8-bit Floating Point Numbers
neurips,2018,2,3789,Daniel,Brand,ibm,IBM Research,danbrand@us.ibm.com,Training Deep Neural Networks with 8-bit Floating Point Numbers
neurips,2018,3,3789,Chia-Yu,Chen,ibm,IBM research,cchen@us.ibm.com,Training Deep Neural Networks with 8-bit Floating Point Numbers
neurips,2018,4,3789,Kailash,Gopalakrishnan,ibm,IBM Research,kailash@us.ibm.com,Training Deep Neural Networks with 8-bit Floating Point Numbers
neurips,2018,0,6429,Hongyi,Wang,,University of Wisconsin-Madison,,ATOMO: Communication-efficient Learning via Atomic Sparsification
neurips,2018,1,6429,Scott,Sievert,,University of Wisconsin-Madison,,ATOMO: Communication-efficient Learning via Atomic Sparsification
neurips,2018,2,6429,Shengchao,Liu,,UW-Madison,,ATOMO: Communication-efficient Learning via Atomic Sparsification
neurips,2018,3,6429,Zachary,Charles,,University of Wisconsin-Madison,,ATOMO: Communication-efficient Learning via Atomic Sparsification
neurips,2018,4,6429,Dimitris,Papailiopoulos,,UW-Madison,,ATOMO: Communication-efficient Learning via Atomic Sparsification
neurips,2018,5,6429,Stephen,Wright,,UW-Madison,,ATOMO: Communication-efficient Learning via Atomic Sparsification
neurips,2018,0,3786,Noam,Brown,cmu,Carnegie Mellon University,noamb@cs.cmu.edu,Depth-Limited Solving for Imperfect-Information Games
neurips,2018,1,3786,Tuomas,Sandholm,cmu,Carnegie Mellon University,sandholm@cs.cmu.edu,Depth-Limited Solving for Imperfect-Information Games
neurips,2018,2,3786,Brandon,Amos,cmu,Carnegie Mellon University,bamos@cs.cmu.edu,Depth-Limited Solving for Imperfect-Information Games
neurips,2018,0,2490,Shoubo,Hu,cuhk,The Chinese University of Hong Kong,sbhu@cse.cuhk.edu.hk,Causal Inference and Mechanism Clustering of A Mixture of Additive Noise Models
neurips,2018,1,2490,Zhitang,Chen,cuhk,"Noah's Ark Lab,Huawei Tech. Investment Co. Ltd.",lwchan@cse.cuhk.edu.hk,Causal Inference and Mechanism Clustering of A Mixture of Additive Noise Models
neurips,2018,2,2490,Vahid,Partovi Nia,huawei,Huawei Technologies,chenzhitang2@huawei.com,Causal Inference and Mechanism Clustering of A Mixture of Additive Noise Models
neurips,2018,3,2490,Laiwan,CHAN,huawei,"Department of Computer Science and Engineering, Chinese University of Hong Kong",vahid.partovinia@huawei.com,Causal Inference and Mechanism Clustering of A Mixture of Additive Noise Models
neurips,2018,4,2490,Yanhui,Geng,huawei,Huawei Montreal Research Centre,geng.yanhui@huawei.com,Causal Inference and Mechanism Clustering of A Mixture of Additive Noise Models
neurips,2018,0,6626,Dimitrios,Diochnos,virginia,University of Virginia,diochnos@virginia.edu,Adversarial Risk and Robustness: General Definitions and Implications for the Uniform Distribution
neurips,2018,1,6626,Saeed,Mahloujifar,virginia,University of Virginia,saeed@virginia.edu,Adversarial Risk and Robustness: General Definitions and Implications for the Uniform Distribution
neurips,2018,2,6626,Mohammad,Mahmoody,virginia,University of Virginia,mohammad@virginia.edu,Adversarial Risk and Robustness: General Definitions and Implications for the Uniform Distribution
neurips,2018,0,6832,Yair,Carmon,stanford,Stanford,yairc@stanford.edu,Analysis of Krylov Subspace Solutions of  Regularized Non-Convex Quadratic Problems
neurips,2018,1,6832,John,Duchi,stanford,Stanford,jduchi@stanford.edu,Analysis of Krylov Subspace Solutions of  Regularized Non-Convex Quadratic Problems
neurips,2018,0,4974,Vatsal,Sharan,,Stanford University,,Efficient Anomaly Detection via Matrix Sketching
neurips,2018,1,4974,Parikshit,Gopalan,,VMware Research,,Efficient Anomaly Detection via Matrix Sketching
neurips,2018,2,4974,Udi,Wieder,,VMware Research,,Efficient Anomaly Detection via Matrix Sketching
neurips,2018,0,6537,Fei,Wang,purdue,Purdue University,wang603@purdue.edu,Backpropagation with Callbacks: Foundations for Efficient and Expressive Differentiable Programming
neurips,2018,1,6537,James,Decker,purdue,Purdue University,decker31@purdue.edu,Backpropagation with Callbacks: Foundations for Efficient and Expressive Differentiable Programming
neurips,2018,2,6537,Xilun,Wu,purdue,Purdue University,wu636@purdue.edu,Backpropagation with Callbacks: Foundations for Efficient and Expressive Differentiable Programming
neurips,2018,3,6537,Gregory,Essertel,purdue,Purdue University,gesserte@purdue.edu,Backpropagation with Callbacks: Foundations for Efficient and Expressive Differentiable Programming
neurips,2018,4,6537,Tiark,Rompf,purdue,Purdue University,tiark@purdue.edu,Backpropagation with Callbacks: Foundations for Efficient and Expressive Differentiable Programming
neurips,2018,0,3708,Min,Wen,upenn,University of Pennsylvania,wenm@seas.upenn.edu,Constrained Cross-Entropy Method for Safe Reinforcement Learning
neurips,2018,1,3708,Ufuk,Topcu,utexas,The University of Texas at Austin,utopcu@utexas.edu,Constrained Cross-Entropy Method for Safe Reinforcement Learning
neurips,2018,0,5007,Fredrik,Lindsten,uu,Uppsala University,fredrik.lindsten@it.uu.se,Graphical model inference: Sequential Monte Carlo meets deterministic approximations
neurips,2018,1,5007,Jouni,Helske,liu,Linköping University,jouni.helske@liu.se,Graphical model inference: Sequential Monte Carlo meets deterministic approximations
neurips,2018,2,5007,Matti,Vihola,jyu,University of Jyväskylä,matti.s.vihola@jyu.fi,Graphical model inference: Sequential Monte Carlo meets deterministic approximations
neurips,2018,0,1533,Yusuf,Aytar,google,DeepMind,yusufaytar@google.com,Playing hard exploration games by watching YouTube
neurips,2018,1,1533,Tobias,Pfaff,google,DeepMind,tpfaff@google.com,Playing hard exploration games by watching YouTube
neurips,2018,2,1533,David,Budden,google,DeepMind,budden@google.com,Playing hard exploration games by watching YouTube
neurips,2018,3,1533,Thomas,Paine,google,DeepMind,tpaine@google.com,Playing hard exploration games by watching YouTube
neurips,2018,4,1533,Ziyu,Wang,google,Deepmind,ziyu@google.com,Playing hard exploration games by watching YouTube
neurips,2018,5,1533,Nando,de Freitas,google,DeepMind,nandodefreitas@google.com,Playing hard exploration games by watching YouTube
neurips,2018,0,3780,Huy,Nguyen,northeastern,Princeton,hu.nguyen@northeastern.edu,Improved Algorithms for Collaborative PAC Learning
neurips,2018,1,3780,Lydia,Zakynthinou,northeastern,Northeastern University,zakynthinou.l@northeastern.edu,Improved Algorithms for Collaborative PAC Learning
neurips,2018,0,5094,Eric,Wong,cmu,Carnegie Mellon University,ericwong@cs.cmu.edu,Scaling provable adversarial defenses
neurips,2018,1,5094,Frank,Schmidt,bosch,Robert Bosch GmbH,janhendrik.metzen@de.bosch.com,Scaling provable adversarial defenses
neurips,2018,2,5094,Jan Hendrik,Metzen,bosch,Robert Bosch GmbH,frank.r.schmidt@de.bosch.com,Scaling provable adversarial defenses
neurips,2018,3,5094,J. Zico,Kolter,cmu,Carnegie Mellon University / Bosch Center for AI,zkolter@cs.cmu.edu,Scaling provable adversarial defenses
neurips,2018,0,3797,Nils,Bjorck,,Cornell,,Understanding Batch Normalization
neurips,2018,1,3797,Carla,Gomes,,Cornell University,,Understanding Batch Normalization
neurips,2018,2,3797,Bart,Selman,,Cornell University,,Understanding Batch Normalization
neurips,2018,3,3797,Kilian,Weinberger,,Cornell University,,Understanding Batch Normalization
neurips,2018,0,3115,Minjia,Zhang,microsoft,Microsoft,minjiaz@microsoft.com,Navigating with Graph Representations for Fast and Scalable Decoding of Neural Language Models
neurips,2018,1,3115,Wenhan,Wang,microsoft,Microsoft,xiaodl@microsoft.com,Navigating with Graph Representations for Fast and Scalable Decoding of Neural Language Models
neurips,2018,2,3115,Xiaodong,Liu,microsoft,Microsoft,wenhanw@microsoft.com,Navigating with Graph Representations for Fast and Scalable Decoding of Neural Language Models
neurips,2018,3,3115,Jianfeng,Gao,microsoft,"Microsoft Research, Redmond, WA",jfgao@microsoft.com,Navigating with Graph Representations for Fast and Scalable Decoding of Neural Language Models
neurips,2018,4,3115,Yuxiong,He,microsoft,Microsoft,yuxhe@microsoft.com,Navigating with Graph Representations for Fast and Scalable Decoding of Neural Language Models
neurips,2018,0,1949,Sanjoy,Dasgupta,ucsd,UC San Diego,dasgupta@eng.ucsd.edu,Learning from discriminative feature feedback
neurips,2018,1,1949,Akansha,Dey,ucsd,UCSD,n3robert@ucsd.edu,Learning from discriminative feature feedback
neurips,2018,2,1949,Nicholas,Roberts,ucsd,UC San Diego,a1dey@ucsd.edu,Learning from discriminative feature feedback
neurips,2018,3,1949,Sivan,Sabato,bgu,Ben-Gurion University of the Negev,sabatos@cs.bgu.ac.il,Learning from discriminative feature feedback
neurips,2018,0,1775,Krishnakumar,Balasubramanian,ucdavis,"University of California, Davis",kbala@ucdavis.edu,Zeroth-order (Non)-Convex Stochastic Optimization via Conditional Gradient and Gradient Updates
neurips,2018,1,1775,Saeed,Ghadimi,princeton,Princeton University,sghadimi@princeton.edu,Zeroth-order (Non)-Convex Stochastic Optimization via Conditional Gradient and Gradient Updates
neurips,2018,0,5579,Farnood,Salehi,,EPFL,,Coordinate Descent with Bandit Sampling
neurips,2018,1,5579,Patrick,Thiran,,,,Coordinate Descent with Bandit Sampling
neurips,2018,2,5579,Elisa,Celis,,EPFL,,Coordinate Descent with Bandit Sampling
neurips,2018,0,5551,Omar,Rivasplata,,University College London,,PAC-Bayes bounds for stable algorithms with instance-dependent priors
neurips,2018,1,5551,Emilio,Parrado-Hernandez,,University Carlos III de Madrid,,PAC-Bayes bounds for stable algorithms with instance-dependent priors
neurips,2018,2,5551,John,Shawe-Taylor,,UCL,,PAC-Bayes bounds for stable algorithms with instance-dependent priors
neurips,2018,3,5551,Shiliang,Sun,,East China Normal University,,PAC-Bayes bounds for stable algorithms with instance-dependent priors
neurips,2018,4,5551,Csaba,Szepesvari,,University of Alberta,,PAC-Bayes bounds for stable algorithms with instance-dependent priors
neurips,2018,0,508,Hae Beom,Lee,kaist,KAIST,haebeom.lee@kaist.ac.kr,DropMax: Adaptive Variational Softmax
neurips,2018,1,508,Juho,Lee,kaist,University of Oxford,eunhoy@kaist.ac.kr,DropMax: Adaptive Variational Softmax
neurips,2018,2,508,Saehoon,Kim,kaist,AITRICS,sjhwang82@kaist.ac.kr,DropMax: Adaptive Variational Softmax
neurips,2018,3,508,Eunho,Yang,ox,Korea Advanced Institute of Science and Technology; AItrics,juho.lee@stats.ox.ac.uk,DropMax: Adaptive Variational Softmax
neurips,2018,4,508,Sung Ju,Hwang,aitrics,"KAIST, AItrics",shkim@aitrics.com,DropMax: Adaptive Variational Softmax
neurips,2018,0,1808,Ji,Feng,,Nanjing University & Sinovation Ventures AI Institute,,Multi-Layered Gradient Boosting Decision Trees
neurips,2018,1,1808,Yang,Yu,,Nanjing University,,Multi-Layered Gradient Boosting Decision Trees
neurips,2018,2,1808,Zhi-Hua,Zhou,,Nanjing University,,Multi-Layered Gradient Boosting Decision Trees
neurips,2018,0,270,Junqi,Tang,ed,University of Edinburgh,J.Tang@ed.ac.uk,Rest-Katyusha: Exploiting the Solution's Structure via Scheduled Restart Schemes
neurips,2018,1,270,Mohammad,Golbabaee,bath,University of Bath,M.Golbabaee@bath.ac.uk,Rest-Katyusha: Exploiting the Solution's Structure via Scheduled Restart Schemes
neurips,2018,2,270,Francis,Bach,inria,INRIA - Ecole Normale Superieure,Francis.Bach@inria.fr,Rest-Katyusha: Exploiting the Solution's Structure via Scheduled Restart Schemes
neurips,2018,3,270,Mike,davies,ed,University of Edinburgh,Mike.Davies@ed.ac.uk,Rest-Katyusha: Exploiting the Solution's Structure via Scheduled Restart Schemes
neurips,2018,0,1073,Amit,Zohar,,Tel Aviv Universtiy,,Automatic Program Synthesis of Long Programs with a Learned Garbage Collector
neurips,2018,1,1073,Lior,Wolf,,Facebook AI Research,,Automatic Program Synthesis of Long Programs with a Learned Garbage Collector
neurips,2018,0,386,Kirill,Struminsky,,NRU HSE,,Quantifying Learning Guarantees for Convex but Inconsistent Surrogates
neurips,2018,1,386,Simon,Lacoste-Julien,,"MILA, Université de Montréal",,Quantifying Learning Guarantees for Convex but Inconsistent Surrogates
neurips,2018,2,386,Anton,Osokin,,"NRU HSE, Moscow, Russia",,Quantifying Learning Guarantees for Convex but Inconsistent Surrogates
neurips,2018,0,3632,Zichao,Yang,cmu,Carnegie Mellon University,zichaoy@cs.cmu.edu,Unsupervised Text Style Transfer using Language Models as Discriminators
neurips,2018,1,3632,Zhiting,Hu,cmu,Carnegie Mellon University,zhitingh@cs.cmu.edu,Unsupervised Text Style Transfer using Language Models as Discriminators
neurips,2018,2,3632,Chris,Dyer,cmu,DeepMind,epxing@cs.cmu.edu,Unsupervised Text Style Transfer using Language Models as Discriminators
neurips,2018,3,3632,Eric,Xing,cmu,Petuum Inc. /  Carnegie Mellon University,tberg@cs.cmu.edu,Unsupervised Text Style Transfer using Language Models as Discriminators
neurips,2018,4,3632,Taylor,Berg-Kirkpatrick,google,Carnegie Mellon University,cdyer@google.com,Unsupervised Text Style Transfer using Language Models as Discriminators
neurips,2018,0,3185,Edward,Smith,mcgill,McGill University,edward.smith@mail.mcgill.ca,Multi-View Silhouette and Depth Decomposition for High Resolution 3D Object Representation
neurips,2018,1,3185,Scott,Fujimoto,mcgill,McGill University,scott.fujimoto@mail.mcgill.ca,Multi-View Silhouette and Depth Decomposition for High Resolution 3D Object Representation
neurips,2018,2,3185,David,Meger,mcgill,University of British Columbia,dmeger@cim.mcgill.ca,Multi-View Silhouette and Depth Decomposition for High Resolution 3D Object Representation
neurips,2018,0,6921,Sara,Magliacane,gmail,IBM Research AI,sara.magliacane@gmail.com,Domain Adaptation by Using Causal Inference to Predict Invariant Conditional Distributions
neurips,2018,1,6921,Thijs,van Ommen,gmail,University of Amsterdam,thijsvanommen@gmail.com,Domain Adaptation by Using Causal Inference to Predict Invariant Conditional Distributions
neurips,2018,2,6921,Tom,Claassen,cs,Radboud University Nijmegen,tomc@cs.ru.nl,Domain Adaptation by Using Causal Inference to Predict Invariant Conditional Distributions
neurips,2018,3,6921,Stephan,Bongers,gmail,University of Amsterdam,srbongers@gmail.com,Domain Adaptation by Using Causal Inference to Predict Invariant Conditional Distributions
neurips,2018,4,6921,Philip,Versteeg,uva,University of Amsterdam,p.j.j.p.versteeg@uva.nl,Domain Adaptation by Using Causal Inference to Predict Invariant Conditional Distributions
neurips,2018,5,6921,Joris,Mooij,uva,University of Amsterdam,j.m.mooij@uva.nl,Domain Adaptation by Using Causal Inference to Predict Invariant Conditional Distributions
neurips,2018,0,5614,Nathan,Kallus,cornell,Cornell University,az434@cornell.edu,Confounding-Robust Policy Improvement
neurips,2018,1,5614,Angela,Zhou,cornell,Cornell University,kallus@cornell.edu,Confounding-Robust Policy Improvement
neurips,2018,0,1560,Ronan,Fruit,inria,Inria Lille,ronan.fruit@inria.fr,Near Optimal Exploration-Exploitation in Non-Communicating Markov Decision Processes
neurips,2018,1,1560,Matteo,Pirotta,inria,INRIA Lille-Nord Europe,matteo.pirotta@inria.fr,Near Optimal Exploration-Exploitation in Non-Communicating Markov Decision Processes
neurips,2018,2,1560,Alessandro,Lazaric,fb,Facebook Artificial Intelligence Research,lazaric@fb.com,Near Optimal Exploration-Exploitation in Non-Communicating Markov Decision Processes
neurips,2018,0,6669,Noam,Shazeer,google,Google,noam@google.com,Mesh-TensorFlow: Deep Learning for Supercomputers
neurips,2018,1,6669,Youlong,Cheng,google,Google,ylc@google.com,Mesh-TensorFlow: Deep Learning for Supercomputers
neurips,2018,2,6669,Niki,Parmar,google,Google,nikip@google.com,Mesh-TensorFlow: Deep Learning for Supercomputers
neurips,2018,3,6669,Dustin,Tran,google,Google Brain,trandustin@google.com,Mesh-TensorFlow: Deep Learning for Supercomputers
neurips,2018,4,6669,Ashish,Vaswani,google,Google Brain,avaswani@google.com,Mesh-TensorFlow: Deep Learning for Supercomputers
neurips,2018,5,6669,Penporn,Koanantakool,google,Google,penporn@google.com,Mesh-TensorFlow: Deep Learning for Supercomputers
neurips,2018,6,6669,Peter,Hawkins,google,google.com,phawkins@google.com,Mesh-TensorFlow: Deep Learning for Supercomputers
neurips,2018,7,6669,HyoukJoong,Lee,google,Google,hyouklee@google.com,Mesh-TensorFlow: Deep Learning for Supercomputers
neurips,2018,8,6669,Mingsheng,Hong,google,google.com,hongm@google.com,Mesh-TensorFlow: Deep Learning for Supercomputers
neurips,2018,9,6669,Cliff,Young,google,google.com,cliffy@google.com,Mesh-TensorFlow: Deep Learning for Supercomputers
neurips,2018,10,6669,Ryan,Sepassi,google,Google,rsepassi@google.com,Mesh-TensorFlow: Deep Learning for Supercomputers
neurips,2018,11,6669,Blake,Hechtman,google,Google,blakehechtman@google.com,Mesh-TensorFlow: Deep Learning for Supercomputers
neurips,2018,0,865,Abhishek,Sharma,gmail,Navinfo Europe Research,kein.iitian@gmail.com,Foreground Clustering for Joint Segmentation and Localization in Videos and Images
neurips,2018,0,3097,Borja,Balle,ukGillesBartheIMDEASoftwareInstitutegilles,Amazon Research Cambridge,TightAnalysesviaCouplingsandDivergencesBorjaBalleAmazonResearchpigem@amazon.co.ukGillesBartheIMDEASoftwareInstitutegilles.barthe,Privacy Amplification by Subsampling: Tight Analyses via Couplings and Divergences
neurips,2018,1,3097,Gilles,Barthe,buffalo,IMDEA Software Institute,imdea.orgMarcoGaboardiUniversityatBuffalo@buffalo.edu,Privacy Amplification by Subsampling: Tight Analyses via Couplings and Divergences
neurips,2018,2,3097,Marco,Gaboardi,buffalo,Univeristy at Buffalo,SUNYgaboardi@buffalo.edu,Privacy Amplification by Subsampling: Tight Analyses via Couplings and Divergences
neurips,2018,0,1122,Léonard,Blier,normalesup,Ecole Normale Supérieure,leonard.blier@normalesup.org,The Description Length of Deep Learning models
neurips,2018,1,1122,Yann,Ollivier,fb,Facebook Artificial Intelligence Research,yol@fb.com,The Description Length of Deep Learning models
neurips,2018,0,1639,Yucen,Luo,tsinghua,Tsinghua University,luoyc15@mails.tsinghua.edu.cn,Semi-crowdsourced Clustering with Deep Generative Models
neurips,2018,1,1639,TIAN,TIAN,tsinghua,Tsinghua University,shijx15@mails.tsinghua.edu.cn,Semi-crowdsourced Clustering with Deep Generative Models
neurips,2018,2,1639,Jiaxin,Shi,163,Tsinghua University,rossowhite@163.com,Semi-crowdsourced Clustering with Deep Generative Models
neurips,2018,3,1639,Jun,Zhu,tsinghua,Tsinghua University,dcszj@mail.tsinghua.edu.cn,Semi-crowdsourced Clustering with Deep Generative Models
neurips,2018,4,1639,Bo,Zhang,tsinghua,Tsinghua University,dcszb@mail.tsinghua.edu.cn,Semi-crowdsourced Clustering with Deep Generative Models
neurips,2018,0,6490,Imtiaz,Ziko,,Ecole de technologie superieure (ETS),,Scalable Laplacian K-modes
neurips,2018,1,6490,Eric,Granger,,"École de technologie supérieure, Université du Québec",,Scalable Laplacian K-modes
neurips,2018,2,6490,Ismail,Ben Ayed,,ETS Montreal,,Scalable Laplacian K-modes
neurips,2018,0,1974,Meimei,Liu,duke,Duke University,meimei.liu@duke.edu,Early Stopping for Nonparametric Testing
neurips,2018,1,1974,Guang,Cheng,purdue,Purdue University,chengg@purdue.edu,Early Stopping for Nonparametric Testing
neurips,2018,0,3737,Yedid,Hoshen,,Facebook AI Research,,Non-Adversarial Mapping with VAEs
neurips,2018,0,2298,Kurtland,Chua,berkeley,UC Berkeley,kchua@berkeley.edu,Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models
neurips,2018,1,2298,Roberto,Calandra,berkeley,Facebook AI Research,roberto.calandra@berkeley.edu,Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models
neurips,2018,2,2298,Rowan,McAllister,berkeley,UC Berkeley,rmcallister@berkeley.edu,Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models
neurips,2018,3,2298,Sergey,Levine,berkeley,UC Berkeley,svlevine@berkeley.edu,Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models
neurips,2018,0,4944,Sander,Dieleman,google,DeepMind,sedielem@google.com,The challenge of realistic music generation: modelling raw audio at scale
neurips,2018,1,4944,Aaron,van den Oord,google,Google Deepmind,avdnoord@google.com,The challenge of realistic music generation: modelling raw audio at scale
neurips,2018,2,4944,Karen,Simonyan,google,DeepMind,simonyan@google.com,The challenge of realistic music generation: modelling raw audio at scale
neurips,2018,0,2961,David,Harris,buffalo,University of Maryland,shil@buffalo.edu,Approximation algorithms for stochastic clustering
neurips,2018,1,2961,Shi,Li,gmail,University at Buffalo,davidgharris29@gmail.com,Approximation algorithms for stochastic clustering
neurips,2018,2,2961,Aravind,Srinivasan,bandwidth,University of Maryland College Park,tpensyl@bandwidth.com,Approximation algorithms for stochastic clustering
neurips,2018,3,2961,Khoa,Trinh,umd,,srin@cs.umd.edu,Approximation algorithms for stochastic clustering
neurips,2018,4,2961,Thomas,Pensyl,google,,khoatrinh@google.com,Approximation algorithms for stochastic clustering
neurips,2018,0,2083,Hiroyuki,Kasai,uec,UEC,kasai@is.uec.ac.jp,Inexact trust-region algorithms on Riemannian manifolds
neurips,2018,1,2083,Bamdev,Mishra,microsoft,Microsoft,bamdevm@microsoft.com,Inexact trust-region algorithms on Riemannian manifolds
neurips,2018,0,4848,David,Alvarez Melis,mit,MIT,dalvmel@mit.edu,Towards Robust Interpretability with Self-Explaining Neural Networks
neurips,2018,1,4848,Tommi,Jaakkola,mit,MIT,tommi@csail.mit.edu,Towards Robust Interpretability with Self-Explaining Neural Networks
neurips,2018,0,3499,Andrey,Malinin,cam,University of Cambridge,am969@cam.ac.uk,Predictive Uncertainty Estimation via Prior Networks
neurips,2018,1,3499,Mark,Gales,cam,University of Cambridge,mjfg@eng.cam.ac.uk,Predictive Uncertainty Estimation via Prior Networks
neurips,2018,0,5135,Blake,Woodworth,ttic,TTI-Chicago,blake@ttic.edu,"Graph Oracle Models, Lower Bounds, and Gaps for Parallel Stochastic Optimization"
neurips,2018,1,5135,Jialei,Wang,twosigma,"Two Sigma Investments, University of Chicago",jialei.wang@twosigma.com,"Graph Oracle Models, Lower Bounds, and Gaps for Parallel Stochastic Optimization"
neurips,2018,2,5135,Adam,Smith,bu,Boston University,ads22@bu.edu,"Graph Oracle Models, Lower Bounds, and Gaps for Parallel Stochastic Optimization"
neurips,2018,3,5135,Brendan,McMahan,google,Google,mcmahan@google.com,"Graph Oracle Models, Lower Bounds, and Gaps for Parallel Stochastic Optimization"
neurips,2018,4,5135,Nati,Srebro,ttic,TTI-Chicago,nati@ttic.edu,"Graph Oracle Models, Lower Bounds, and Gaps for Parallel Stochastic Optimization"
neurips,2018,0,85,Ehsan,Imani,ualberta,University of Alberta,imani@ualberta.ca,An Off-policy Policy Gradient Theorem Using Emphatic Weightings
neurips,2018,1,85,Eric,Graves,ualberta,University of Alberta,graves@ualberta.ca,An Off-policy Policy Gradient Theorem Using Emphatic Weightings
neurips,2018,2,85,Martha,White,ualberta,University of Alberta,whitem@ualberta.ca,An Off-policy Policy Gradient Theorem Using Emphatic Weightings
neurips,2018,0,2501,Yonathan,Efroni,gmail,Technion,jonathan.efroni@gmail.com,Multiple-Step Greedy Policies in Approximate and Online Reinforcement Learning
neurips,2018,1,2501,Gal,Dalal,technion,Technion,gald@campus.technion.ac.il,Multiple-Step Greedy Policies in Approximate and Online Reinforcement Learning
neurips,2018,2,2501,Bruno,Scherrer,inria,INRIA,bruno.scherrer@inria.fr,Multiple-Step Greedy Policies in Approximate and Online Reinforcement Learning
neurips,2018,3,2501,Shie,Mannor,technion,Technion,shie@ee.technion.ac.il,Multiple-Step Greedy Policies in Approximate and Online Reinforcement Learning
neurips,2018,0,1803,David,Zoltowski,princeton,Princeton University,zoltowski@princeton.edu,Scaling the Poisson GLM to massive neural datasets through polynomial approximations
neurips,2018,1,1803,Jonathan,Pillow,princeton,Princeton University,pillow@princeton.edu,Scaling the Poisson GLM to massive neural datasets through polynomial approximations
neurips,2018,0,3481,Yingyezhe,Jin,tamu,Facebook Inc,jyyz@tamu.edu,Hybrid Macro/Micro Level Backpropagation for Training Deep Spiking Neural Networks
neurips,2018,1,3481,Wenrui,Zhang,tamu,Texas A&M University,zhangwenrui@tamu.edu,Hybrid Macro/Micro Level Backpropagation for Training Deep Spiking Neural Networks
neurips,2018,2,3481,Peng,Li,tamu,Texas A&M University,pli@tamu.edu,Hybrid Macro/Micro Level Backpropagation for Training Deep Spiking Neural Networks
neurips,2018,0,2825,Giulia,Luise,,University College London,,Differential Properties of Sinkhorn Approximation for Learning with Wasserstein Distance
neurips,2018,1,2825,Alessandro,Rudi,,"INRIA, Ecole Normale Superieure",,Differential Properties of Sinkhorn Approximation for Learning with Wasserstein Distance
neurips,2018,2,2825,Massimiliano,Pontil,,IIT,,Differential Properties of Sinkhorn Approximation for Learning with Wasserstein Distance
neurips,2018,3,2825,Carlo,Ciliberto,,Imperial College London,,Differential Properties of Sinkhorn Approximation for Learning with Wasserstein Distance
neurips,2018,0,3042,Ian,Davidson,ucdavis,U.C. Davis,davidson@cs.ucdavis.edu,"The Cluster Description Problem - Complexity Results, Formulations and Approximations"
neurips,2018,1,3042,Antoine,Gourru,univ-lyon2,University of Lyon - 2,antoine.gourru@univ-lyon2.fr,"The Cluster Description Problem - Complexity Results, Formulations and Approximations"
neurips,2018,2,3042,S,Ravi,gmail,Biocomplexity Institute,ssravi0@gmail.com,"The Cluster Description Problem - Complexity Results, Formulations and Approximations"
neurips,2018,0,6072,Murat,Erdogdu,,University of Toronto,,Global Non-convex Optimization with Discretized Diffusions
neurips,2018,1,6072,Lester,Mackey,,Microsoft Research,,Global Non-convex Optimization with Discretized Diffusions
neurips,2018,2,6072,Ohad,Shamir,,Weizmann Institute of Science,,Global Non-convex Optimization with Discretized Diffusions
neurips,2018,0,2713,Jieming,Mao,upenn,Princeton University,jiemingm@seas.upenn.edu,Contextual Pricing for Lipschitz Buyers
neurips,2018,1,2713,Renato,Leme,google,Google Research,renatoppl@google.com,Contextual Pricing for Lipschitz Buyers
neurips,2018,2,2713,Jon,Schneider,google,Google,jschnei@google.com,Contextual Pricing for Lipschitz Buyers
neurips,2018,0,1430,Marek,mieja,uj,Jagiellonian University,marek.smieja@uj.edu.pl,Processing of missing data by neural networks
neurips,2018,1,1430,ukasz,Struski,uj,Jagiellonian University,lukasz.struski@uj.edu.pl,Processing of missing data by neural networks
neurips,2018,2,1430,Jacek,Tabor,uj,Jagiellonian University,jacek.tabor@uj.edu.pl,Processing of missing data by neural networks
neurips,2018,3,1430,Bartosz,Zieliski,uj,Jagiellonian University,bartosz.zielinski@uj.edu.pl,Processing of missing data by neural networks
neurips,2018,4,1430,Przemysaw,Spurek,uj,Jagiellonian University,przemyslaw.spurek@uj.edu.pl,Processing of missing data by neural networks
neurips,2018,0,5443,Daniel,Moyer,usc,University of Southern California,moyerd@usc.edu,Invariant Representations without Adversarial Training
neurips,2018,1,5443,Shuyang,Gao,usc,ISI USC,gaos@usc.edu,Invariant Representations without Adversarial Training
neurips,2018,2,5443,Rob,Brekelmans,usc,University of Southern California,brekelma@usc.edu,Invariant Representations without Adversarial Training
neurips,2018,3,5443,Aram,Galstyan,isi,USC Information Sciences Inst,gregv@isi.edu,Invariant Representations without Adversarial Training
neurips,2018,4,5443,Greg,Ver Steeg,isi,University of Southern California,galstyan@isi.edu,Invariant Representations without Adversarial Training
neurips,2018,0,3724,Marton,Havasi,cam,University of Cambridge,mh740@cam.ac.uk,Inference in Deep Gaussian Processes using Stochastic Gradient Hamiltonian Monte Carlo
neurips,2018,1,3724,José Miguel,Hernández-Lobato,cam,University of Cambridge,jmh233@cam.ac.uk,Inference in Deep Gaussian Processes using Stochastic Gradient Hamiltonian Monte Carlo
neurips,2018,2,3724,Juan José,Murillo-Fuentes,us,Universidad de Sevilla,murillo@us.es,Inference in Deep Gaussian Processes using Stochastic Gradient Hamiltonian Monte Carlo
neurips,2018,0,6720,Zi,Wang,mit,MIT,ziw@csail.mit.edu,Regret bounds for meta Bayesian optimization with an unknown Gaussian process prior
neurips,2018,1,6720,Beomjoon,Kim,mit,MIT,beomjoon@mit.edu,Regret bounds for meta Bayesian optimization with an unknown Gaussian process prior
neurips,2018,2,6720,Leslie,Kaelbling,mit,MIT,lpk@csail.mit.edu,Regret bounds for meta Bayesian optimization with an unknown Gaussian process prior
neurips,2018,0,6779,Jinhwan,Park,snu,Seoul National University,bnoo@snu.ac.kr,Fully Neural Network Based Speech Recognition on Mobile and Embedded Devices
neurips,2018,1,6779,Yoonho,Boo,snu,Seoul National University,dnsgh@snu.ac.kr,Fully Neural Network Based Speech Recognition on Mobile and Embedded Devices
neurips,2018,2,6779,Iksoo,Choi,snu,Seoul National University,akacis@snu.ac.kr,Fully Neural Network Based Speech Recognition on Mobile and Embedded Devices
neurips,2018,3,6779,Sungho,Shin,snu,Seoul National University,ssh9919@snu.ac.kr,Fully Neural Network Based Speech Recognition on Mobile and Embedded Devices
neurips,2018,4,6779,Wonyong,Sung,snu,Seoul National University,wysung@snu.ac.kr,Fully Neural Network Based Speech Recognition on Mobile and Embedded Devices
neurips,2018,0,457,Gamaleldin,Elsayed,google,Google Brain,gamaleldin@google.com,Large Margin Deep Networks for Classification
neurips,2018,1,457,Dilip,Krishnan,google,Google,dilipkay@google.com,Large Margin Deep Networks for Classification
neurips,2018,2,457,Hossein,Mobahi,google,Google Research,hmobahi@google.com,Large Margin Deep Networks for Classification
neurips,2018,3,457,Kevin,Regan,google,Google,kevinregan@google.com,Large Margin Deep Networks for Classification
neurips,2018,4,457,Samy,Bengio,google,Google Brain,bengio@google.com,Large Margin Deep Networks for Classification
neurips,2018,0,921,Guocong,Song,gmail,Playground Global,songgc@gmail.com,Collaborative Learning for Deep Neural Networks
neurips,2018,1,921,Wei,Chai,google,Google Inc,chaiwei@google.com,Collaborative Learning for Deep Neural Networks
neurips,2018,0,318,Ozan,Sener,,Intel Labs,,Multi-Task Learning as Multi-Objective Optimization
neurips,2018,1,318,Vladlen,Koltun,,Intel Labs,,Multi-Task Learning as Multi-Objective Optimization
neurips,2018,0,872,Yilun,Du,,MIT,,Learning to Exploit Stability for 3D Scene Parsing
neurips,2018,1,872,Zhijian,Liu,,MIT,,Learning to Exploit Stability for 3D Scene Parsing
neurips,2018,2,872,Hector,Basevi,,University of Birmingham,,Learning to Exploit Stability for 3D Scene Parsing
neurips,2018,3,872,Ales,Leonardis,,University of Birmingham,,Learning to Exploit Stability for 3D Scene Parsing
neurips,2018,4,872,Bill,Freeman,,MIT/Google,,Learning to Exploit Stability for 3D Scene Parsing
neurips,2018,5,872,Josh,Tenenbaum,,MIT,,Learning to Exploit Stability for 3D Scene Parsing
neurips,2018,6,872,Jiajun,Wu,,MIT,,Learning to Exploit Stability for 3D Scene Parsing
neurips,2018,0,1920,Jingzhao,Zhang,,MIT,,Direct Runge-Kutta Discretization Achieves Acceleration
neurips,2018,1,1920,Aryan,Mokhtari,,MIT,,Direct Runge-Kutta Discretization Achieves Acceleration
neurips,2018,2,1920,Suvrit,Sra,,MIT,,Direct Runge-Kutta Discretization Achieves Acceleration
neurips,2018,3,1920,Ali,Jadbabaie,,MIT,,Direct Runge-Kutta Discretization Achieves Acceleration
neurips,2018,0,3785,Hanlin,Tang,rochester,University of Rochester,htang14@ur.rochester.edu,Communication Compression for Decentralized Training
neurips,2018,1,3785,Shaoduo,Gan,ethz,ETH Zurich,sgan@inf.ethz.ch,Communication Compression for Decentralized Training
neurips,2018,2,3785,Ce,Zhang,ethz,ETH Zurich,ce.zhang@inf.ethz.ch,Communication Compression for Decentralized Training
neurips,2018,3,3785,Tong,Zhang,tongzhang-ml,Tencent AI Lab,tongzhang@tongzhang-ml.org,Communication Compression for Decentralized Training
neurips,2018,4,3785,Ji,Liu,gmail,"University of Rochester, Tencent AI lab",ji.liu.uwisc@gmail.com,Communication Compression for Decentralized Training
neurips,2018,0,6483,Sercan,Arik,baidu,Google,sercanarik@baidu.com,Neural Voice Cloning with a Few Samples
neurips,2018,1,6483,Jitong,Chen,baidu,ByteDance,chenjitong01@baidu.com,Neural Voice Cloning with a Few Samples
neurips,2018,2,6483,Kainan,Peng,baidu,Baidu Research,pengkainan@baidu.com,Neural Voice Cloning with a Few Samples
neurips,2018,3,6483,Wei,Ping,baidu,Baidu Silicon Valley AI Lab,pingwei01@baidu.com,Neural Voice Cloning with a Few Samples
neurips,2018,4,6483,Yanqi,Zhou,baidu,Baidu Research,yanqiz@baidu.com,Neural Voice Cloning with a Few Samples
neurips,2018,0,6498,Osman Asif,Malik,colorado,University of Colorado Boulder,osman.malik@colorado.edu,Low-Rank Tucker Decomposition of Large Tensors Using TensorSketch
neurips,2018,1,6498,Stephen,Becker,colorado,University of Colorado,stephen.becker@colorado.edu,Low-Rank Tucker Decomposition of Large Tensors Using TensorSketch
neurips,2018,0,1713,Yitong,Sun,umich,University of Michigan,syitong@umich.edu,But How Does It Work in Theory? Linear SVM with Random Features
neurips,2018,1,1713,Anna,Gilbert,umich,University of Michigan,annacg@umich.edu,But How Does It Work in Theory? Linear SVM with Random Features
neurips,2018,2,1713,Ambuj,Tewari,umich,University of Michigan,tewaria@umich.edu,But How Does It Work in Theory? Linear SVM with Random Features
neurips,2018,0,757,Longquan,Dai,njust,Nanjing University of Science and Technology,dailongquan@njust.edu.cn,Designing by Training: Acceleration Neural Network for Fast High-Dimensional Convolution
neurips,2018,1,757,Liang,Tang,casaet,"CASA Environmental Technology Co., Ltd and CASA EM&EW IOT Research Center",tangl@casaet.com,Designing by Training: Acceleration Neural Network for Fast High-Dimensional Convolution
neurips,2018,2,757,Yuan,Xie,ia,Chinese Academy of Sciences,yuan.xie@ia.ac.cn,Designing by Training: Acceleration Neural Network for Fast High-Dimensional Convolution
neurips,2018,3,757,Jinhui,Tang,njust,Nanjing University of Science and Technology,jinhuitang@njust.edu.cn,Designing by Training: Acceleration Neural Network for Fast High-Dimensional Convolution
neurips,2018,0,3455,Simon,Kohl,google,German Cancer Research Center (DKFZ),brp@google.com,A Probabilistic U-Net for Segmentation of Ambiguous Images
neurips,2018,1,3455,Bernardino,Romera-Paredes,google,DeepMind,meyerc@google.com,A Probabilistic U-Net for Segmentation of Ambiguous Images
neurips,2018,2,3455,Clemens,Meyer,google,DeepMind,defauw@google.com,A Probabilistic U-Net for Segmentation of Ambiguous Images
neurips,2018,3,3455,Jeffrey,De Fauw,google,DeepMind,jledsam@google.com,A Probabilistic U-Net for Segmentation of Ambiguous Images
neurips,2018,4,3455,Joseph R.,Ledsam,google,DeepMind,aeslami@google.com,A Probabilistic U-Net for Segmentation of Ambiguous Images
neurips,2018,5,3455,Klaus,Maier-Hein,google,German Cancer Research Center,danilor@google.com,A Probabilistic U-Net for Segmentation of Ambiguous Images
neurips,2018,6,3455,S. M. Ali,Eslami,google,DeepMind,olafr@google.com,A Probabilistic U-Net for Segmentation of Ambiguous Images
neurips,2018,7,3455,Danilo,Jimenez Rezende,dkfz,Google DeepMind,simon.kohl@dkfz.de,A Probabilistic U-Net for Segmentation of Ambiguous Images
neurips,2018,8,3455,Olaf,Ronneberger,dkfz,DeepMind,k.maier-hein@dkfz.de,A Probabilistic U-Net for Segmentation of Ambiguous Images
neurips,2018,0,2736,Mario,Bravo,usach,"University of Santiago, Chile",mario.bravo.g@usach.cl,Bandit Learning in Concave N-Person Games
neurips,2018,1,2736,David,Leslie,lancaster,Lancaster University and PROWLER.io,d.leslie@lancaster.ac.uk,Bandit Learning in Concave N-Person Games
neurips,2018,2,2736,Panayotis,Mertikopoulos,imag,CNRS (French National Center for Scientific Research),panayotis.mertikopoulos@imag.fr,Bandit Learning in Concave N-Person Games
neurips,2018,0,5828,Thomas,George,,"MILA, Université de Montréal",,Fast Approximate Natural Gradient Descent in a Kronecker Factored Eigenbasis
neurips,2018,1,5828,César,Laurent,,Mila - Université de Montréal,,Fast Approximate Natural Gradient Descent in a Kronecker Factored Eigenbasis
neurips,2018,2,5828,Xavier,Bouthillier,,Université de Montréal,,Fast Approximate Natural Gradient Descent in a Kronecker Factored Eigenbasis
neurips,2018,3,5828,Nicolas,Ballas,,Facebook FAIR,,Fast Approximate Natural Gradient Descent in a Kronecker Factored Eigenbasis
neurips,2018,4,5828,Pascal,Vincent,,Facebook and U. Montreal,,Fast Approximate Natural Gradient Descent in a Kronecker Factored Eigenbasis
neurips,2018,0,5148,Alireza,Aghasi,gsu,Institute for Insight,aaghasi@gsu.edu,A convex program for bilinear inversion of sparse vectors
neurips,2018,1,5148,Ali,Ahmed,itu,Information Technology University,ali.ahmed@itu.edu.pk,A convex program for bilinear inversion of sparse vectors
neurips,2018,2,5148,Paul,Hand,northeastern,Northeastern University,p.hand@northeastern.edu,A convex program for bilinear inversion of sparse vectors
neurips,2018,3,5148,Babhru,Joshi,rice,Rice University,babhru.joshi@rice.edu,A convex program for bilinear inversion of sparse vectors
neurips,2018,0,3258,Yusuke,Tsuzuku,u-tokyo,The University of Tokyo / RIKEN,tsuzuku@ms.k.u-tokyo.ac.jp,Lipschitz-Margin Training: Scalable Certification of Perturbation Invariance for Deep Neural Networks
neurips,2018,1,3258,Issei,Sato,u-tokyo,The University of Tokyo/RIKEN,sato@k.u-tokyo.ac.jp,Lipschitz-Margin Training: Scalable Certification of Perturbation Invariance for Deep Neural Networks
neurips,2018,2,3258,Masashi,Sugiyama,u-tokyo,RIKEN / University of Tokyo,sugi@k.u-tokyo.ac.jp,Lipschitz-Margin Training: Scalable Certification of Perturbation Invariance for Deep Neural Networks
neurips,2018,0,6591,Yu,Cheng,duke,Duke University,yucheng@cs.duke.edu,Robust Learning of Fixed-Structure Bayesian Networks
neurips,2018,1,6591,Ilias,Diakonikolas,gmail,University of Southern California,ilias.diakonikolas@gmail.com,Robust Learning of Fixed-Structure Bayesian Networks
neurips,2018,2,6591,Daniel,Kane,ucsd,UCSD,dakane@ucsd.edu,Robust Learning of Fixed-Structure Bayesian Networks
neurips,2018,3,6591,Alistair,Stewart,gmail,University of Southern California,stewart.al@gmail.com,Robust Learning of Fixed-Structure Bayesian Networks
neurips,2018,0,6629,Maurice,Weiler,uva,University of Amsterdam,m.weiler@uva.nl,3D Steerable CNNs: Learning Rotationally Equivariant Features in Volumetric Data
neurips,2018,1,6629,Mario,Geiger,epfl,EPFL,mario.geiger@epfl.ch,3D Steerable CNNs: Learning Rotationally Equivariant Features in Volumetric Data
neurips,2018,2,6629,Max,Welling,uva,University of Amsterdam / Qualcomm AI Research,m.welling@uva.nl,3D Steerable CNNs: Learning Rotationally Equivariant Features in Volumetric Data
neurips,2018,3,6629,Wouter,Boomsma,ku,University of Copenhagen,wb@di.ku.dk,3D Steerable CNNs: Learning Rotationally Equivariant Features in Volumetric Data
neurips,2018,4,6629,Taco,Cohen,gmail,University of Amsterdam,taco.cohen@gmail.com,3D Steerable CNNs: Learning Rotationally Equivariant Features in Volumetric Data
neurips,2018,0,624,Sven,Bambach,iu,The Research Institute at Nationwide Children's Hospital,sbambach@iu.edu,Toddler-Inspired Visual Object Learning
neurips,2018,1,624,David,Crandall,iu,Indiana University,djcran@iu.edu,Toddler-Inspired Visual Object Learning
neurips,2018,2,624,Linda,Smith,iu,Indiana University,smith4@iu.edu,Toddler-Inspired Visual Object Learning
neurips,2018,3,624,Chen,Yu,iu,Indiana University,chenyu@iu.edu,Toddler-Inspired Visual Object Learning
neurips,2018,0,5501,Akshay Raj,Dhamija,,University of Colorado Colorado Springs,,Reducing Network Agnostophobia
neurips,2018,1,5501,Manuel,Günther,,Vision and Security Technology Lab (VaST),,Reducing Network Agnostophobia
neurips,2018,2,5501,Terrance,Boult,,University of Colorado Colorado Springs,,Reducing Network Agnostophobia
neurips,2018,0,295,Minhyuk,Sung,stanford,Stanford University,mhsung@cs.stanford.edu,Deep Functional Dictionaries: Learning Consistent Semantic Structures on 3D Models from Functions
neurips,2018,1,295,Hao,Su,ucsd,UCSD,haosu@eng.ucsd.edu,Deep Functional Dictionaries: Learning Consistent Semantic Structures on 3D Models from Functions
neurips,2018,2,295,Ronald,Yu,ucsd,UCSD,ronaldyu@ucsd.edu,Deep Functional Dictionaries: Learning Consistent Semantic Structures on 3D Models from Functions
neurips,2018,3,295,Leonidas,Guibas,stanford,stanford.edu,guibas@cs.stanford.edu,Deep Functional Dictionaries: Learning Consistent Semantic Structures on 3D Models from Functions
neurips,2018,0,5128,Luis,Haug,ethz,ETH Zurich,lhaug@inf.ethz.ch,Teaching Inverse Reinforcement Learners via Features and Demonstrations
neurips,2018,1,5128,Sebastian,Tschiatschek,microsoft,Microsoft Research,setschia@microsoft.com,Teaching Inverse Reinforcement Learners via Features and Demonstrations
neurips,2018,2,5128,Adish,Singla,mpi-sws,MPI-SWS,adishs@mpi-sws.org,Teaching Inverse Reinforcement Learners via Features and Demonstrations
neurips,2018,0,305,Jun-Ting,Hsieh,stanford,Stanford University,junting@stanford.edu,Learning to Decompose and Disentangle Representations for Video Prediction
neurips,2018,1,305,Bingbin,Liu,stanford,Stanford University,bingbin@stanford.edu,Learning to Decompose and Disentangle Representations for Video Prediction
neurips,2018,2,305,De-An,Huang,stanford,Stanford University,dahuang@cs.stanford.edu,Learning to Decompose and Disentangle Representations for Video Prediction
neurips,2018,3,305,Li,Fei-Fei,stanford,Stanford University & Google,feifeili@cs.stanford.edu,Learning to Decompose and Disentangle Representations for Video Prediction
neurips,2018,4,305,Juan Carlos,Niebles,stanford,Stanford University,jniebles@cs.stanford.edu,Learning to Decompose and Disentangle Representations for Video Prediction
neurips,2018,0,6437,James,Wilson,,Imperial College of London,,Maximizing acquisition functions for Bayesian optimization
neurips,2018,1,6437,Frank,Hutter,,University of Freiburg,,Maximizing acquisition functions for Bayesian optimization
neurips,2018,2,6437,Marc,Deisenroth,,Imperial College London,,Maximizing acquisition functions for Bayesian optimization
neurips,2018,0,6570,Shashank,Singh,,Carnegie Mellon University,,Nonparametric Density Estimation under Adversarial Losses
neurips,2018,1,6570,Ananya,Uppal,,Carnegie Mellon University,,Nonparametric Density Estimation under Adversarial Losses
neurips,2018,2,6570,Boyue,Li,,Carnegie Mellon University,,Nonparametric Density Estimation under Adversarial Losses
neurips,2018,3,6570,Chun-Liang,Li,,Carnegie Mellon University,,Nonparametric Density Estimation under Adversarial Losses
neurips,2018,4,6570,Manzil,Zaheer,,Google,,Nonparametric Density Estimation under Adversarial Losses
neurips,2018,5,6570,Barnabas,Poczos,,Carnegie Mellon University,,Nonparametric Density Estimation under Adversarial Losses
neurips,2018,0,1587,Xuguang,Duan,outlook,Tsinghua University,duan_xg@outlook.com,Weakly Supervised Dense Event Captioning in Videos
neurips,2018,1,1587,Wenbing,Huang,126,Tencent AI Lab,hwenbing@126.com,Weakly Supervised Dense Event Captioning in Videos
neurips,2018,2,1587,Chuang,Gan,gmail,MIT-IBM Watson AI Lab,ganchuang1990@gmail.com,Weakly Supervised Dense Event Captioning in Videos
neurips,2018,3,1587,Jingdong,Wang,microsoft,"Microsoft Research,",jingdw@microsoft.com,Weakly Supervised Dense Event Captioning in Videos
neurips,2018,4,1587,Wenwu,Zhu,tsinghua,Tsinghua University,wwzhu@tsinghua.edu.cn,Weakly Supervised Dense Event Captioning in Videos
neurips,2018,5,1587,Junzhou,Huang,tencent,University of Texas at Arlington / Tencent AI Lab,joehhuang@tencent.com,Weakly Supervised Dense Event Captioning in Videos
neurips,2018,0,1504,Elliot,Crowley,ed,University of Edinburgh,elliot.j.crowley@ed.ac.uk,Moonshine: Distilling with Cheap Convolutions
neurips,2018,1,1504,Gavin,Gray,ed,University of Edinburgh,g.d.b.gray@ed.ac.uk,Moonshine: Distilling with Cheap Convolutions
neurips,2018,2,1504,Amos,Storkey,ed,University of Edinburgh,a.storkey@ed.ac.uk,Moonshine: Distilling with Cheap Convolutions
neurips,2018,0,2521,Neha,Gupta,stanford,Stanford University,sidford@stanford.edu,Exploiting Numerical Sparsity for Efficient Learning : Faster Eigenvector Computation and Regression
neurips,2018,1,2521,Aaron,Sidford,stanford,Stanford,nehagupta@cs.stanford.edu,Exploiting Numerical Sparsity for Efficient Learning : Faster Eigenvector Computation and Regression
neurips,2018,0,3253,Blake,Woodworth,,TTI-Chicago,,The Everlasting Database: Statistical Validity at a Fair Price
neurips,2018,1,3253,Vitaly,Feldman,,Google Brain,,The Everlasting Database: Statistical Validity at a Fair Price
neurips,2018,2,3253,Saharon,Rosset,,Technion,,The Everlasting Database: Statistical Validity at a Fair Price
neurips,2018,3,3253,Nati,Srebro,,TTI-Chicago,,The Everlasting Database: Statistical Validity at a Fair Price
neurips,2018,0,5053,Will,Norcliffe-Brown,aimbrain,AimBrain,will.norcliffe@aimbrain.com,Learning Conditioned Graph Structures for Interpretable Visual Question Answering
neurips,2018,1,5053,Stathis,Vafeias,aimbrain,AimBrain,stathis@aimbrain.com,Learning Conditioned Graph Structures for Interpretable Visual Question Answering
neurips,2018,2,5053,Sarah,Parisot,aimbrain,Huawei,sarah@aimbrain.com,Learning Conditioned Graph Structures for Interpretable Visual Question Answering
neurips,2018,0,3106,Qing,Wang,tencent,Tencent AI Lab,drwang@tencent.com,Exponentially Weighted Imitation Learning for Batched Historical Data
neurips,2018,1,3106,Jiechao,Xiong,tencent,Tencent AI Lab,jcxiong@tencent.com,Exponentially Weighted Imitation Learning for Batched Historical Data
neurips,2018,2,3106,Lei,Han,tencent,,lxhan@tencent.com,Exponentially Weighted Imitation Learning for Batched Historical Data
neurips,2018,3,3106,peng,sun,tencent,Tencent AI Lab,pythonsun@tencent.com,Exponentially Weighted Imitation Learning for Batched Historical Data
neurips,2018,4,3106,Han,Liu,northwestern,Tencent AI Lab,hanliu@northwestern.edu,Exponentially Weighted Imitation Learning for Batched Historical Data
neurips,2018,5,3106,Tong,Zhang,tongzhang-ml,Tencent AI Lab,tongzhang@tongzhang-ml.org,Exponentially Weighted Imitation Learning for Batched Historical Data
neurips,2018,0,894,Pierre,Thodoroff,mcgill,McGill,pierre.thodoroff@mail.mcgill.ca,Temporal Regularization for Markov Decision Process
neurips,2018,1,894,Audrey,Durand,mcgill,McGill University,audrey.durand@mcgill.ca,Temporal Regularization for Markov Decision Process
neurips,2018,2,894,Joelle,Pineau,mcgill,McGill University,jpineau@cs.mcgill.ca,Temporal Regularization for Markov Decision Process
neurips,2018,3,894,Doina,Precup,mcgill,McGill University / DeepMind Montreal,dprecup@cs.mcgill.ca,Temporal Regularization for Markov Decision Process
neurips,2018,0,2204,Wenbo,Guo,psu,Pennsylvania State University,wzg13@ist.psu.edu,Explaining Deep Learning Models -- A Bayesian Non-parametric Approach
neurips,2018,1,2204,Sui,Huang,netflix,Netflix,shuang@netflix.com,Explaining Deep Learning Models -- A Bayesian Non-parametric Approach
neurips,2018,2,2204,Yunzhe,Tao,columbia,Columbia University,y.tao@columbia.edu,Explaining Deep Learning Models -- A Bayesian Non-parametric Approach
neurips,2018,3,2204,Xinyu,Xing,psu,Penn State University,xxing@ist.psu.edu,Explaining Deep Learning Models -- A Bayesian Non-parametric Approach
neurips,2018,4,2204,Lin,Lin,psu,The Pennsylvania State University,llin@psu.edu,Explaining Deep Learning Models -- A Bayesian Non-parametric Approach
neurips,2018,0,2116,Yining,Wang,,CMU,,Optimization of Smooth Functions with Noisy Observations: Local Minimax Rates
neurips,2018,1,2116,Sivaraman,Balakrishnan,,Carnegie Mellon University,,Optimization of Smooth Functions with Noisy Observations: Local Minimax Rates
neurips,2018,2,2116,Aarti,Singh,,CMU,,Optimization of Smooth Functions with Noisy Observations: Local Minimax Rates
neurips,2018,0,2372,Leena,Chennuru Vankadara,mpg,Max Planck Institute for Intelligent Systems,leena.chennuru@tuebingen.mpg.de,Measures of distortion for machine learning
neurips,2018,1,2372,Ulrike,von Luxburg,uni-tuebingen,University of Tübingen,luxburg@informatik.uni-tuebingen.de,Measures of distortion for machine learning
neurips,2018,0,182,Yiwen,Guo,tsinghua,Intel Labs China,zcs@mail.tsinghua.edu.cn,Sparse DNNs with Improved Adversarial Robustness
neurips,2018,1,182,Chao,Zhang,intel,Peking University,yiwen.guo@intel.com,Sparse DNNs with Improved Adversarial Robustness
neurips,2018,2,182,Changshui,Zhang,intel,Tsinghua University,yurong.chen@intel.com,Sparse DNNs with Improved Adversarial Robustness
neurips,2018,3,182,Yurong,Chen,pku,Intel Labs China,pkuzc@pku.edu.cn,Sparse DNNs with Improved Adversarial Robustness
neurips,2018,0,5810,Oana-Maria,Camburu,ox,University of Oxford,oana-maria.camburu@cs.ox.ac.uk,e-SNLI: Natural Language Inference with Natural Language Explanations
neurips,2018,1,5810,Tim,Rocktäschel,ox,University of Oxford,thomas.lukasiewicz@cs.ox.ac.uk,e-SNLI: Natural Language Inference with Natural Language Explanations
neurips,2018,2,5810,Thomas,Lukasiewicz,ox,University of Oxford,phil.blunsom@cs.ox.ac.uk,e-SNLI: Natural Language Inference with Natural Language Explanations
neurips,2018,3,5810,Phil,Blunsom,ucl,Oxford University,t.rocktaschel@ucl.ac.uk,e-SNLI: Natural Language Inference with Natural Language Explanations
neurips,2018,0,6523,CHEN,LIN,sensetime,SenseTime,linchen@sensetime.com,Synaptic Strength For Convolutional Neural Network
neurips,2018,1,6523,Zhao,Zhong,sensetime,CASIA (Institute of Automation Chinese Academy of Sciences),wuwei@sensetime.com,Synaptic Strength For Convolutional Neural Network
neurips,2018,2,6523,Wu,Wei,ia,Sensetime,zhao.zhong@nlpr.ia.ac.cn,Synaptic Strength For Convolutional Neural Network
neurips,2018,3,6523,Junjie,Yan,sensetime,Sensetime Group Limited,yanjunjie@sensetime.com,Synaptic Strength For Convolutional Neural Network
neurips,2018,0,2533,Abhishek,Gupta,berkeley,"University of California, Berkeley",abhigupta@eecs.berkeley.edu,Meta-Reinforcement Learning of Structured Exploration Strategies
neurips,2018,1,2533,Russell,Mendonca,berkeley,UC Berkeley,pabbeel@eecs.berkeley.edu,Meta-Reinforcement Learning of Structured Exploration Strategies
neurips,2018,2,2533,YuXuan,Liu,berkeley,UC Berkeley,svlevine@eecs.berkeley.edu,Meta-Reinforcement Learning of Structured Exploration Strategies
neurips,2018,3,2533,Pieter,Abbeel,berkeley,UC Berkeley | Gradescope | Covariant,russellm@berkeley.edu,Meta-Reinforcement Learning of Structured Exploration Strategies
neurips,2018,4,2533,Sergey,Levine,berkeley,UC Berkeley,yuxuanliu@berkeley.edu,Meta-Reinforcement Learning of Structured Exploration Strategies
neurips,2018,0,2816,Trong Dinh Thac,Do,gmail,University of Technology Sydney,thacdtd@gmail.com,Gamma-Poisson Dynamic Matrix Factorization Embedded with Metadata Influence
neurips,2018,1,2816,Longbing,Cao,gmail,University of Technology Sydney,longbing.cao@gmail.com,Gamma-Poisson Dynamic Matrix Factorization Embedded with Metadata Influence
neurips,2018,0,562,Tengyang,Xie,umass,University of Massachusetts Amherst,txie@cs.umass.edu,A Block Coordinate Ascent Algorithm for Mean-Variance Optimization
neurips,2018,1,562,Bo,Liu,auburn,Auburn University,boliu@auburn.edu,A Block Coordinate Ascent Algorithm for Mean-Variance Optimization
neurips,2018,2,562,Yangyang,Xu,rpi,Rensselaer Polytechnic Institute,xuy21@rpi.edu,A Block Coordinate Ascent Algorithm for Mean-Variance Optimization
neurips,2018,3,562,Mohammad,Ghavamzadeh,fb,FaceBook FAIR,mgh@fb.com,A Block Coordinate Ascent Algorithm for Mean-Variance Optimization
neurips,2018,4,562,Yinlam,Chow,google,DeepMind,yinlamchow@google.com,A Block Coordinate Ascent Algorithm for Mean-Variance Optimization
neurips,2018,5,562,Daoming,Lyu,auburn,Auburn University,daoming.lyu@auburn.edu,A Block Coordinate Ascent Algorithm for Mean-Variance Optimization
neurips,2018,6,562,Daesub,Yoon,re,ETRI,eyetracker@etri.re.kr,A Block Coordinate Ascent Algorithm for Mean-Variance Optimization
neurips,2018,0,1207,Ruixiang,ZHANG,gmail,MILA,sodabeta7@gmail.com,MetaGAN: An Adversarial Approach to Few-Shot Learning
neurips,2018,1,1207,Tong,Che,gmail,MILA,tongcheprivate@gmail.com,MetaGAN: An Adversarial Approach to Few-Shot Learning
neurips,2018,2,1207,Zoubin,Ghahramani,cam,Uber and University of Cambridge,zoubin@cam.ac.uk,MetaGAN: An Adversarial Approach to Few-Shot Learning
neurips,2018,3,1207,Yoshua,Bengio,mila,U. Montreal,yoshua.bengio@mila.quebec,MetaGAN: An Adversarial Approach to Few-Shot Learning
neurips,2018,4,1207,Yangqiu,Song,ust,Hong Kong University of Science and Technology,yqsong@cse.ust.hk,MetaGAN: An Adversarial Approach to Few-Shot Learning
neurips,2018,0,5390,Mojmir,Mutny,ethz,ETH Zurich,krausea@inf.ethz.ch,Efficient High Dimensional Bayesian Optimization with Additivity and Quadrature Fourier Features
neurips,2018,1,5390,Andreas,Krause,ethz,ETH Zurich,mojmir.mutny@inf.ethz.ch,Efficient High Dimensional Bayesian Optimization with Additivity and Quadrature Fourier Features
neurips,2018,0,2136,Lin,Yang,princeton,Princeton University,lin.yang@princeton.edu,The Physical Systems Behind Optimization Algorithms
neurips,2018,1,2136,Raman,Arora,jhu,Johns Hopkins University,arora@cs.jhu.edu,The Physical Systems Behind Optimization Algorithms
neurips,2018,2,2136,Vladimir,braverman,jhu,Johns Hopkins University,vova@cs.jhu.edu,The Physical Systems Behind Optimization Algorithms
neurips,2018,3,2136,Tuo,Zhao,gatech,Georgia Tech,tourzhao@gatech.edu,The Physical Systems Behind Optimization Algorithms
neurips,2018,0,1481,Eldar,Insafutdinov,mpg,Max Planck Institute for Informatics,eldar@mpi-inf.mpg.de,Unsupervised Learning of Shape and Pose with Differentiable Point Clouds
neurips,2018,1,1481,Alexey,Dosovitskiy,gmail,Intel Labs,adosovitskiy@gmail.com,Unsupervised Learning of Shape and Pose with Differentiable Point Clouds
neurips,2018,0,1862,Youssef,Alami Mejjati,bath,University of Bath,yam28@bath.ac.uk,Unsupervised Attention-guided Image-to-Image Translation
neurips,2018,1,1862,Christian,Richardt,richardt,University of Bath,christian@richardt.name,Unsupervised Attention-guided Image-to-Image Translation
neurips,2018,2,1862,James,Tompkin,brown,Brown University,james_tompkin@brown.edu,Unsupervised Attention-guided Image-to-Image Translation
neurips,2018,3,1862,Darren,Cosker,bath,University of Bath,D.P.Cosker@bath.ac.uk,Unsupervised Attention-guided Image-to-Image Translation
neurips,2018,4,1862,Kwang In,Kim,bath,University of Bath,k.kim@bath.ac.uk,Unsupervised Attention-guided Image-to-Image Translation
neurips,2018,0,2598,John,Halloran,ucdavis,"University of California, Davis",jthalloran@ucdavis.edu,Learning Concave Conditional Likelihood Models for Improved Analysis of Tandem Mass Spectra
neurips,2018,1,2598,David,Rocke,ucdavis,"University of California, Davis",dmrocke@ucdavis.edu,Learning Concave Conditional Likelihood Models for Improved Analysis of Tandem Mass Spectra
neurips,2018,0,5558,Yin,Li,wisc,University of Wisconsin-Madison,yin.li@wisc.edu,Beyond Grids: Learning Graph Representations for Visual Recognition
neurips,2018,1,5558,Abhinav,Gupta,cmu,Facebook AI Research/CMU,abhinavg@cs.cmu.edu,Beyond Grids: Learning Graph Representations for Visual Recognition
neurips,2018,0,4952,Tal,Friedman,ucla,UCLA,tal@cs.ucla.edu,Approximate Knowledge Compilation by Online Collapsed Importance Sampling
neurips,2018,1,4952,Guy,Van den Broeck,ucla,UCLA,guyvdb@cs.ucla.edu,Approximate Knowledge Compilation by Online Collapsed Importance Sampling
neurips,2018,0,4923,Tianyu,He,ustc,University of Science and Technology of China,hetianyu@mail.ustc.edu.cn,Layer-Wise Coordination between Encoder and Decoder for Neural Machine Translation
neurips,2018,1,4923,Xu,Tan,microsoft,Microsoft Research,xuta@microsoft.com,Layer-Wise Coordination between Encoder and Decoder for Neural Machine Translation
neurips,2018,2,4923,Yingce,Xia,microsoft,Microsoft Research,yingce.xia@microsoft.com,Layer-Wise Coordination between Encoder and Decoder for Neural Machine Translation
neurips,2018,3,4923,Di,He,pku,Peking University,di_he@pku.edu.cn,Layer-Wise Coordination between Encoder and Decoder for Neural Machine Translation
neurips,2018,4,4923,Tao,Qin,microsoft,Microsoft Research,taoqin@microsoft.com,Layer-Wise Coordination between Encoder and Decoder for Neural Machine Translation
neurips,2018,5,4923,Zhibo,Chen,ustc,University of Science and Technology of China,chenzhibo@ustc.edu.cn,Layer-Wise Coordination between Encoder and Decoder for Neural Machine Translation
neurips,2018,6,4923,Tie-Yan,Liu,microsoft,Microsoft Research Asia,tie-yan.liu@microsoft.com,Layer-Wise Coordination between Encoder and Decoder for Neural Machine Translation
neurips,2018,0,4976,Yinlam,Chow,,DeepMind,,A Lyapunov-based Approach to Safe Reinforcement Learning
neurips,2018,1,4976,Ofir,Nachum,,Google Brain,,A Lyapunov-based Approach to Safe Reinforcement Learning
neurips,2018,2,4976,Edgar,Duenez-Guzman,,DeepMind,,A Lyapunov-based Approach to Safe Reinforcement Learning
neurips,2018,3,4976,Mohammad,Ghavamzadeh,,FaceBook FAIR,,A Lyapunov-based Approach to Safe Reinforcement Learning
neurips,2018,0,5410,Matthew,MacKay,toronto,University of Toronto,mmackay@cs.toronto.edu,Reversible Recurrent Neural Networks
neurips,2018,1,5410,Paul,Vicol,toronto,University of Toronto,pvicol@cs.toronto.edu,Reversible Recurrent Neural Networks
neurips,2018,2,5410,Jimmy,Ba,toronto,University of Toronto / Vector Institute,jba@cs.toronto.edu,Reversible Recurrent Neural Networks
neurips,2018,3,5410,Roger,Grosse,toronto,University of Toronto,rgrosse@cs.toronto.edu,Reversible Recurrent Neural Networks
neurips,2018,0,5118,Dandan,Guo,126,Xidian University,gdd_xidian@126.com,Deep Poisson gamma dynamical systems
neurips,2018,1,5118,Bo,Chen,xidian,Xidian University,bchen@mail.xidian.edu.cn,Deep Poisson gamma dynamical systems
neurips,2018,2,5118,Hao,Zhang,163,Xidian University,zhanghao_xidian@163.com,Deep Poisson gamma dynamical systems
neurips,2018,3,5118,Mingyuan,Zhou,utexas,University of Texas at Austin,mingyuan.zhou@mccombs.utexas.edu,Deep Poisson gamma dynamical systems
neurips,2018,0,707,Ira,Shavitt,gmail,Weizmann Institute of Science,irashavitt@gmail.com,Regularization Learning Networks: Deep Learning for Tabular Datasets
neurips,2018,1,707,Eran,Segal,weizmann,Weizmann Institute of Science,eran.segal@weizmann.ac.il,Regularization Learning Networks: Deep Learning for Tabular Datasets
neurips,2018,0,1314,Stephen,Gillen,upenn,University of Pennsylvania,stepe@math.upenn.edu,Online Learning with an Unknown Fairness Metric
neurips,2018,1,1314,Christopher,Jung,upenn,University of Pennsylvania,chrjung@cis.upenn.edu,Online Learning with an Unknown Fairness Metric
neurips,2018,2,1314,Michael,Kearns,upenn,University of Pennsylvania,mkearns@cis.upenn.edu,Online Learning with an Unknown Fairness Metric
neurips,2018,3,1314,Aaron,Roth,upenn,University of Pennsylvania,aaroth@cis.upenn.edu,Online Learning with an Unknown Fairness Metric
neurips,2018,0,2114,Nan,Jiang,,University of Illinois at Urbana-Champaign,,Completing State Representations using Spectral Learning
neurips,2018,1,2114,Alex,Kulesza,,Google,,Completing State Representations using Spectral Learning
neurips,2018,2,2114,Satinder,Singh,,University of Michigan,,Completing State Representations using Spectral Learning
neurips,2018,0,1591,Hao(Jackson),Cui,tufts,Tufts University,hao.cui@tufts.edu,From Stochastic Planning to Marginal MAP
neurips,2018,1,1591,Radu,Marinescu,ibm,IBM Research,radu.marinescu@ie.ibm.com,From Stochastic Planning to Marginal MAP
neurips,2018,2,1591,Roni,Khardon,iu,"Indiana University, Bloomington",rkhardon@iu.edu,From Stochastic Planning to Marginal MAP
neurips,2018,0,462,Tianshu,Yu,asu,Arizona State University,tianshuy@asu.edu,Generalizing Graph Matching beyond Quadratic Assignment Model
neurips,2018,1,462,Junchi,Yan,sjtu,Shanghai Jiao Tong University,yanjunchi@sjtu.edu.cn,Generalizing Graph Matching beyond Quadratic Assignment Model
neurips,2018,2,462,Yilin,Wang,adobe,Adobe,yilwang@adobe.com,Generalizing Graph Matching beyond Quadratic Assignment Model
neurips,2018,3,462,Wei,Liu,columbia,Tencent AI Lab,wl2223@columbia.edu,Generalizing Graph Matching beyond Quadratic Assignment Model
neurips,2018,4,462,baoxin,Li,asu,Arizona State University,baoxin.li@asu.edu,Generalizing Graph Matching beyond Quadratic Assignment Model
neurips,2018,0,2269,Zeyu,Zheng,umich,University of Michigan,zeyu@umich.edu,On Learning Intrinsic Rewards for Policy Gradient Methods
neurips,2018,1,2269,Junhyuk,Oh,umich,DeepMind,junhyuk@umich.edu,On Learning Intrinsic Rewards for Policy Gradient Methods
neurips,2018,2,2269,Satinder,Singh,umich,University of Michigan,baveja@umich.edu,On Learning Intrinsic Rewards for Policy Gradient Methods
neurips,2018,0,1078,Etai,Littwin,,Apple,,Regularizing by the Variance of the Activations' Sample-Variances
neurips,2018,1,1078,Lior,Wolf,,Facebook AI Research,,Regularizing by the Variance of the Activations' Sample-Variances
neurips,2018,0,1637,Laurent,Orseau,google,DeepMind,lorseau@google.com,Single-Agent Policy Tree Search With Guarantees
neurips,2018,1,1637,Levi,Lelis,ufv,Universidade Federal de Viçosa,levi.lelis@ufv.br,Single-Agent Policy Tree Search With Guarantees
neurips,2018,2,1637,Tor,Lattimore,google,DeepMind,lattimore@google.com,Single-Agent Policy Tree Search With Guarantees
neurips,2018,3,1637,Theophane,Weber,google,DeepMind,theophane@google.com,Single-Agent Policy Tree Search With Guarantees
neurips,2018,0,6882,Shengjia,Zhao,stanford,Stanford University,sjzhao@stanford.edu,Bias and Generalization in Deep Generative Models: An Empirical Study
neurips,2018,1,6882,Hongyu,Ren,stanford,Stanford University,hyren@stanford.edu,Bias and Generalization in Deep Generative Models: An Empirical Study
neurips,2018,2,6882,Arianna,Yuan,stanford,Stanford University,xfyuan@stanford.edu,Bias and Generalization in Deep Generative Models: An Empirical Study
neurips,2018,3,6882,Jiaming,Song,stanford,Stanford University,tsong@stanford.edu,Bias and Generalization in Deep Generative Models: An Empirical Study
neurips,2018,4,6882,Noah,Goodman,stanford,Stanford University,ngoodman@stanford.edu,Bias and Generalization in Deep Generative Models: An Empirical Study
neurips,2018,5,6882,Stefano,Ermon,stanford,Stanford,ermon@stanford.edu,Bias and Generalization in Deep Generative Models: An Empirical Study
neurips,2018,0,6863,David,Minnen,google,Google,dminnen@google.com,Joint Autoregressive and Hierarchical Priors for Learned Image Compression
neurips,2018,1,6863,Johannes,Ballé,google,Google,jballe@google.com,Joint Autoregressive and Hierarchical Priors for Learned Image Compression
neurips,2018,2,6863,George,Toderici,google,Google,gtoderici@google.com,Joint Autoregressive and Hierarchical Priors for Learned Image Compression
neurips,2018,0,2478,Muhan,Zhang,wustl,Washington University in St. Louis,muhan@wustl.edu,Link Prediction Based on Graph Neural Networks
neurips,2018,1,2478,Yixin,Chen,wustl,Washington University in St. Louis,chen@cse.wustl.edu,Link Prediction Based on Graph Neural Networks
neurips,2018,0,522,Guilhem,Chéron,,Inria,,A flexible model for training action localization with varying levels of supervision
neurips,2018,1,522,Jean-Baptiste,Alayrac,,Deepmind,,A flexible model for training action localization with varying levels of supervision
neurips,2018,2,522,Ivan,Laptev,,INRIA,,A flexible model for training action localization with varying levels of supervision
neurips,2018,3,522,Cordelia,Schmid,,Inria / Google,,A flexible model for training action localization with varying levels of supervision
neurips,2018,0,3518,Sabyasachi,Shivkumar,rochester,University of Rochester,sshivkum@ur.rochester.edu,A probabilistic population code based on neural samples
neurips,2018,1,3518,Richard,Lange,rochester,University of Rochester,rlange@ur.rochester.edu,A probabilistic population code based on neural samples
neurips,2018,2,3518,Ankani,Chattoraj,rochester,University of Rochester,achattor@ur.rochester.edu,A probabilistic population code based on neural samples
neurips,2018,3,3518,Ralf,Haefner,rochester,"Brain & Cognitive Sciences, University of Rochester",rhaefne2@ur.rochester.edu,A probabilistic population code based on neural samples
neurips,2018,0,3427,Stanislav,Pidhorskyi,,Lane Department of Computer Science and Electrical Engineering of West Virginia University,,Generative Probabilistic Novelty Detection with Adversarial Autoencoders
neurips,2018,1,3427,Ranya,Almohsen,,West Virginia University,,Generative Probabilistic Novelty Detection with Adversarial Autoencoders
neurips,2018,2,3427,Gianfranco,Doretto,,West Virginia University,,Generative Probabilistic Novelty Detection with Adversarial Autoencoders
neurips,2018,0,4906,Jongmin,Lee,kaist,KAIST,jmlee@ai.kaist.ac.kr,Monte-Carlo Tree Search for Constrained POMDPs
neurips,2018,1,4906,Geon-hyeong,Kim,kaist,KAIST,ghkim@ai.kaist.ac.kr,Monte-Carlo Tree Search for Constrained POMDPs
neurips,2018,2,4906,Pascal,Poupart,uwaterloo,University of Waterloo & RBC Borealis AI,ppoupart@uwaterloo.ca,Monte-Carlo Tree Search for Constrained POMDPs
neurips,2018,3,4906,Kee-Eung,Kim,kaist,KAIST,kekim@cs.kaist.ac.kr,Monte-Carlo Tree Search for Constrained POMDPs
neurips,2018,0,4999,Yuanzhi,Li,,Princeton,,Learning Overparameterized Neural Networks via Stochastic Gradient Descent on Structured Data
neurips,2018,1,4999,Yingyu,Liang,,University of Wisconsin Madison,,Learning Overparameterized Neural Networks via Stochastic Gradient Descent on Structured Data
neurips,2018,0,444,Wittawat,Jitkrittum,mpg,Max Planck Institute for Intelligent Systems,wittawat@tuebingen.mpg.de,Informative Features for Model Comparison
neurips,2018,1,444,Heishiro,Kanagawa,ucl,"Gatsby Unit, University College London",heishirok@gatsby.ucl.ac.uk,Informative Features for Model Comparison
neurips,2018,2,444,Patsorn,Sangkloy,gatech,Georgia Institute of Technology,patsorn_sangkloy@gatech.edu,Informative Features for Model Comparison
neurips,2018,3,444,James,Hays,gatech,"Georgia Institute of Technology, USA",hays@gatech.edu,Informative Features for Model Comparison
neurips,2018,4,444,Bernhard,Schölkopf,mpg,MPI for Intelligent Systems,bernhard.schoelkopf@tuebingen.mpg.de,Informative Features for Model Comparison
neurips,2018,5,444,Arthur,Gretton,gmail,"Gatsby Unit, UCL",arthur.gretton@gmail.com,Informative Features for Model Comparison
neurips,2018,0,492,Zhuangwei,Zhuang,scut,SCUT,z.zhuangwei@mail.scut.edu.cn,Discrimination-aware Channel Pruning for Deep Neural Networks
neurips,2018,1,492,Mingkui,Tan,scut,South China University of Technology,seliujing@mail.scut.edu.cn,Discrimination-aware Channel Pruning for Deep Neural Networks
neurips,2018,2,492,Bohan,Zhuang,scut,The University of Adelaide,guo.yong@mail.scut.edu.cn,Discrimination-aware Channel Pruning for Deep Neural Networks
neurips,2018,3,492,Jing,Liu,uta,South China University of Technology,jzhuang@uta.edu,Discrimination-aware Channel Pruning for Deep Neural Networks
neurips,2018,4,492,Yong,Guo,scut,South China University of Technology,mingkuitan@scut.edu.cn,Discrimination-aware Channel Pruning for Deep Neural Networks
neurips,2018,5,492,Qingyao,Wu,scut,South China University of Technology,qyw@scut.edu.cn,Discrimination-aware Channel Pruning for Deep Neural Networks
neurips,2018,6,492,Junzhou,Huang,scut,University of Texas at Arlington / Tencent AI Lab,csjhzhu@scut.edu.cn,Discrimination-aware Channel Pruning for Deep Neural Networks
neurips,2018,7,492,Jinhui,Zhu,adelaide,SCUT,bohan.zhuang@adelaide.edu.au,Discrimination-aware Channel Pruning for Deep Neural Networks
neurips,2018,0,5309,Cezary,Kaliszyk,,Innsbruck University,,Reinforcement Learning of Theorem Proving
neurips,2018,1,5309,Josef,Urban,,Czech Technical University in Prague,,Reinforcement Learning of Theorem Proving
neurips,2018,2,5309,Henryk,Michalewski,,"University of Warsaw, University of Oxford, deepsense.ai",,Reinforcement Learning of Theorem Proving
neurips,2018,3,5309,Miroslav,Olák,,Charles University in Prague,,Reinforcement Learning of Theorem Proving
neurips,2018,0,2739,Alessandro,Rudi,,"INRIA, Ecole Normale Superieure",,On Fast Leverage Score Sampling and Optimal Learning
neurips,2018,1,2739,Daniele,Calandriello,,LCSL IIT/MIT,,On Fast Leverage Score Sampling and Optimal Learning
neurips,2018,2,2739,Luigi,Carratino,,University of Genoa,,On Fast Leverage Score Sampling and Optimal Learning
neurips,2018,3,2739,Lorenzo,Rosasco,,University of Genova- MIT - IIT,,On Fast Leverage Score Sampling and Optimal Learning
neurips,2018,0,6588,Kiran,Thekumparampil,,Univ. of Illinois at Urbana-Champaign,,Robustness of conditional GANs to noisy labels
neurips,2018,1,6588,Ashish,Khetan,,Amazon AI Labs,,Robustness of conditional GANs to noisy labels
neurips,2018,2,6588,Zinan,Lin,,Carnegie Mellon University,,Robustness of conditional GANs to noisy labels
neurips,2018,3,6588,Sewoong,Oh,,University of Washington,,Robustness of conditional GANs to noisy labels
neurips,2018,0,6972,Nathan,Kallus,cornell,Cornell University,kallus@cornell.edu,Removing Hidden Confounding by Experimental Grounding
neurips,2018,1,6972,Aahlad Manas,Puli,nyu,NYU,apm470@nyu.edu,Removing Hidden Confounding by Experimental Grounding
neurips,2018,2,6972,Uri,Shalit,technion,Technion,urishalit@technion.ac.il,Removing Hidden Confounding by Experimental Grounding
neurips,2018,0,5299,Mahito,Sugiyama,riken,National Institute of Informatics,hiro@brain.riken.jp,Legendre Decomposition for Tensors
neurips,2018,1,5299,Hiroyuki,Nakahara,nii,RIKEN Brain Science Institute,mahito@nii.ac.jp,Legendre Decomposition for Tensors
neurips,2018,2,5299,Koji,Tsuda,u-tokyo,The University of Tokyo / RIKEN,tsuda@k.u-tokyo.ac.jp,Legendre Decomposition for Tensors
neurips,2018,0,5045,Jordan,Frecon,,Istituto Italiano di Tecnologia,,Bilevel learning of the Group Lasso structure
neurips,2018,1,5045,Saverio,Salzo,,Istituto Italiano di Tecnologia,,Bilevel learning of the Group Lasso structure
neurips,2018,2,5045,Massimiliano,Pontil,,IIT & UCL,,Bilevel learning of the Group Lasso structure
neurips,2018,0,5412,Alexandre,Defossez,fb,Facebook,defossez@fb.com,SING: Symbol-to-Instrument Neural Generator
neurips,2018,1,5412,Neil,Zeghidour,fb,Facebook A.I. Research / Ecole Normale Supérieure,neilz@fb.com,SING: Symbol-to-Instrument Neural Generator
neurips,2018,2,5412,Nicolas,Usunier,fb,Facebook AI Research,usunier@fb.com,SING: Symbol-to-Instrument Neural Generator
neurips,2018,3,5412,Leon,Bottou,fb,Facebook AI Research,leonb@fb.com,SING: Symbol-to-Instrument Neural Generator
neurips,2018,4,5412,Francis,Bach,ens,INRIA - Ecole Normale Superieure,francis.bach@ens.fr,SING: Symbol-to-Instrument Neural Generator
neurips,2018,0,3722,Bryan,Lim,,University of Oxford,,Forecasting Treatment Responses Over Time Using Recurrent Marginal Structural Networks
neurips,2018,0,1842,Daniel,Ting,tableau,Tableau Software,dting@tableau.com,Optimal Subsampling with Influence Functions
neurips,2018,1,1842,Eric,Brochu,tableau,Tableau Software,ebrochu@tableau.com,Optimal Subsampling with Influence Functions
neurips,2018,0,342,Sanghyun,Woo,kaist,KAIST,shwoo93@kaist.ac.kr,LinkNet: Relational Embedding for Scene Graph
neurips,2018,1,342,Dahun,Kim,kaist,KAIST,mcahny@kaist.ac.kr,LinkNet: Relational Embedding for Scene Graph
neurips,2018,2,342,Donghyeon,Cho,kaist,KAIST,iskweon@kaist.ac.kr,LinkNet: Relational Embedding for Scene Graph
neurips,2018,3,342,In So,Kweon,gmail,KAIST,cdh12242@gmail.com,LinkNet: Relational Embedding for Scene Graph
neurips,2018,0,2052,Tongzhou,Wang,gmail,Facebook AI Research,tongzhou.wang.1994@gmail.com,Meta-Learning MCMC Proposals
neurips,2018,1,2052,YI,WU,gmail,UC Berkeley,jxwuyi@gmail.com,Meta-Learning MCMC Proposals
neurips,2018,2,2052,Dave,Moore,gmail,Google,davmre@gmail.com,Meta-Learning MCMC Proposals
neurips,2018,3,2052,Stuart,Russell,berkeley,UC Berkeley,russell@cs.berkeley.edu,Meta-Learning MCMC Proposals
neurips,2018,0,3442,Nanyang,Ye,,University of Cambridge,,Bayesian Adversarial Learning
neurips,2018,1,3442,Zhanxing,Zhu,,Peking University,,Bayesian Adversarial Learning
neurips,2018,0,192,Tolga,Birdal,,Technical University of Munich,,Bayesian Pose Graph Optimization via Bingham Distributions and Tempered Geodesic MCMC
neurips,2018,1,192,Umut,Simsekli,,Telecom ParisTech,,Bayesian Pose Graph Optimization via Bingham Distributions and Tempered Geodesic MCMC
neurips,2018,2,192,Mustafa Onur,Eken,,Technical University of Munich,,Bayesian Pose Graph Optimization via Bingham Distributions and Tempered Geodesic MCMC
neurips,2018,3,192,Slobodan,Ilic,,Siemens AG,,Bayesian Pose Graph Optimization via Bingham Distributions and Tempered Geodesic MCMC
neurips,2018,0,561,Pan,Li,illinois,University of Illinois Urbana-Champaign,panli2@illinois.edu,Quadratic Decomposable Submodular Function Minimization
neurips,2018,1,561,Niao,He,illinois,UIUC,niaohe@illinois.edu,Quadratic Decomposable Submodular Function Minimization
neurips,2018,2,561,Olgica,Milenkovic,illinois,University of Illinois at Urbana-Champaign,milenkov@illinois.edu,Quadratic Decomposable Submodular Function Minimization
neurips,2018,0,3335,Sheng,Chen,umn,University of Minnesota,chen2832@umn.edu,An Improved Analysis of Alternating Minimization for Structured Multi-Response Regression
neurips,2018,1,3335,Arindam,Banerjee,umn,Voleon,banerjee@cs.umn.edu,An Improved Analysis of Alternating Minimization for Structured Multi-Response Regression
neurips,2018,0,5274,Dylan,Foster,cornell,Cornell University,djfoster@cornell.edu,Uniform Convergence of Gradients for Non-Convex Learning and Optimization
neurips,2018,1,5274,Ayush,Sekhari,cornell,Cornell University,sekhari@cs.cornell.edu,Uniform Convergence of Gradients for Non-Convex Learning and Optimization
neurips,2018,2,5274,Karthik,Sridharan,cornell,Cornell University,sridharan@cs.cornell.edu,Uniform Convergence of Gradients for Non-Convex Learning and Optimization
neurips,2018,0,514,Nicholas,Polson,,Chicago Booth,,Posterior Concentration for Sparse Deep Learning
neurips,2018,1,514,Veronika,Roková,,University of Chicago,,Posterior Concentration for Sparse Deep Learning
neurips,2018,0,1794,Zijun,Wei,,Stony Brook University,,Sequence-to-Segment Networks for Segment Detection
neurips,2018,1,1794,Boyu,Wang,,Stony Brook University,,Sequence-to-Segment Networks for Segment Detection
neurips,2018,2,1794,Minh Hoai,Nguyen,,Stony Brook University,,Sequence-to-Segment Networks for Segment Detection
neurips,2018,3,1794,Jianming,Zhang,,Adobe Research,,Sequence-to-Segment Networks for Segment Detection
neurips,2018,4,1794,Zhe,Lin,,Adobe Research,,Sequence-to-Segment Networks for Segment Detection
neurips,2018,5,1794,Xiaohui,Shen,,ByteDance AI Lab,,Sequence-to-Segment Networks for Segment Detection
neurips,2018,6,1794,Radomir,Mech,,Adobe Systems Incorporated,,Sequence-to-Segment Networks for Segment Detection
neurips,2018,7,1794,Dimitris,Samaras,,Stony Brook University,,Sequence-to-Segment Networks for Segment Detection
neurips,2018,0,6015,Hoi-To,Wai,cuhk,The Chinese University of Hong Kong,htwai@se.cuhk.edu.hk,Multi-Agent Reinforcement Learning via Double Averaging Primal-Dual Optimization
neurips,2018,1,6015,Zhuoran,Yang,princeton,Princeton University,zy6@princeton.edu,Multi-Agent Reinforcement Learning via Double Averaging Primal-Dual Optimization
neurips,2018,2,6015,Zhaoran,Wang,gmail,"Princeton, Phd student",zhaoranwang@gmail.com,Multi-Agent Reinforcement Learning via Double Averaging Primal-Dual Optimization
neurips,2018,3,6015,Mingyi,Hong,umn,University of Minnesota,mhong@umn.edu,Multi-Agent Reinforcement Learning via Double Averaging Primal-Dual Optimization
neurips,2018,0,5153,Arthur,Jacot,netopera,EPFL,arthur.jacot@netopera.net,Neural Tangent Kernel: Convergence and Generalization in Neural Networks
neurips,2018,1,5153,Franck,Gabriel,gmail,EPFL,franckrgabriel@gmail.com,Neural Tangent Kernel: Convergence and Generalization in Neural Networks
neurips,2018,2,5153,Clement,Hongler,gmail,EPFL,clement.hongler@gmail.com,Neural Tangent Kernel: Convergence and Generalization in Neural Networks
neurips,2018,0,5217,Ian,Osband,google,Google Deepmind,iosband@google.com,Randomized Prior Functions for Deep Reinforcement Learning
neurips,2018,1,5217,John,Aslanides,google,DeepMind,jaslanides@google.com,Randomized Prior Functions for Deep Reinforcement Learning
neurips,2018,2,5217,Albin,Cassirer,google,DeepMind,cassirer@google.com,Randomized Prior Functions for Deep Reinforcement Learning
neurips,2018,0,3533,Maziar,Sanjabi,usc,University of Southern California,sanjabi@usc.edu,On the Convergence and Robustness of Training GANs with Regularized Optimal Transport
neurips,2018,1,3533,Jimmy,Ba,usc,,razaviya@usc.edu,On the Convergence and Robustness of Training GANs with Regularized Optimal Transport
neurips,2018,2,3533,Meisam,Razaviyayn,toronto,University of Southern California,jimmy@cs.toronto.edu,On the Convergence and Robustness of Training GANs with Regularized Optimal Transport
neurips,2018,3,3533,Jason,Lee,usc,University of Southern California,jasonlee@marshall.usc.edu,On the Convergence and Robustness of Training GANs with Regularized Optimal Transport
neurips,2018,0,3454,Stephen,Mussmann,stanford,Stanford University,mussmann@stanford.edu,Uncertainty Sampling is Preconditioned Stochastic Gradient Descent on Zero-One Loss
neurips,2018,1,3454,Percy,Liang,stanford,Stanford University,pliang@cs.stanford.edu,Uncertainty Sampling is Preconditioned Stochastic Gradient Descent on Zero-One Loss
neurips,2018,0,2287,Nishant,Desai,berkeley,UC Berkeley,nishantdesai@berkeley.edu,Negotiable Reinforcement Learning for Pareto Optimal Sequential Decision-Making
neurips,2018,1,2287,Andrew,Critch,berkeley,UC Berkeley,critch@berkeley.edu,Negotiable Reinforcement Learning for Pareto Optimal Sequential Decision-Making
neurips,2018,2,2287,Stuart,Russell,berkeley,UC Berkeley,russell@cs.berkeley.edu,Negotiable Reinforcement Learning for Pareto Optimal Sequential Decision-Making
neurips,2018,0,962,Ashok,Cutkosky,google,Google,cutkosky@google.com,Distributed Stochastic Optimization via Adaptive SGD
neurips,2018,1,962,Róbert,Busa-Fekete,oath,Yahoo! Research,busafekete@oath.com,Distributed Stochastic Optimization via Adaptive SGD
neurips,2018,0,6923,Nima,Anari,stanford,Stanford University,anari@cs.stanford.edu,Smoothed Analysis of Discrete Tensor Decomposition and Assemblies of Neurons
neurips,2018,1,6923,Constantinos,Daskalakis,mit,MIT,costis@csail.mit.edu,Smoothed Analysis of Discrete Tensor Decomposition and Assemblies of Neurons
neurips,2018,2,6923,Wolfgang,Maass,tugraz,Graz University of Technology,maass@igi.tugraz.at,Smoothed Analysis of Discrete Tensor Decomposition and Assemblies of Neurons
neurips,2018,3,6923,Christos,Papadimitriou,columbia,Columbia University,christos@cs.columbia.edu,Smoothed Analysis of Discrete Tensor Decomposition and Assemblies of Neurons
neurips,2018,4,6923,Amin,Saberi,stanford,Stanford University,saberi@stanford.edu,Smoothed Analysis of Discrete Tensor Decomposition and Assemblies of Neurons
neurips,2018,5,6923,Santosh,Vempala,gatech,Georgia Tech,vempala@gatech.edu,Smoothed Analysis of Discrete Tensor Decomposition and Assemblies of Neurons
neurips,2018,0,4852,Syama Sundar,Rangapuram,amazon,Amazon Research,rangapur@amazon.com,Deep State Space Models for Time Series Forecasting
neurips,2018,1,4852,Matthias,Seeger,amazon,Amazon Development Center,matthis@amazon.com,Deep State Space Models for Time Series Forecasting
neurips,2018,2,4852,Jan,Gasthaus,amazon,Amazon.com,gasthaus@amazon.com,Deep State Space Models for Time Series Forecasting
neurips,2018,3,4852,Lorenzo,Stella,amazon,Amazon,stellalo@amazon.com,Deep State Space Models for Time Series Forecasting
neurips,2018,4,4852,Yuyang,Wang,amazon,AWS AI Labs,yuyawang@amazon.com,Deep State Space Models for Time Series Forecasting
neurips,2018,5,4852,Tim,Januschowski,amazon,Amazon,tjnsch@amazon.com,Deep State Space Models for Time Series Forecasting
neurips,2018,0,6874,Shuang,Li,,Georgia Institute of Technology,,Learning Temporal Point Processes via Reinforcement Learning
neurips,2018,1,6874,Shuai,Xiao,,Ant Financial,,Learning Temporal Point Processes via Reinforcement Learning
neurips,2018,2,6874,Shixiang,Zhu,,Georgia Institute of Technology,,Learning Temporal Point Processes via Reinforcement Learning
neurips,2018,3,6874,Nan,Du,,Google Brain,,Learning Temporal Point Processes via Reinforcement Learning
neurips,2018,4,6874,Yao,Xie,,Georgia Institute of Technology,,Learning Temporal Point Processes via Reinforcement Learning
neurips,2018,5,6874,Le,Song,,Ant Financial & Georgia Institute of Technology,,Learning Temporal Point Processes via Reinforcement Learning
neurips,2018,0,5363,Zhilin,Yang,cmu,Carnegie Mellon University,zhiliny@cs.cmu.edu,GLoMo: Unsupervised Learning of Transferable Relational Graphs
neurips,2018,1,5363,Jake,Zhao,cmu,New York University / Facebook,bdhingra@cs.cmu.edu,GLoMo: Unsupervised Learning of Transferable Relational Graphs
neurips,2018,2,5363,Bhuwan,Dhingra,cmu,Carnegie Mellon University,wcohen@cs.cmu.edu,GLoMo: Unsupervised Learning of Transferable Relational Graphs
neurips,2018,3,5363,Kaiming,He,cmu,Facebook AI Research,rsalakhu@cs.cmu.edu,GLoMo: Unsupervised Learning of Transferable Relational Graphs
neurips,2018,4,5363,William,Cohen,nyu,Google AI,jakezhao@cs.nyu.com,GLoMo: Unsupervised Learning of Transferable Relational Graphs
neurips,2018,5,5363,Russ,Salakhutdinov,nyu,Carnegie Mellon University,yann@cs.nyu.com,GLoMo: Unsupervised Learning of Transferable Relational Graphs
neurips,2018,6,5363,Yann,LeCun,fb,Facebook AI Research and New York University,kaiminghe@fb.com,GLoMo: Unsupervised Learning of Transferable Relational Graphs
neurips,2018,0,554,Kexin,Yi,,"Harvard University, MIT CSAIL",,Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding
neurips,2018,1,554,Jiajun,Wu,,MIT,,Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding
neurips,2018,2,554,Chuang,Gan,,MIT-IBM Watson AI Lab,,Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding
neurips,2018,3,554,Antonio,Torralba,,MIT,,Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding
neurips,2018,4,554,Pushmeet,Kohli,,DeepMind,,Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding
neurips,2018,5,554,Josh,Tenenbaum,,MIT,,Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding
neurips,2018,0,6397,Izhak,Golan,technion,Technion,izikgo@cs.technion.ac.il,Deep Anomaly Detection Using Geometric Transformations
neurips,2018,1,6397,Ran,El-Yaniv,technion,Technion,rani@cs.technion.ac.il,Deep Anomaly Detection Using Geometric Transformations
neurips,2018,0,745,Christoph,Dann,cdann,Carnegie Mellon University,cdann@cdann.net,On Oracle-Efficient PAC RL with Rich Observations
neurips,2018,1,745,Nan,Jiang,illinois,University of Illinois at Urbana-Champaign,nanjiang@illinois.edu,On Oracle-Efficient PAC RL with Rich Observations
neurips,2018,2,745,Akshay,Krishnamurthy,umass,Microsoft,akshay@cs.umass.edu,On Oracle-Efficient PAC RL with Rich Observations
neurips,2018,3,745,Alekh,Agarwal,microsoft,Microsoft Research,alekha@microsoft.com,On Oracle-Efficient PAC RL with Rich Observations
neurips,2018,4,745,John,Langford,microsoft,Microsoft Research New York,jcl@microsoft.com,On Oracle-Efficient PAC RL with Rich Observations
neurips,2018,5,745,Robert,Schapire,microsoft,MIcrosoft Research,schapire@microsoft.com,On Oracle-Efficient PAC RL with Rich Observations
neurips,2018,0,110,Zhisheng,Zhong,pku,Peking University,zszhong@pku.edu.cn,Joint Sub-bands Learning with Clique Structures for Wavelet Domain Super-Resolution
neurips,2018,1,110,Tiancheng,Shen,pku,Peking University,tianchengshen@pku.edu.cn,Joint Sub-bands Learning with Clique Structures for Wavelet Domain Super-Resolution
neurips,2018,2,110,Yibo,Yang,pku,Peking University,ibo@pku.edu.cn,Joint Sub-bands Learning with Clique Structures for Wavelet Domain Super-Resolution
neurips,2018,3,110,Zhouchen,Lin,pku,Peking University,c.zhang@pku.edu.cn,Joint Sub-bands Learning with Clique Structures for Wavelet Domain Super-Resolution
neurips,2018,4,110,Chao,Zhang,pku,Peking University,zlin@pku.edu.cn,Joint Sub-bands Learning with Clique Structures for Wavelet Domain Super-Resolution
neurips,2018,0,5841,Liwei,Wang,pku,Peking University,wanglw@cis.pku.edu.cn,Towards Understanding Learning Representations: To What Extent Do Different Neural Networks Learn the Same Representation
neurips,2018,1,5841,Lunjia,Hu,stanford,Stanford University,lunjia@stanford.edu,Towards Understanding Learning Representations: To What Extent Do Different Neural Networks Learn the Same Representation
neurips,2018,2,5841,Jiayuan,Gu,pku,"University of California, San Diego",gujiayuan@pku.edu.cn,Towards Understanding Learning Representations: To What Extent Do Different Neural Networks Learn the Same Representation
neurips,2018,3,5841,Zhiqiang,Hu,pku,Peking University,frankwu@pku.edu.cn,Towards Understanding Learning Representations: To What Extent Do Different Neural Networks Learn the Same Representation
neurips,2018,4,5841,Yue,Wu,pku,Peking University,huzq@pku.edu.cn,Towards Understanding Learning Representations: To What Extent Do Different Neural Networks Learn the Same Representation
neurips,2018,5,5841,Kun,He,hust,Hua Zhong University of Science and Technology,brooklet60@hust.edu.cn,Towards Understanding Learning Representations: To What Extent Do Different Neural Networks Learn the Same Representation
neurips,2018,6,5841,John,Hopcroft,cornell,Cornell University,jeh17@cornell.edu,Towards Understanding Learning Representations: To What Extent Do Different Neural Networks Learn the Same Representation
neurips,2018,0,6460,Tyler,Lu,google,Google,tylerlu@google.com,Non-delusional Q-learning and value-iteration
neurips,2018,1,6460,Dale,Schuurmans,google,Google Inc.,schuurmans@google.com,Non-delusional Q-learning and value-iteration
neurips,2018,2,6460,Craig,Boutilier,google,Google,cboutilier@google.com,Non-delusional Q-learning and value-iteration
neurips,2018,0,5859,Rosanne,Liu,uber,Uber AI Labs,rosanne@uber.com,An intriguing failing of convolutional neural networks and the CoordConv solution
neurips,2018,1,5859,Joel,Lehman,uber,Uber AI Labs,joel.lehman@uber.com,An intriguing failing of convolutional neural networks and the CoordConv solution
neurips,2018,2,5859,Piero,Molino,uber,Uber AI Labs,piero@uber.com,An intriguing failing of convolutional neural networks and the CoordConv solution
neurips,2018,3,5859,Felipe,Petroski Such,uber,Uber AI Labs,felipe.such@uber.com,An intriguing failing of convolutional neural networks and the CoordConv solution
neurips,2018,4,5859,Eric,Frank,uber,Uber AI Labs,mysterefrank@uber.com,An intriguing failing of convolutional neural networks and the CoordConv solution
neurips,2018,5,5859,Alex,Sergeev,uber,"Uber Technologies Inc,",asergeev@uber.com,An intriguing failing of convolutional neural networks and the CoordConv solution
neurips,2018,6,5859,Jason,Yosinski,uber,Uber AI Labs; Recursion,yosinski@uber.com,An intriguing failing of convolutional neural networks and the CoordConv solution
neurips,2018,0,2782,Ilija,Bogunovic,epfl,EPFL Lausanne,ilija.bogunovic@epfl.ch,Adversarially Robust Optimization with Gaussian Processes
neurips,2018,1,2782,Jonathan,Scarlett,nus,National University of Singapore,scarlett@comp.nus.edu.sg,Adversarially Robust Optimization with Gaussian Processes
neurips,2018,2,2782,Stefanie,Jegelka,mit,MIT,stefje@mit.edu,Adversarially Robust Optimization with Gaussian Processes
neurips,2018,3,2782,Volkan,Cevher,epfl,EPFL,volkan.cevher@epfl.ch,Adversarially Robust Optimization with Gaussian Processes
neurips,2018,0,1399,Seunghoon,Hong,,University of Michigan,,Learning Hierarchical Semantic Image Manipulation through Structured Representations
neurips,2018,1,1399,Xinchen,Yan,,University of Michigan,,Learning Hierarchical Semantic Image Manipulation through Structured Representations
neurips,2018,2,1399,Thomas,Huang,,University of Michigan,,Learning Hierarchical Semantic Image Manipulation through Structured Representations
neurips,2018,3,1399,Honglak,Lee,,Google / U. Michigan,,Learning Hierarchical Semantic Image Manipulation through Structured Representations
neurips,2018,0,5840,Morteza,Mardani,stanford,Stanford University,morteza@stanford.edu,Neural Proximal Gradient Descent for Compressive Imaging
neurips,2018,1,5840,Qingyun,Sun,stanford,Stanford university,qysun@stanford.edu,Neural Proximal Gradient Descent for Compressive Imaging
neurips,2018,2,5840,David,Donoho,stanford,Stanford University,vasanawala@stanford.edu,Neural Proximal Gradient Descent for Compressive Imaging
neurips,2018,3,5840,Vardan,Papyan,stanford,Stanford University,papyan@stanford.edu,Neural Proximal Gradient Descent for Compressive Imaging
neurips,2018,4,5840,Hatef,Monajemi,stanford,Stanford University,monajemi@stanford.edu,Neural Proximal Gradient Descent for Compressive Imaging
neurips,2018,5,5840,Shreyas,Vasanawala,stanford,Stanford University,pauly@stanford.edu,Neural Proximal Gradient Descent for Compressive Imaging
neurips,2018,6,5840,John,Pauly,stanford,Stanford University,donoho@stanford.edu,Neural Proximal Gradient Descent for Compressive Imaging
neurips,2018,0,2449,Michael,Morais,princeton,Princeton University,mjmorais@princeton.edu,Power-law efficient neural codes provide general link between perceptual bias and discriminability
neurips,2018,1,2449,Jonathan,Pillow,princeton,Princeton University,pillow@princeton.edu,Power-law efficient neural codes provide general link between perceptual bias and discriminability
neurips,2018,0,3436,Shandian,Zhe,utah,University of Utah,zhe@cs.utah.edu,Stochastic Nonparametric Event-Tensor Decomposition
neurips,2018,1,3436,Yishuai,Du,utah,University of Utah,yishuai.du@utah.edu,Stochastic Nonparametric Event-Tensor Decomposition
neurips,2018,0,2307,Venkata Krishna,Pillutla,,University of Washington,,A Smoother Way to Train Structured Prediction Models
neurips,2018,1,2307,Vincent,Roulet,,UW,,A Smoother Way to Train Structured Prediction Models
neurips,2018,2,2307,Sham,Kakade,,University of Washington,,A Smoother Way to Train Structured Prediction Models
neurips,2018,3,2307,Zaid,Harchaoui,,University of Washington,,A Smoother Way to Train Structured Prediction Models
neurips,2018,0,2968,Xiaodong,Cui,ibm,IBM T. J. Watson Research Center,cuix@us.ibm.com,Evolutionary Stochastic Gradient Descent for Optimization of Deep Neural Networks
neurips,2018,1,2968,Wei,Zhang,ibm,IBM T.J.Watson Research Center,weiz@us.ibm.com,Evolutionary Stochastic Gradient Descent for Optimization of Deep Neural Networks
neurips,2018,2,2968,Zoltán,Tüske,ibm,IBM T. J. Watson Research Center,picheny@us.ibm.com,Evolutionary Stochastic Gradient Descent for Optimization of Deep Neural Networks
neurips,2018,3,2968,Michael,Picheny,ibm,IBM T. J. Watson Research Center,Zoltan.Tuske@ibm.com,Evolutionary Stochastic Gradient Descent for Optimization of Deep Neural Networks
neurips,2018,0,3300,Alexander,Munteanu,tu-dortmund,TU Dortmund,alexander.munteanu@tu-dortmund.de,On Coresets for Logistic Regression
neurips,2018,1,3300,Chris,Schwiegelshohn,uniroma1,"Sapienza, University of Rome",schwiegelshohn@diag.uniroma1.it,On Coresets for Logistic Regression
neurips,2018,2,3300,Christian,Sohler,tu-dortmund,TU Dortmund,christian.sohler@tu-dortmund.de,On Coresets for Logistic Regression
neurips,2018,3,3300,David,Woodruff,cmu,Carnegie Mellon University,dwoodruf@cs.cmu.edu,On Coresets for Logistic Regression
neurips,2018,0,5709,Sergey,Bartunov,,DeepMind,,Assessing the Scalability of Biologically-Motivated Deep Learning Algorithms and Architectures
neurips,2018,1,5709,Adam,Santoro,,DeepMind,,Assessing the Scalability of Biologically-Motivated Deep Learning Algorithms and Architectures
neurips,2018,2,5709,Blake,Richards,,University of Toronto,,Assessing the Scalability of Biologically-Motivated Deep Learning Algorithms and Architectures
neurips,2018,3,5709,Luke,Marris,,DeepMind,,Assessing the Scalability of Biologically-Motivated Deep Learning Algorithms and Architectures
neurips,2018,4,5709,Geoffrey,Hinton,,Google & University of Toronto,,Assessing the Scalability of Biologically-Motivated Deep Learning Algorithms and Architectures
neurips,2018,5,5709,Timothy,Lillicrap,,Google DeepMind,,Assessing the Scalability of Biologically-Motivated Deep Learning Algorithms and Architectures
neurips,2018,0,944,Shunyu,Yao,,Tsinghua University,,3D-Aware Scene Manipulation via Inverse Graphics
neurips,2018,1,944,Tzu Ming,Hsu,,MIT,,3D-Aware Scene Manipulation via Inverse Graphics
neurips,2018,2,944,Jun-Yan,Zhu,,MIT,,3D-Aware Scene Manipulation via Inverse Graphics
neurips,2018,3,944,Jiajun,Wu,,MIT,,3D-Aware Scene Manipulation via Inverse Graphics
neurips,2018,4,944,Antonio,Torralba,,MIT,,3D-Aware Scene Manipulation via Inverse Graphics
neurips,2018,5,944,Bill,Freeman,,MIT/Google,,3D-Aware Scene Manipulation via Inverse Graphics
neurips,2018,6,944,Josh,Tenenbaum,,MIT,,3D-Aware Scene Manipulation via Inverse Graphics
neurips,2018,0,1809,Tom,Zahavy,,Technion,,Learn What Not to Learn: Action Elimination with Deep Reinforcement Learning
neurips,2018,1,1809,Matan,Haroush,,Technion,,Learn What Not to Learn: Action Elimination with Deep Reinforcement Learning
neurips,2018,2,1809,Nadav,Merlis,,Technion,,Learn What Not to Learn: Action Elimination with Deep Reinforcement Learning
neurips,2018,3,1809,Daniel,Mankowitz,,Technion,,Learn What Not to Learn: Action Elimination with Deep Reinforcement Learning
neurips,2018,4,1809,Shie,Mannor,,Technion,,Learn What Not to Learn: Action Elimination with Deep Reinforcement Learning
neurips,2018,0,6777,Arun,Suggala,cmu,Carnegie Mellon University,asuggala@cs.cmu.edu,Connecting Optimization and Regularization Paths
neurips,2018,1,6777,Adarsh,Prasad,cmu,Carnegie Mellon University,adarshp@cs.cmu.edu,Connecting Optimization and Regularization Paths
neurips,2018,2,6777,Pradeep,Ravikumar,cmu,Carnegie Mellon University,pradeepr@cs.cmu.edu,Connecting Optimization and Regularization Paths
neurips,2018,0,3392,Hendrik,Fichtenberger,tu-dortmund,TU Dortmund,hendrik.fichtenberger@tu-dortmund.de,A Theory-Based Evaluation of Nearest Neighbor Models Put Into Practice
neurips,2018,1,3392,Dennis,Rohde,tu-dortmund,TU Dortmund,dennis.rohde@cs.tu-dortmund.de,A Theory-Based Evaluation of Nearest Neighbor Models Put Into Practice
neurips,2018,0,545,Yogesh,Balaji,umd,University of Maryland,yogesh@cs.umd.edu,MetaReg: Towards Domain Generalization using Meta-Regularization
neurips,2018,1,545,Swami,Sankaranarayanan,butterflynetinc,Butterfly Network inc.,swamiviv@butterflynetinc.com,MetaReg: Towards Domain Generalization using Meta-Regularization
neurips,2018,2,545,Rama,Chellappa,umd,University of Maryland College Park,rama@umiacs.umd.edu,MetaReg: Towards Domain Generalization using Meta-Regularization
neurips,2018,0,1499,Ya-Ping,Hsieh,epfl,EPFL,ya-ping.hsieh@epfl.ch,Mirrored Langevin Dynamics
neurips,2018,1,1499,Ali,Kavis,epfl,EPFL,ali.kavis@epfl.ch,Mirrored Langevin Dynamics
neurips,2018,2,1499,Paul,Rolland,epfl,EPFL,paul.rolland@epfl.ch,Mirrored Langevin Dynamics
neurips,2018,3,1499,Volkan,Cevher,epfl,EPFL,volkan.cevher@epfl.ch,Mirrored Langevin Dynamics
neurips,2018,0,1675,Tom,Dupré la Tour,,Télécom ParisTech,,Multivariate Convolutional Sparse Coding for Electromagnetic Brain Signals
neurips,2018,1,1675,Thomas,Moreau,,Inria,,Multivariate Convolutional Sparse Coding for Electromagnetic Brain Signals
neurips,2018,2,1675,Mainak,Jas,,Télécom ParisTech,,Multivariate Convolutional Sparse Coding for Electromagnetic Brain Signals
neurips,2018,3,1675,Alexandre,Gramfort,,"INRIA, Université Paris-Saclay",,Multivariate Convolutional Sparse Coding for Electromagnetic Brain Signals
neurips,2018,0,6734,Moritz,Wolter,uni-bonn,University of Bonn,wolter@cs.uni-bonn.de,Complex Gated Recurrent Neural Networks
neurips,2018,1,6734,Angela,Yao,nus,National University of Singapore,yaoa@comp.nus.edu.sg,Complex Gated Recurrent Neural Networks
neurips,2018,0,2234,Xin,Yang,dlut,Dalian University of Technology,xinyang@dlut.edu.cn,Active Matting
neurips,2018,1,2234,Ke,Xu,dlut,Dalian University of Technology;City University of Hong Kong,csz@mail.dlut.edu.cn,Active Matting
neurips,2018,2,2234,Shaozhe,Chen,dlut,Dalian University of Technology,kkangwing@mail.dlut.edu.cn,Active Matting
neurips,2018,3,2234,Shengfeng,He,scut,South China University of Technology,hesfe@scut.edu.cn,Active Matting
neurips,2018,4,2234,Baocai Yin,Yin,dlut,Dalian University of Technology,ybc@dlut.edu.cn,Active Matting
neurips,2018,5,2234,Rynson,Lau,cityu,City University of Hong Kong,rynson.lau@cityu.edu.hk,Active Matting
neurips,2018,0,6426,Matthew,O'Kelly,upenn,University of Pennsylvania,mokelly@seas.upenn.edu,Scalable End-to-End Autonomous Vehicle Testing via Rare-event Simulation
neurips,2018,1,6426,Aman,Sinha,stanford,Stanford University,amans@stanford.edu,Scalable End-to-End Autonomous Vehicle Testing via Rare-event Simulation
neurips,2018,2,6426,Hongseok,Namkoong,stanford,Stanford University,hnamk@stanford.edu,Scalable End-to-End Autonomous Vehicle Testing via Rare-event Simulation
neurips,2018,3,6426,Russ,Tedrake,stanford,MIT,jduchi@stanford.edu,Scalable End-to-End Autonomous Vehicle Testing via Rare-event Simulation
neurips,2018,4,6426,John,Duchi,mit,Stanford,russt@mit.edu,Scalable End-to-End Autonomous Vehicle Testing via Rare-event Simulation
neurips,2018,0,6174,Chin-Wei,Huang,umontreal,MILA,1chin-wei.huang@umontreal.ca,Improving Explorability in Variational Inference with Annealed Variational Objectives
neurips,2018,1,6174,Shawn,Tan,umontreal,Mila,2jing.shan.shawn.tan@umontreal.ca,Improving Explorability in Variational Inference with Annealed Variational Objectives
neurips,2018,2,6174,Alexandre,Lacoste,elementai,Element AI,3allac@elementai.com,Improving Explorability in Variational Inference with Annealed Variational Objectives
neurips,2018,3,6174,Aaron,Courville,umontreal,U. Montreal,4aaron.courville@umontreal.ca,Improving Explorability in Variational Inference with Annealed Variational Objectives
neurips,2018,0,3833,Xujie,Si,upenn,University of Pennsylvania,xsi@cis.upenn.edu,Learning Loop Invariants for Program Verification
neurips,2018,1,3833,Hanjun,Dai,gatech,Georgia Tech,hanjundai@gatech.edu,Learning Loop Invariants for Program Verification
neurips,2018,2,3833,Mukund,Raghothaman,upenn,University of Pennsylvania,rmukund@cis.upenn.edu,Learning Loop Invariants for Program Verification
neurips,2018,3,3833,Mayur,Naik,upenn,University of Pennsylvania,mhnaik@cis.upenn.edu,Learning Loop Invariants for Program Verification
neurips,2018,4,3833,Le,Song,gatech,Ant Financial & Georgia Institute of Technology,lsong@cc.gatech.edu,Learning Loop Invariants for Program Verification
neurips,2018,0,1916,Xiaoxuan,Zhang,,University of Iowa,,Faster Online Learning of Optimal Threshold for Consistent F-measure Optimization
neurips,2018,1,1916,Mingrui,Liu,,The University of Iowa,,Faster Online Learning of Optimal Threshold for Consistent F-measure Optimization
neurips,2018,2,1916,Xun,Zhou,,University of Iowa,,Faster Online Learning of Optimal Threshold for Consistent F-measure Optimization
neurips,2018,3,1916,Tianbao,Yang,,The University of Iowa,,Faster Online Learning of Optimal Threshold for Consistent F-measure Optimization
neurips,2018,0,2711,Yanlin,Han,uic,University of Illinois at Chicago,yhan37@uic.edu,Learning Others' Intentional Models in Multi-Agent Settings Using Interactive POMDPs
neurips,2018,1,2711,Piotr,Gmytrasiewicz,uic,UIC,piotr@uic.edu,Learning Others' Intentional Models in Multi-Agent Settings Using Interactive POMDPs
neurips,2018,0,3452,Agastya,Kalra,gmail,University of Waterloo,agastya.kalra@gmail.com,Online Structure Learning for Feed-Forward and Recurrent Sum-Product Networks
neurips,2018,1,3452,Abdullah,Rashwan,uwaterloo,University of Waterloo,arashwan@uwaterloo.ca,Online Structure Learning for Feed-Forward and Recurrent Sum-Product Networks
neurips,2018,2,3452,Wei-Shou,Hsu,uwaterloo,University of Waterloo,wwhsu@uwaterloo.ca,Online Structure Learning for Feed-Forward and Recurrent Sum-Product Networks
neurips,2018,3,3452,Pascal,Poupart,uwaterloo,University of Waterloo & RBC Borealis AI,ppoupart@uwaterloo.ca,Online Structure Learning for Feed-Forward and Recurrent Sum-Product Networks
neurips,2018,4,3452,Prashant,Doshi,huawei,University of Georgia,g.trimponias@huawei.com,Online Structure Learning for Feed-Forward and Recurrent Sum-Product Networks
neurips,2018,5,3452,Georgios,Trimponias,uga,"Huawei Technologies Co., Ltd.",pdoshi@cs.uga.edu,Online Structure Learning for Feed-Forward and Recurrent Sum-Product Networks
neurips,2018,0,5335,Nathan,Kallus,cornell,Cornell University,kallus@cornell.edu,Balanced Policy Evaluation and Learning
neurips,2018,0,431,Ashish,Kumar,berkeley,UC Berkeley,ashish_kumar@berkeley.edu,Visual Memory for Robust Path Following
neurips,2018,1,431,Saurabh,Gupta,berkeley,UC Berkeley / FAIR / UIUC,sgupta@eecs.berkeley.edu,Visual Memory for Robust Path Following
neurips,2018,2,431,David,Fouhey,berkeley,UC Berkeley,dfouhey@eecs.berkeley.edu,Visual Memory for Robust Path Following
neurips,2018,3,431,Sergey,Levine,berkeley,UC Berkeley,svlevine@eecs.berkeley.edu,Visual Memory for Robust Path Following
neurips,2018,4,431,Jitendra,Malik,berkeley,University of California at Berkley,malik@eecs.berkeley.edu,Visual Memory for Robust Path Following
neurips,2018,0,3363,Marta,Avalos,,"INRIA, INSERM U1219, University of Bordeaux",,Representation Learning of Compositional Data
neurips,2018,1,3363,Richard,Nock,,"Data61, the Australian National University and the University of Sydney",,Representation Learning of Compositional Data
neurips,2018,2,3363,Cheng Soon,Ong,,Data61 and ANU,,Representation Learning of Compositional Data
neurips,2018,3,3363,Julien,Rouar,,University of Bordeaux,,Representation Learning of Compositional Data
neurips,2018,4,3363,Ke,Sun,,"Data61, CSIRO",,Representation Learning of Compositional Data
neurips,2018,0,5039,Lei,Wu,pku,Peking University,leiwu@pku.edu.cn,How SGD Selects the Global Minima in Over-parameterized Learning: A Dynamical Stability Perspective
neurips,2018,1,5039,Chao,Ma,princeton,Princeton University,chaom@princeton.edu,How SGD Selects the Global Minima in Over-parameterized Learning: A Dynamical Stability Perspective
neurips,2018,2,5039,Weinan,E,princeton,Princeton University,weinan@math.princeton.edu,How SGD Selects the Global Minima in Over-parameterized Learning: A Dynamical Stability Perspective
neurips,2018,0,414,Boris,Oreshkin,elementai,Element AI,boris@elementai.com,TADAM: Task dependent adaptive metric for improved few-shot learning
neurips,2018,1,414,Pau,Rodríguez López,elementai,CVC UAB,pau.rodriguez@elementai.com,TADAM: Task dependent adaptive metric for improved few-shot learning
neurips,2018,2,414,Alexandre,Lacoste,elementai,Element AI,allac@elementai.com,TADAM: Task dependent adaptive metric for improved few-shot learning
neurips,2018,0,2835,Toni,Karvonen,aalto,Aalto University,toni.karvonen@aalto.fi,A Bayes-Sard Cubature Method
neurips,2018,1,2835,Chris,Oates,ncl,Newcastle University,chris.oates@ncl.ac.uk,A Bayes-Sard Cubature Method
neurips,2018,2,2835,Simo,Sarkka,aalto,Aalto University,simo.sarkka@aalto.fi,A Bayes-Sard Cubature Method
neurips,2018,0,2974,Kevin,Ellis,mit,MIT,ellisk@mit.edu,Learning to Infer Graphics Programs from Hand-Drawn Images
neurips,2018,1,2974,Daniel,Ritchie,brown,Brown University,daniel_ritchie@brown.edu,Learning to Infer Graphics Programs from Hand-Drawn Images
neurips,2018,2,2974,Armando,Solar-Lezama,mit,MIT,asolar@csail.mit.edu,Learning to Infer Graphics Programs from Hand-Drawn Images
neurips,2018,3,2974,Josh,Tenenbaum,mit,MIT,jbt@mit.edu,Learning to Infer Graphics Programs from Hand-Drawn Images
neurips,2018,0,876,Lisa,Zhang,toronto,University of Toronto,1lczhang@cs.toronto.edu,Neural Guided Constraint Logic Programming for Program Synthesis
neurips,2018,1,876,Gregory,Rosenblatt,toronto,University of Alabama at Birmingham,ethanf@cs.toronto.edu,Neural Guided Constraint Logic Programming for Program Synthesis
neurips,2018,2,876,Ethan,Fetaya,toronto,University of Toronto,rjliao@cs.toronto.edu,Neural Guided Constraint Logic Programming for Program Synthesis
neurips,2018,3,876,Renjie,Liao,toronto,University of Toronto,urtasun@cs.toronto.edu,Neural Guided Constraint Logic Programming for Program Synthesis
neurips,2018,4,876,William,Byrd,toronto,University of Alabama at Birmingham,zemel@cs.toronto.edu,Neural Guided Constraint Logic Programming for Program Synthesis
neurips,2018,5,876,Matthew,Might,uab,University of Alabama at Birmingham,4gregr@uab.edu,Neural Guided Constraint Logic Programming for Program Synthesis
neurips,2018,6,876,Raquel,Urtasun,uab,University of Toronto,webyrd@uab.edu,Neural Guided Constraint Logic Programming for Program Synthesis
neurips,2018,7,876,Richard,Zemel,uab,Vector Institute/University of Toronto,might@uab.edu,Neural Guided Constraint Logic Programming for Program Synthesis
neurips,2018,0,779,Sainandan,Ramakrishnan,gatech,Georgia Institute of Technology,sainandancv@gatech.edu,Overcoming Language Priors in Visual Question Answering with Adversarial Regularization
neurips,2018,1,779,Aishwarya,Agrawal,gatech,Georgia Institute of Technology,aishwarya@gatech.edu,Overcoming Language Priors in Visual Question Answering with Adversarial Regularization
neurips,2018,2,779,Stefan,Lee,gatech,Georgia Institute of Technology,steflee@gatech.edu,Overcoming Language Priors in Visual Question Answering with Adversarial Regularization
neurips,2018,0,641,Pan,Zhou,nus,National University of Singapore,pzhou@u.nus.edu,New Insight into Hybrid Stochastic Gradient Descent: Beyond With-Replacement Sampling and Convexity
neurips,2018,1,641,Xiaotong,Yuan,nuist,Nanjing University of Information Science and Technology,xtyuan@nuist.edu.cn,New Insight into Hybrid Stochastic Gradient Descent: Beyond With-Replacement Sampling and Convexity
neurips,2018,2,641,Jiashi,Feng,nus,National University of Singapore,elefjia@nus.edu.sg,New Insight into Hybrid Stochastic Gradient Descent: Beyond With-Replacement Sampling and Convexity
neurips,2018,0,1889,Ganesh,Sundaramoorthi,utc,UTRC,sundarga1@utrc.utc.com,Variational PDEs for Acceleration on Manifolds and Application to Diffeomorphisms
neurips,2018,1,1889,Anthony,Yezzi,gatech,Georgia Tech,ayezzi@ece.gatech.edu,Variational PDEs for Acceleration on Manifolds and Application to Diffeomorphisms
neurips,2018,0,2198,Ye,Jia,,Google,,Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis
neurips,2018,1,2198,Yu,Zhang,,Google Brain,,Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis
neurips,2018,2,2198,Ron,Weiss,,"Google, Inc.",,Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis
neurips,2018,3,2198,Quan,Wang,,Google,,Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis
neurips,2018,4,2198,Jonathan,Shen,,Google,,Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis
neurips,2018,5,2198,Fei,Ren,,,,Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis
neurips,2018,6,2198,zhifeng,Chen,,Google Brain,,Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis
neurips,2018,7,2198,Patrick,Nguyen,,Google,,Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis
neurips,2018,8,2198,Ruoming,Pang,,Google Brain,,Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis
neurips,2018,9,2198,Ignacio,Lopez Moreno,,Google,,Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis
neurips,2018,10,2198,Yonghui,Wu,,Google,,Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis
neurips,2018,0,6603,Mislav,Balunovic,ethz,ETH Zurich,bmislav@ethz.ch,Learning to Solve SMT Formulas
neurips,2018,1,6603,Pavol,Bielik,ethz,ETH Zurich,pavol.bielik@inf.ethz.ch,Learning to Solve SMT Formulas
neurips,2018,2,6603,Martin,Vechev,ethz,"DeepCode and ETH Zurich, Switzerland",martin.vechev@inf.ethz.ch,Learning to Solve SMT Formulas
neurips,2018,0,4911,Jacob,Harer,draper,Boston University,jharer@draper.com,Learning to Repair Software Vulnerabilities with Generative Adversarial Networks
neurips,2018,1,4911,Onur,Ozdemir,draper,Draper,oozdemir@draper.com,Learning to Repair Software Vulnerabilities with Generative Adversarial Networks
neurips,2018,2,4911,Tomo,Lazovich,draper,Lightmatter,creale@draper.com,Learning to Repair Software Vulnerabilities with Generative Adversarial Networks
neurips,2018,3,4911,Christopher,Reale,draper,Draper,rrussell@draper.com,Learning to Repair Software Vulnerabilities with Generative Adversarial Networks
neurips,2018,4,4911,Rebecca,Russell,draper,Draper,lkim@draper.com,Learning to Repair Software Vulnerabilities with Generative Adversarial Networks
neurips,2018,5,4911,Louis,Kim,lightmatter,Draper,tomo@lightmatter.ai,Learning to Repair Software Vulnerabilities with Generative Adversarial Networks
neurips,2018,6,4911,peter,chin,bu,boston university,spchin@cs.bu.edu,Learning to Repair Software Vulnerabilities with Generative Adversarial Networks
neurips,2018,0,1093,Markus,Lange-Hegermann,hs-owl,Hochschule Ostwestfalen-Lippe,markus.lange-hegermann@hs-owl.de,Algorithmic Linearly Constrained Gaussian Processes
neurips,2018,0,4893,Thu,Nguyen-Phuoc,,University of Bath,,RenderNet: A deep convolutional network for differentiable rendering from 3D shapes
neurips,2018,1,4893,Chuan,Li,,"Lambda Labs, Inc.",,RenderNet: A deep convolutional network for differentiable rendering from 3D shapes
neurips,2018,2,4893,Stephen,Balaban,,Lambda,,RenderNet: A deep convolutional network for differentiable rendering from 3D shapes
neurips,2018,3,4893,Yongliang,Yang,,University of Bath,,RenderNet: A deep convolutional network for differentiable rendering from 3D shapes
neurips,2018,0,991,Simina,Branzei,purdue,Purdue University,simina@purdue.edu,Universal Growth in Production Economies
neurips,2018,1,991,Ruta,Mehta,illinois,UIUC,rutamehta@illinois.edu,Universal Growth in Production Economies
neurips,2018,2,991,Noam,Nisan,huji,Hebrew University of Jerusalem and Microsoft Research,noam@cs.huji.ac.il,Universal Growth in Production Economies
neurips,2018,0,3310,Ricky T. Q.,Chen,,University of Toronto,,Neural Ordinary Differential Equations
neurips,2018,1,3310,Yulia,Rubanova,,University of Toronto,,Neural Ordinary Differential Equations
neurips,2018,2,3310,Jesse,Bettencourt,,University of Toronto,,Neural Ordinary Differential Equations
neurips,2018,3,3310,David,Duvenaud,,University of Toronto,,Neural Ordinary Differential Equations
neurips,2018,0,207,Tong,Yang,megvii,"Megvii(Face++),Fudan University",yangtong@megvii.com,MetaAnchor: Learning to Detect Objects with Customized Anchors
neurips,2018,1,207,Xiangyu,Zhang,megvii,Megvii Inc (Face++),zhangxiangyu@megvii.com,MetaAnchor: Learning to Detect Objects with Customized Anchors
neurips,2018,2,207,Zeming,Li,megvii,Megvii(Face++) Inc,lizeming@megvii.com,MetaAnchor: Learning to Detect Objects with Customized Anchors
neurips,2018,3,207,Wenqiang,Zhang,megvii,Fudan University,sunjian@megvii.com,MetaAnchor: Learning to Detect Objects with Customized Anchors
neurips,2018,4,207,Jian,Sun,fudan,"Megvii, Face++",wqzhang@fudan.edu.cn,MetaAnchor: Learning to Detect Objects with Customized Anchors
neurips,2018,0,2487,Hongyang,Gao,tamu,Texas A&M University,hongyang.gao@tamu.edu,ChannelNets: Compact and Efficient Convolutional Neural Networks via Channel-Wise Convolutions
neurips,2018,1,2487,Zhengyang,Wang,tamu,Texas A&M University,zhengyang.wang@tamu.edu,ChannelNets: Compact and Efficient Convolutional Neural Networks via Channel-Wise Convolutions
neurips,2018,2,2487,Shuiwang,Ji,tamu,Texas A&M University,sji@tamu.edu,ChannelNets: Compact and Efficient Convolutional Neural Networks via Channel-Wise Convolutions
neurips,2018,0,3163,Anirban,Laha,,IBM Research,,On Controllable Sparse Alternatives to Softmax
neurips,2018,1,3163,Saneem Ahmed,Chemmengath,,IBM Research AI,,On Controllable Sparse Alternatives to Softmax
neurips,2018,2,3163,Priyanka,Agrawal,,IBM India Pvt. Ltd.,,On Controllable Sparse Alternatives to Softmax
neurips,2018,3,3163,Mitesh,Khapra,,IIT Madras,,On Controllable Sparse Alternatives to Softmax
neurips,2018,4,3163,Karthik,Sankaranarayanan,,IBM Research,,On Controllable Sparse Alternatives to Softmax
neurips,2018,5,3163,Harish,Ramaswamy,,IIT Madras,,On Controllable Sparse Alternatives to Softmax
neurips,2018,0,1217,Vincent,Dutordoir,prowler,PROWLER.io,vincent@prowler.io,Gaussian Process Conditional Density Estimation
neurips,2018,1,1217,Hugh,Salimbeni,prowler,Imperial College London,hugh@prowler.io,Gaussian Process Conditional Density Estimation
neurips,2018,2,1217,James,Hensman,prowler,PROWLER.io,marc@prowler.io,Gaussian Process Conditional Density Estimation
neurips,2018,3,1217,Marc,Deisenroth,prowler,Imperial College London,james@prowler.io,Gaussian Process Conditional Density Estimation
neurips,2018,0,5104,Andrei,Zanfir,imar,Institute of Mathematics of the Romanian Academy,andrei.zanfir@imar.ro,Deep Network for the Integrated 3D Sensing of Multiple People in Natural Images
neurips,2018,1,5104,Elisabeta,Marinoiu,imar,IMAR,elisabeta.marinoiu@imar.ro,Deep Network for the Integrated 3D Sensing of Multiple People in Natural Images
neurips,2018,2,5104,Mihai,Zanfir,imar,IMAR,mihai.zanfir@imar.ro,Deep Network for the Integrated 3D Sensing of Multiple People in Natural Images
neurips,2018,3,5104,Alin-Ionut,Popa,imar,IMAR,alin.popa@imar.ro,Deep Network for the Integrated 3D Sensing of Multiple People in Natural Images
neurips,2018,4,5104,Cristian,Sminchisescu,lth,LTH,cristian.sminchisescu@math.lth.se,Deep Network for the Integrated 3D Sensing of Multiple People in Natural Images
neurips,2018,0,3603,Jiechuan,Jiang,pku,Peking University,jiechuan.jiang@pku.edu.cn,Learning Attentional Communication for Multi-Agent Cooperation
neurips,2018,1,3603,Zongqing,Lu,pku,Peking University,zongqing.lu@pku.edu.cn,Learning Attentional Communication for Multi-Agent Cooperation
neurips,2018,0,1682,Daniel,Fried,,UC Berkeley,,Speaker-Follower Models for Vision-and-Language Navigation
neurips,2018,1,1682,Ronghang,Hu,,"University of California, Berkeley",,Speaker-Follower Models for Vision-and-Language Navigation
neurips,2018,2,1682,Volkan,Cirik,,Carnegie Mellon University,,Speaker-Follower Models for Vision-and-Language Navigation
neurips,2018,3,1682,Anna,Rohrbach,,UC Berkeley,,Speaker-Follower Models for Vision-and-Language Navigation
neurips,2018,4,1682,Jacob,Andreas,,UC Berkeley,,Speaker-Follower Models for Vision-and-Language Navigation
neurips,2018,5,1682,Louis-Philippe,Morency,,Carnegie Mellon University,,Speaker-Follower Models for Vision-and-Language Navigation
neurips,2018,6,1682,Taylor,Berg-Kirkpatrick,,Carnegie Mellon University,,Speaker-Follower Models for Vision-and-Language Navigation
neurips,2018,7,1682,Kate,Saenko,,Boston University,,Speaker-Follower Models for Vision-and-Language Navigation
neurips,2018,8,1682,Dan,Klein,,UC Berkeley,,Speaker-Follower Models for Vision-and-Language Navigation
neurips,2018,9,1682,Trevor,Darrell,,UC Berkeley,,Speaker-Follower Models for Vision-and-Language Navigation
neurips,2018,0,282,Mario,Drumond,epfl,EPFL,mario.drumond@epfl.ch,Training DNNs with Hybrid Block Floating Point
neurips,2018,1,282,Tao,LIN,epfl,EPFL,tao.lin@epfl.ch,Training DNNs with Hybrid Block Floating Point
neurips,2018,2,282,Martin,Jaggi,epfl,EPFL,martin.jaggi@epfl.ch,Training DNNs with Hybrid Block Floating Point
neurips,2018,3,282,Babak,Falsafi,epfl,"EcoCloud, EPFL",babak.falsafi@epfl.ch,Training DNNs with Hybrid Block Floating Point
neurips,2018,0,6162,Bo,Dai,,Google Brain,,Coupled Variational Bayes via Optimization Embedding
neurips,2018,1,6162,Hanjun,Dai,,Georgia Tech,,Coupled Variational Bayes via Optimization Embedding
neurips,2018,2,6162,Niao,He,,UIUC,,Coupled Variational Bayes via Optimization Embedding
neurips,2018,3,6162,Weiyang,Liu,,Georgia Institute of Technology,,Coupled Variational Bayes via Optimization Embedding
neurips,2018,4,6162,Zhen,Liu,,Georgia Institute of Technology,,Coupled Variational Bayes via Optimization Embedding
neurips,2018,5,6162,Jianshu,Chen,,Tencent AI Lab,,Coupled Variational Bayes via Optimization Embedding
neurips,2018,6,6162,Lin,Xiao,,Microsoft Research,,Coupled Variational Bayes via Optimization Embedding
neurips,2018,7,6162,Le,Song,,Ant Financial & Georgia Institute of Technology,,Coupled Variational Bayes via Optimization Embedding
neurips,2018,0,3092,AmirEmad,Ghassami,,University of Illinois at UrbanaChampaign,,Multi-domain Causal Structure Learning in Linear Systems
neurips,2018,1,3092,Negar,Kiyavash,,Georgia Tech,,Multi-domain Causal Structure Learning in Linear Systems
neurips,2018,2,3092,Biwei,Huang,,Carnegie Mellon University,,Multi-domain Causal Structure Learning in Linear Systems
neurips,2018,3,3092,Kun,Zhang,,CMU,,Multi-domain Causal Structure Learning in Linear Systems
neurips,2018,0,2613,Alberto Maria,Metelli,polimi,Politecnico di Milano,albertomaria.metelli@polimi.it,Policy Optimization via Importance Sampling
neurips,2018,1,2613,Matteo,Papini,polimi,Politecnico di Milano,matteo.papini@polimi.it,Policy Optimization via Importance Sampling
neurips,2018,2,2613,Francesco,Faccio,polimi,"Politecnico di Milano -                 The Swiss AI Lab, IDSIA (USI & SUPSI)",marcello.restelli@polimi.it,Policy Optimization via Importance Sampling
neurips,2018,3,2613,Marcello,Restelli,polimi,Politecnico di Milano,francesco.faccio@mail.polimi.it,Policy Optimization via Importance Sampling
neurips,2018,0,2528,Aran,Nayebi,,Stanford University,,Task-Driven Convolutional Recurrent Models of the Visual System
neurips,2018,1,2528,Daniel,Bear,,Stanford University,,Task-Driven Convolutional Recurrent Models of the Visual System
neurips,2018,2,2528,Jonas,Kubilius,,Massachusetts Institute of Technology,,Task-Driven Convolutional Recurrent Models of the Visual System
neurips,2018,3,2528,Kohitij,Kar,,MIT,,Task-Driven Convolutional Recurrent Models of the Visual System
neurips,2018,4,2528,Surya,Ganguli,,Stanford,,Task-Driven Convolutional Recurrent Models of the Visual System
neurips,2018,5,2528,David,Sussillo,,Google Inc.,,Task-Driven Convolutional Recurrent Models of the Visual System
neurips,2018,6,2528,James,DiCarlo,,Massachusetts Institute of Technology,,Task-Driven Convolutional Recurrent Models of the Visual System
neurips,2018,7,2528,Daniel,Yamins,,Stanford University,,Task-Driven Convolutional Recurrent Models of the Visual System
neurips,2018,0,7985,Yi,Chen,northwestern,Northwestern University,yichen2016@u.northwestern.edu,Contrastive Learning from Pairwise Measurements
neurips,2018,1,7985,Zhuoran,Yang,northwestern,Princeton University,ycxie@u.northwestern.edu,Contrastive Learning from Pairwise Measurements
neurips,2018,2,7985,Yuchen,Xie,princeton,Northwestern University,zy6@princeton.edu,Contrastive Learning from Pairwise Measurements
neurips,2018,3,7985,Zhaoran,Wang,northwestern,"Princeton, Phd student",zhaoran.wang@northwestern.edu,Contrastive Learning from Pairwise Measurements
neurips,2018,0,6757,Shinji,Ito,,NEC Corporation,,Regret Bounds for Online Portfolio Selection with a Cardinality Constraint
neurips,2018,1,6757,Daisuke,Hatano,,RIKEN AIP,,Regret Bounds for Online Portfolio Selection with a Cardinality Constraint
neurips,2018,2,6757,Hanna,Sumita,,Tokyo Metropolitan University,,Regret Bounds for Online Portfolio Selection with a Cardinality Constraint
neurips,2018,3,6757,Akihiro,Yabe,,,,Regret Bounds for Online Portfolio Selection with a Cardinality Constraint
neurips,2018,4,6757,Takuro,Fukunaga,,"RIKEN AIP, JST PRESTO",,Regret Bounds for Online Portfolio Selection with a Cardinality Constraint
neurips,2018,5,6757,Naonori,Kakimura,,Keio University,,Regret Bounds for Online Portfolio Selection with a Cardinality Constraint
neurips,2018,6,6757,Ken-Ichi,Kawarabayashi,,National Institute of Informatics,,Regret Bounds for Online Portfolio Selection with a Cardinality Constraint
neurips,2018,0,2229,Samuel,Yeom,cmu,Carnegie Mellon University,syeom@cs.cmu.edu,Hunting for Discriminatory Proxies in Linear Regression Models
neurips,2018,1,2229,Anupam,Datta,cmu,Carnegie Mellon University,danupam@cmu.edu,Hunting for Discriminatory Proxies in Linear Regression Models
neurips,2018,2,2229,Matt,Fredrikson,cmu,CMU,mfredrik@cs.cmu.edu,Hunting for Discriminatory Proxies in Linear Regression Models
neurips,2018,0,920,Marylou,Gabrié,,École Normale Supérieure,,Entropy and mutual information in models of deep neural networks
neurips,2018,1,920,Andre,Manoel,,OWKIN,,Entropy and mutual information in models of deep neural networks
neurips,2018,2,920,Clément,Luneau,,École Polytechnique de Lausanne,,Entropy and mutual information in models of deep neural networks
neurips,2018,3,920,jean,barbier,,EPFL,,Entropy and mutual information in models of deep neural networks
neurips,2018,4,920,Nicolas,Macris,,EPFL,,Entropy and mutual information in models of deep neural networks
neurips,2018,5,920,Florent,Krzakala,,École Normale Supérieure,,Entropy and mutual information in models of deep neural networks
neurips,2018,6,920,Lenka,Zdeborová,,CEA Saclay,,Entropy and mutual information in models of deep neural networks
neurips,2018,0,1466,Jangho,Kim,snu,Seoul National University,kjh91@snu.ac.kr,Paraphrasing Complex Network: Network Compression via Factor Transfer
neurips,2018,1,1466,Seonguk,Park,snu,Seoul National University,swpark0703@snu.ac.kr,Paraphrasing Complex Network: Network Compression via Factor Transfer
neurips,2018,2,1466,Nojun,Kwak,snu,Seoul National University,nojunk@snu.ac.kr,Paraphrasing Complex Network: Network Compression via Factor Transfer
neurips,2018,0,6499,Emin,Orhan,gmail,BCM & Rice,aeminorhan@gmail.com,A Simple Cache Model for Image Recognition
neurips,2018,0,5715,Yan,Wu,google,DeepMind,yanwu@google.com,Learning Attractor Dynamics for Generative Memory
neurips,2018,1,5715,Gregory,Wayne,google,Google DeepMind,gregwayne@google.com,Learning Attractor Dynamics for Generative Memory
neurips,2018,2,5715,Karol,Gregor,google,DeepMind,karolg@google.com,Learning Attractor Dynamics for Generative Memory
neurips,2018,3,5715,Timothy,Lillicrap,google,Google DeepMind,countzero@google.com,Learning Attractor Dynamics for Generative Memory
neurips,2018,0,5500,Marina,Munkhoeva,,Skoltech / Skolkovo Institute of Science and Technology,,Quadrature-based features for kernel approximation
neurips,2018,1,5500,Yermek,Kapushev,,Skolkovo Institute of Science and Technology,,Quadrature-based features for kernel approximation
neurips,2018,2,5500,Evgeny,Burnaev,,Skoltech,,Quadrature-based features for kernel approximation
neurips,2018,3,5500,Ivan,Oseledets,,Skoltech,,Quadrature-based features for kernel approximation
neurips,2018,0,29,Francis,Bach,ens,INRIA - Ecole Normale Superieure,francis.bach@ens.fr,Efficient Algorithms for Non-convex Isotonic Regression through Submodular Optimization
neurips,2018,0,426,Bao,Wang,gmail,UCLA,wangbaonj@gmail.com,Deep Neural Nets with Interpolating Function as Output Activation
neurips,2018,1,426,Xiyang,Luo,gmail,Google,xylmath@gmail.com,Deep Neural Nets with Interpolating Function as Output Activation
neurips,2018,2,426,Zhen,Li,gmail,Hong Kong University of Science & Technology,lishen03@gmail.com,Deep Neural Nets with Interpolating Function as Output Activation
neurips,2018,3,426,Wei,Zhu,duke,Duke University,zhu@math.duke.edu,Deep Neural Nets with Interpolating Function as Output Activation
neurips,2018,4,426,Zuoqiang,Shi,tsinghua,zqshi@mail.tsinghua.edu.cn,zqshi@mail.tsinghua.edu.cn,Deep Neural Nets with Interpolating Function as Output Activation
neurips,2018,5,426,Stanley,Osher,ucla,UCLA,sjo@math.ucla.edu,Deep Neural Nets with Interpolating Function as Output Activation
neurips,2018,0,753,Sid,Reddy,berkeley,UC Berkeley,sgr@berkeley.edu,Where Do You Think You're Going?: Inferring Beliefs about Dynamics from Behavior
neurips,2018,1,753,Anca,Dragan,berkeley,UC Berkeley,anca@berkeley.edu,Where Do You Think You're Going?: Inferring Beliefs about Dynamics from Behavior
neurips,2018,2,753,Sergey,Levine,berkeley,UC Berkeley,svlevine@berkeley.edu,Where Do You Think You're Going?: Inferring Beliefs about Dynamics from Behavior
neurips,2018,0,210,Yi,Wang,cuhk,Chinese University of Hong Kong,yiwang@cse.cuhk.edu.hk,Image Inpainting via Generative Multi-column Convolutional Neural Networks
neurips,2018,1,210,Xin,Tao,cuhk,CUHK,xtao@cse.cuhk.edu.hk,Image Inpainting via Generative Multi-column Convolutional Neural Networks
neurips,2018,2,210,Xiaojuan,Qi,cuhk,CUHK,xjqi@cse.cuhk.edu.hk,Image Inpainting via Generative Multi-column Convolutional Neural Networks
neurips,2018,3,210,Xiaoyong,Shen,cuhk,CUHK,leojia@cse.cuhk.edu.hk,Image Inpainting via Generative Multi-column Convolutional Neural Networks
neurips,2018,4,210,Jiaya,Jia,gmail,CUHK,goodshenxy@gmail.com,Image Inpainting via Generative Multi-column Convolutional Neural Networks
neurips,2018,0,5138,Vincent,Cohen-Addad,,CNRS & Sorbonne Université,,Clustering RedemptionBeyond the Impossibility of Kleinbergs Axioms
neurips,2018,1,5138,Varun,Kanade,,University of Oxford,,Clustering RedemptionBeyond the Impossibility of Kleinbergs Axioms
neurips,2018,2,5138,Frederik,Mallmann-Trenn,,MIT,,Clustering RedemptionBeyond the Impossibility of Kleinbergs Axioms
neurips,2018,0,5332,Rudrasis,Chakraborty,,University of Florida,,A Statistical Recurrent Model on the Manifold of Symmetric Positive Definite Matrices
neurips,2018,1,5332,Chun-Hao,Yang,,University of Florida,,A Statistical Recurrent Model on the Manifold of Symmetric Positive Definite Matrices
neurips,2018,2,5332,Xingjian,Zhen,,UW-Madison,,A Statistical Recurrent Model on the Manifold of Symmetric Positive Definite Matrices
neurips,2018,3,5332,Monami,Banerjee,,University of Florida,,A Statistical Recurrent Model on the Manifold of Symmetric Positive Definite Matrices
neurips,2018,4,5332,Derek,Archer,,University of Florida,,A Statistical Recurrent Model on the Manifold of Symmetric Positive Definite Matrices
neurips,2018,5,5332,David,Vaillancourt,,University of Florida,,A Statistical Recurrent Model on the Manifold of Symmetric Positive Definite Matrices
neurips,2018,6,5332,Vikas,Singh,,UW-Madison,,A Statistical Recurrent Model on the Manifold of Symmetric Positive Definite Matrices
neurips,2018,7,5332,Baba,Vemuri,,"University of Florida, USA",,A Statistical Recurrent Model on the Manifold of Symmetric Positive Definite Matrices
neurips,2018,0,1737,Hassan,Ashtiani,mcmaster,McMaster University,zokaeiam@mcmaster.ca,Nearly tight sample complexity bounds for learning mixtures of Gaussians via sample compression schemes
neurips,2018,1,1737,Shai,Ben-David,ubc,University of Waterloo,nickhar@cs.ubc.ca,Nearly tight sample complexity bounds for learning mixtures of Gaussians via sample compression schemes
neurips,2018,2,1737,Nicholas,Harvey,gmail,University of British Columbia,abbasmehrabian@gmail.com,Nearly tight sample complexity bounds for learning mixtures of Gaussians via sample compression schemes
neurips,2018,3,1737,Christopher,Liaw,uwaterloo,University of British Columbia,shai@uwaterloo.ca,Nearly tight sample complexity bounds for learning mixtures of Gaussians via sample compression schemes
neurips,2018,4,1737,Abbas,Mehrabian,ubc,Mcgill University,cvliaw@cs.ubc.ca,Nearly tight sample complexity bounds for learning mixtures of Gaussians via sample compression schemes
neurips,2018,5,1737,Yaniv,Plan,ubc,University of British Columbia,yaniv@math.ubc.ca,Nearly tight sample complexity bounds for learning mixtures of Gaussians via sample compression schemes
neurips,2018,0,6410,Guangxiang,Zhu,outlook,Tsinghua university,guangxiangzhu@outlook.com,Object-Oriented Dynamics Predictor
neurips,2018,1,6410,Zhiao,Huang,tsinghua,"IIIS, Tsinghua University",hza14@mails.tsinghua.edu.cn,Object-Oriented Dynamics Predictor
neurips,2018,2,6410,Chongjie,Zhang,tsinghua,Tsinghua University,chongjie@tsinghua.edu.cn,Object-Oriented Dynamics Predictor
neurips,2018,0,2283,Mingrui,Liu,,The University of Iowa,,Fast Rates of ERM and Stochastic Approximation: Adaptive to Error Bound Conditions
neurips,2018,1,2283,Xiaoxuan,Zhang,,University of Iowa,,Fast Rates of ERM and Stochastic Approximation: Adaptive to Error Bound Conditions
neurips,2018,2,2283,Lijun,Zhang,,Nanjing University (NJU),,Fast Rates of ERM and Stochastic Approximation: Adaptive to Error Bound Conditions
neurips,2018,3,2283,Rong,Jin,,Alibaba,,Fast Rates of ERM and Stochastic Approximation: Adaptive to Error Bound Conditions
neurips,2018,4,2283,Tianbao,Yang,,The University of Iowa,,Fast Rates of ERM and Stochastic Approximation: Adaptive to Error Bound Conditions
neurips,2018,0,5151,Han,Zhao,cmu,Carnegie Mellon University,hzhao1@andrew.cmu.edu,Adversarial Multiple Source Domain Adaptation
neurips,2018,1,5151,Shanghang,Zhang,cmu,Carnegie Mellon University,shanghaz@andrew.cmu.edu,Adversarial Multiple Source Domain Adaptation
neurips,2018,2,5151,Guanhang,Wu,cmu,Carnegie Mellon University,guanhanw@andrew.cmu.edu,Adversarial Multiple Source Domain Adaptation
neurips,2018,3,5151,José M. F.,Moura,cmu,Carnegie Mellon University,moura@andrew.cmu.edu,Adversarial Multiple Source Domain Adaptation
neurips,2018,4,5151,Joao,Costeira,cmu,Instituto Superior Tecnico VAT- 501507930,ggordon@andrew.cmu.edu,Adversarial Multiple Source Domain Adaptation
neurips,2018,5,5151,Geoffrey,Gordon,utl,MSR Montréal & CMU,jpc@isr.ist.utl.pt,Adversarial Multiple Source Domain Adaptation
neurips,2018,0,2654,Heinrich,Jiang,google,Google Research,heinrichj@google.com,To Trust Or Not To Trust A Classifier
neurips,2018,1,2654,Been,Kim,google,Google,beenkim@google.com,To Trust Or Not To Trust A Classifier
neurips,2018,2,2654,Melody,Guan,stanford,Stanford University,mguan@stanford.edu,To Trust Or Not To Trust A Classifier
neurips,2018,3,2654,Maya,Gupta,google,Google,mayagupta@google.com,To Trust Or Not To Trust A Classifier
neurips,2018,0,1615,Utkarsh,Upadhyay,,Max Plank Institute for Software Systems,,Deep Reinforcement Learning of Marked Temporal Point Processes
neurips,2018,1,1615,Abir,De,,Max Planck Insitute for Software Systems,,Deep Reinforcement Learning of Marked Temporal Point Processes
neurips,2018,2,1615,Manuel,Gomez Rodriguez,,Max Planck Institute for Software Systems,,Deep Reinforcement Learning of Marked Temporal Point Processes
neurips,2018,0,5086,Nick,Haber,,Stanford University,,"Learning to Play With Intrinsically-Motivated, Self-Aware Agents"
neurips,2018,1,5086,Damian,Mrowca,,Stanford University,,"Learning to Play With Intrinsically-Motivated, Self-Aware Agents"
neurips,2018,2,5086,Stephanie,Wang,,Stanford University,,"Learning to Play With Intrinsically-Motivated, Self-Aware Agents"
neurips,2018,3,5086,Li,Fei-Fei,,Stanford University & Google,,"Learning to Play With Intrinsically-Motivated, Self-Aware Agents"
neurips,2018,4,5086,Daniel,Yamins,,Stanford University,,"Learning to Play With Intrinsically-Motivated, Self-Aware Agents"
neurips,2018,0,3133,Bargav,Jayaraman,virginia,University of Virginia,bj4nq@virginia.edu,Distributed Learning without Distress: Privacy-Preserving Empirical Risk Minimization
neurips,2018,1,3133,Lingxiao,Wang,virginia,"University of California, Los Angeles",evans@virginia.edu,Distributed Learning without Distress: Privacy-Preserving Empirical Risk Minimization
neurips,2018,2,3133,David,Evans,ucla,University of Virginia,lingxw@cs.ucla.edu,Distributed Learning without Distress: Privacy-Preserving Empirical Risk Minimization
neurips,2018,3,3133,Quanquan,Gu,ucla,UCLA,qgu@cs.ucla.edu,Distributed Learning without Distress: Privacy-Preserving Empirical Risk Minimization
neurips,2018,0,1484,Motoya,Ohnishi,riken,Keio University/KTH Royal Institute of Technology/RIKEN,motoya.ohnishi@riken.jp,Continuous-time Value Function Approximation in Reproducing Kernel Hilbert Spaces
neurips,2018,1,1484,Masahiro,Yukawa,kth,Keio University,mikaelj@ee.kth.se,Continuous-time Value Function Approximation in Reproducing Kernel Hilbert Spaces
neurips,2018,2,1484,Mikael,Johansson,keio,KTH - Royal Institute of Technology,yukawa@elec.keio.ac.jp,Continuous-time Value Function Approximation in Reproducing Kernel Hilbert Spaces
neurips,2018,3,1484,Masashi,Sugiyama,riken,RIKEN / University of Tokyo,masashi.sugiyama@riken.jp,Continuous-time Value Function Approximation in Reproducing Kernel Hilbert Spaces
neurips,2018,0,782,ChenHan,Jiang,gmail,Sun Yat-sen University,jchcyan@gmail.com,Hybrid Knowledge Routed Modules for Large-scale Object Detection
neurips,2018,1,782,Hang,Xu,live,Huawei Noah's Ark Lab,xbjxh@live.com,Hybrid Knowledge Routed Modules for Large-scale Object Detection
neurips,2018,2,782,Xiaodan,Liang,gmail,Sun Yat-sen University,xdliang328@gmail.com,Hybrid Knowledge Routed Modules for Large-scale Object Detection
neurips,2018,3,782,Liang,Lin,ieee,Sun Yat-Sen University,linliang@ieee.org,Hybrid Knowledge Routed Modules for Large-scale Object Detection
neurips,2018,0,2413,Vikas,Garg,mit,MIT,vgarg@csail.mit.edu,Supervising Unsupervised Learning
neurips,2018,1,2413,Adam,Kalai,microsoft,Microsoft Research,noreply@microsoft.com,Supervising Unsupervised Learning
neurips,2018,0,1080,Xueyu,Mao,utexas,University of Texas at Austin,xmao@cs.utexas.edu,"Overlapping Clustering Models, and One (class) SVM to Bind Them All"
neurips,2018,1,1080,Purnamrita,Sarkar,utexas,UT Austin,purna.sarkar@austin.utexas.edu,"Overlapping Clustering Models, and One (class) SVM to Bind Them All"
neurips,2018,2,1080,Deepayan,Chakrabarti,utexas,UT Austin,deepay@utexas.edu,"Overlapping Clustering Models, and One (class) SVM to Bind Them All"
neurips,2018,0,3408,Wei,Cao,tsinghua,Tsinghua University,cao-13@tsinghua.org.cn,BRITS: Bidirectional Recurrent Imputation for Time Series
neurips,2018,1,3408,Dong,Wang,gmail,Duke University,haozhou0806@gmail.com,BRITS: Bidirectional Recurrent Imputation for Time Series
neurips,2018,2,3408,Jian,Li,duke,Tsinghua University,dong.wang363@duke.edu,BRITS: Bidirectional Recurrent Imputation for Time Series
neurips,2018,3,3408,Hao,Zhou,bytedance,Bytedance AI Lab,liyitan@bytedance.com,BRITS: Bidirectional Recurrent Imputation for Time Series
neurips,2018,4,3408,Lei,Li,tsinghua,ByteDance AI Lab,lijian83@mail.tsinghua.edu.cn,BRITS: Bidirectional Recurrent Imputation for Time Series
neurips,2018,5,3408,Yitan,Li,bytedance,ByteDance.Inc,lileilab@bytedance.com,BRITS: Bidirectional Recurrent Imputation for Time Series
neurips,2018,0,6046,Manish,Purohit,gmail,Google,ravi.k53@gmail.com,Improving Online Algorithms via ML Predictions
neurips,2018,1,6046,Zoya,Svitkina,google,Google,mpurohit@google.com,Improving Online Algorithms via ML Predictions
neurips,2018,2,6046,Ravi,Kumar,cornell,Google,zoya@cs.cornell.edu,Improving Online Algorithms via ML Predictions
neurips,2018,0,3170,Jack,Klys,toronto,University of Toronto,jackklys@cs.toronto.edu,Learning Latent Subspaces in Variational Autoencoders
neurips,2018,1,3170,Jake,Snell,toronto,"University of Toronto, Vector Institute",jsnell@cs.toronto.edu,Learning Latent Subspaces in Variational Autoencoders
neurips,2018,2,3170,Richard,Zemel,toronto,Vector Institute/University of Toronto,zemel@cs.toronto.edu,Learning Latent Subspaces in Variational Autoencoders
neurips,2018,0,3774,Kevin,Duarte,ucf,University of Central Florida,kevin_duarte@knights.ucf.edu,VideoCapsuleNet: A Simplified Network for Action Detection
neurips,2018,1,3774,Yogesh,Rawat,ucf,University of Central Florida,yogesh@crcv.ucf.edu,VideoCapsuleNet: A Simplified Network for Action Detection
neurips,2018,2,3774,Mubarak,Shah,ucf,University of Central Florida,shah@crcv.ucf.edu,VideoCapsuleNet: A Simplified Network for Action Detection
neurips,2018,0,3470,Jovana,Mitrovic,,University of Oxford,,Causal Inference via Kernel Deviance Measures
neurips,2018,1,3470,Dino,Sejdinovic,,University of Oxford,,Causal Inference via Kernel Deviance Measures
neurips,2018,2,3470,Yee Whye,Teh,,"University of Oxford, DeepMind",,Causal Inference via Kernel Deviance Measures
neurips,2018,0,5214,Adam,Kosiorek,,University of Oxford,,"Sequential Attend, Infer, Repeat: Generative Modelling of Moving Objects"
neurips,2018,1,5214,Hyunjik,Kim,,,,"Sequential Attend, Infer, Repeat: Generative Modelling of Moving Objects"
neurips,2018,2,5214,Yee Whye,Teh,,"University of Oxford, DeepMind",,"Sequential Attend, Infer, Repeat: Generative Modelling of Moving Objects"
neurips,2018,3,5214,Ingmar,Posner,,Oxford University,,"Sequential Attend, Infer, Repeat: Generative Modelling of Moving Objects"
neurips,2018,0,6538,Luigi,Carratino,,University of Genoa,,Learning with SGD and Random Features
neurips,2018,1,6538,Alessandro,Rudi,,"INRIA, Ecole Normale Superieure",,Learning with SGD and Random Features
neurips,2018,2,6538,Lorenzo,Rosasco,,University of Genova- MIT - IIT,,Learning with SGD and Random Features
neurips,2018,0,2272,Sanjeeb,Dash,ibm,IBM Research,sanjeebd@us.ibm.com,Boolean Decision Rules via Column Generation
neurips,2018,1,2272,Oktay,Gunluk,ibm,IBM Research,gunluk@us.ibm.com,Boolean Decision Rules via Column Generation
neurips,2018,2,2272,Dennis,Wei,ibm,IBM Research,dwei@us.ibm.com,Boolean Decision Rules via Column Generation
neurips,2018,0,2797,Michael,Tsang,usc,University of Southern California,tsangm@usc.edu,Neural Interaction Transparency (NIT): Disentangling Learned Interactions for Improved Interpretability
neurips,2018,1,2797,Hanpeng,Liu,usc,University of Southern California,hanpengl@usc.edu,Neural Interaction Transparency (NIT): Disentangling Learned Interactions for Improved Interpretability
neurips,2018,2,2797,Sanjay,Purushotham,usc,University of Maryland Baltimore County,spurusho@usc.edu,Neural Interaction Transparency (NIT): Disentangling Learned Interactions for Improved Interpretability
neurips,2018,3,2797,Pavankumar,Murali,usc,IBM,yanliu.cs@usc.edu,Neural Interaction Transparency (NIT): Disentangling Learned Interactions for Improved Interpretability
neurips,2018,4,2797,Yan,Liu,ibm,DiDi AI Labs,pavanm@us.ibm.com,Neural Interaction Transparency (NIT): Disentangling Learned Interactions for Improved Interpretability
neurips,2018,0,1726,Francesco,Locatello,,MPI Tübingen - ETH Zürich,,Boosting Black Box Variational Inference
neurips,2018,1,1726,Gideon,Dresdner,,ETH Zürich,,Boosting Black Box Variational Inference
neurips,2018,2,1726,Rajiv,Khanna,,University of Texas at Austin,,Boosting Black Box Variational Inference
neurips,2018,3,1726,Isabel,Valera,,Max Planck Institute for Intelligent Systems,,Boosting Black Box Variational Inference
neurips,2018,4,1726,Gunnar,Raetsch,,ETHZ,,Boosting Black Box Variational Inference
neurips,2018,0,8009,Aniket (Nick),Bajpai,gmail,MIT,quantum.computing96@gmail.com,Transfer of Deep Reactive Policies for MDP Planning
neurips,2018,1,8009,Sankalp,Garg,gmail,Indian Institute of Technology Delhi,sankalp2621998@gmail.com,Transfer of Deep Reactive Policies for MDP Planning
neurips,2018,2,8009,Mausam,,iitd,IIT Dehli,mausam@cse.iitd.ac.in,Transfer of Deep Reactive Policies for MDP Planning
neurips,2018,0,5015,Luigi,Acerbi,unige,University of Geneva,luigi.acerbi@unige.ch,Variational Bayesian Monte Carlo
neurips,2018,0,3090,Bart,van Merrienboer,,"MILA, Google",,Tangent: Automatic differentiation using source-code transformation for dynamically typed array programming
neurips,2018,1,3090,Dan,Moldovan,,Google,,Tangent: Automatic differentiation using source-code transformation for dynamically typed array programming
neurips,2018,2,3090,Alexander,Wiltschko,,Google Brain,,Tangent: Automatic differentiation using source-code transformation for dynamically typed array programming
neurips,2018,0,2577,Marcell,Vazquez-Chanlatte,berkeley,"University of California, Berkeley",marcell.vc@eecs.berkeley.edu,Learning Task Specifications from Demonstrations
neurips,2018,1,2577,Susmit,Jha,berkeley,SRI International,sseshia@eecs.berkeley.edu,Learning Task Specifications from Demonstrations
neurips,2018,2,2577,Ashish,Tiwari,berkeley,SRI International,mark_ho@eecs.berkeley.edu,Learning Task Specifications from Demonstrations
neurips,2018,3,2577,Mark,Ho,sri,UC Berkeley,susmit.jha@sri.com,Learning Task Specifications from Demonstrations
neurips,2018,4,2577,Sanjit,Seshia,sri,UC Berkeley,tiwari@sri.com,Learning Task Specifications from Demonstrations
neurips,2018,0,7997,Guy,Bresler,mit,MIT,guy@mit.edu,Sparse PCA from Sparse Linear Regression
neurips,2018,1,7997,Sung Min,Park,mit,MIT,sp765@mit.edu,Sparse PCA from Sparse Linear Regression
neurips,2018,2,7997,Madalina,Persu,mit,"Two Sigma Investments, MIT",mpersu@mit.edu,Sparse PCA from Sparse Linear Regression
neurips,2018,0,3497,Alexander,Alemi,google,Google,alemi@google.com,GILBO: One Metric to Measure Them All
neurips,2018,1,3497,Ian,Fischer,google,Google,iansf@google.com,GILBO: One Metric to Measure Them All
neurips,2018,0,3444,Jennifer,Gillenwater,google,Google,jengi@google.com,Maximizing Induced Cardinality Under a Determinantal Point Process
neurips,2018,1,3444,Alex,Kulesza,google,Google,kulesza@google.com,Maximizing Induced Cardinality Under a Determinantal Point Process
neurips,2018,2,3444,Sergei,Vassilvitskii,mit,Google,zelda@csail.mit.edu,Maximizing Induced Cardinality Under a Determinantal Point Process
neurips,2018,3,3444,Zelda,Mariet,google,MIT,sergeiv@google.com,Maximizing Induced Cardinality Under a Determinantal Point Process
neurips,2018,0,429,Shuyang,Sun,,The University of Sydney,,"FishNet: A Versatile Backbone for Image, Region, and Pixel Level Prediction"
neurips,2018,1,429,Jiangmiao,Pang,,Zhejiang University,,"FishNet: A Versatile Backbone for Image, Region, and Pixel Level Prediction"
neurips,2018,2,429,Jianping,Shi,,Sensetime Group Limited,,"FishNet: A Versatile Backbone for Image, Region, and Pixel Level Prediction"
neurips,2018,3,429,Shuai,Yi,,SenseTime Group Limited,,"FishNet: A Versatile Backbone for Image, Region, and Pixel Level Prediction"
neurips,2018,4,429,Wanli,Ouyang,,The University of Sydney,,"FishNet: A Versatile Backbone for Image, Region, and Pixel Level Prediction"
neurips,2018,0,914,Horia,Mania,berkeley,UC Berkeley,hmania@berkeley.edu,Simple random search of static linear policies is competitive for reinforcement learning
neurips,2018,1,914,Aurelia,Guy,berkeley,UC Berkeley,lia@berkeley.edu,Simple random search of static linear policies is competitive for reinforcement learning
neurips,2018,2,914,Benjamin,Recht,berkeley,UC Berkeley,brecht@berkeley.edu,Simple random search of static linear policies is competitive for reinforcement learning
neurips,2018,0,5277,Bart,van Merrienboer,google,"MILA, Google",bartvm@google.com,Automatic differentiation in ML: Where we are and where we should be going
neurips,2018,1,5277,Olivier,Breuleux,umontreal,MILA,breuleuo@iro.umontreal.ca,Automatic differentiation in ML: Where we are and where we should be going
neurips,2018,2,5277,Arnaud,Bergeron,umontreal,Université de Montréal (MILA),bergearn@iro.umontreal.ca,Automatic differentiation in ML: Where we are and where we should be going
neurips,2018,3,5277,Pascal,Lamblin,google,Google,lamblinp@google.com,Automatic differentiation in ML: Where we are and where we should be going
neurips,2018,0,5345,Eui Chul,Shin,berkeley,UC Berkeley,ricshin@cs.berkeley.edu,Improving Neural Program Synthesis with Inferred Execution Traces
neurips,2018,1,5345,Illia,Polosukhin,nearprotocol,NEAR,illia@nearprotocol.com,Improving Neural Program Synthesis with Inferred Execution Traces
neurips,2018,2,5345,Dawn,Song,berkeley,UC Berkeley,dawnsong@cs.berkeley.edu,Improving Neural Program Synthesis with Inferred Execution Traces
neurips,2018,0,6704,Trefor,Evans,utoronto,University of Toronto,trefor.evans@mail.utoronto.ca,Discretely Relaxing Continuous Variables for tractable Variational Inference
neurips,2018,1,6704,Prasanth,Nair,utoronto,University of Toronto,pbn@utias.utoronto.ca,Discretely Relaxing Continuous Variables for tractable Variational Inference
neurips,2018,0,3150,Jonathan,Ullman,,Northeastern University,,The Limits of Post-Selection Generalization
neurips,2018,1,3150,Adam,Smith,,Boston University,,The Limits of Post-Selection Generalization
neurips,2018,2,3150,Kobbi,Nissim,,Georgetown University,,The Limits of Post-Selection Generalization
neurips,2018,3,3150,Uri,Stemmer,,Ben-Gurion University,,The Limits of Post-Selection Generalization
neurips,2018,4,3150,Thomas,Steinke,,IBM Research - Almaden,,The Limits of Post-Selection Generalization
neurips,2018,0,3690,Sofiane,Dhouib,insa-lyon,CREATIS UMR CNRS 5220,sofiane.dhouib@creatis.insa-lyon.fr,"Revisiting $(\epsilon, \gamma, \tau)$-similarity learning for domain adaptation"
neurips,2018,1,3690,Ievgen,Redko,univ-st-etienne,Hubert Curien laboratory,ievgen.redko@univ-st-etienne.fr,"Revisiting $(\epsilon, \gamma, \tau)$-similarity learning for domain adaptation"
neurips,2018,0,5744,Jayadev,Acharya,cornell,Cornell University,acharya@cornell.edu,Learning and Testing Causal Models with Interventions
neurips,2018,1,5744,Arnab,Bhattacharyya,iisc,National University of Singapore & Indian Institute of Science,arnabb@iisc.ac.in,Learning and Testing Causal Models with Interventions
neurips,2018,2,5744,Constantinos,Daskalakis,mit,MIT,costis@csail.mit.edu,Learning and Testing Causal Models with Interventions
neurips,2018,3,5744,Saravanan,Kandasamy,gmail,Tata Institute of Fundamental Research,saravan.tuty@gmail.com,Learning and Testing Causal Models with Interventions
neurips,2018,0,2590,Rein,Houthooft,,Happy Elements,,Evolved Policy Gradients
neurips,2018,1,2590,Yuhua,Chen,,Happy Elements Inc.,,Evolved Policy Gradients
neurips,2018,2,2590,Phillip,Isola,,OpenAI,,Evolved Policy Gradients
neurips,2018,3,2590,Bradly,Stadie,,UC Berkeley,,Evolved Policy Gradients
neurips,2018,4,2590,Filip,Wolski,,OpenAI,,Evolved Policy Gradients
neurips,2018,5,2590,OpenAI,Jonathan Ho,,"OpenAI, UC Berkeley",,Evolved Policy Gradients
neurips,2018,6,2590,Pieter,Abbeel,,UC Berkeley | Gradescope | Covariant,,Evolved Policy Gradients
neurips,2018,0,1477,Chaitanya,Ryali,ucsd,UC San Diego,rckrishn@eng.ucsd.edu,Demystifying excessively volatile human learning: A Bayesian persistent prior and a neural approximation
neurips,2018,1,1477,Gautam,Reddy,ucsd,"University of California, San Diego",gnallama@physics.ucsd.edu,Demystifying excessively volatile human learning: A Bayesian persistent prior and a neural approximation
neurips,2018,2,1477,Angela,Yu,ucsd,UC San Diego,ajyu@ucsd.edu,Demystifying excessively volatile human learning: A Bayesian persistent prior and a neural approximation
neurips,2018,0,5057,Rizal,Fathony,uic,University of Illinois at Chicago,rfatho2@uic.edu,Distributionally Robust Graphical Models
neurips,2018,1,5057,Ashkan,Rezaei,uic,University of Illinois at Chicago,arezae4@uic.edu,Distributionally Robust Graphical Models
neurips,2018,2,5057,Mohammad Ali,Bashiri,uic,University of Illinois at Chicago,mbashi4@uic.edu,Distributionally Robust Graphical Models
neurips,2018,3,5057,Xinhua,Zhang,uic,UIC,zhangx@uic.edu,Distributionally Robust Graphical Models
neurips,2018,4,5057,Brian,Ziebart,uic,University of Illinois at Chicago,bziebart@uic.edu,Distributionally Robust Graphical Models
neurips,2018,0,1376,Zeyuan,Allen-Zhu,mit,Microsoft Research,zeyuan@csail.mit.edu,Natasha 2: Faster Non-Convex Optimization Than SGD
neurips,2018,0,5440,Amir-massoud,Farahmand,vectorinstitute,Vector Institute,farahmand@vectorinstitute.ai,Iterative Value-Aware Model Learning
neurips,2018,0,6601,Joseph,Antognini,gmail,Whisper AI,joe.antognini@gmail.com,PCA of high dimensional random walks with comparison to neural network training
neurips,2018,1,6601,Jascha,Sohl-Dickstein,google,Google Brain,jaschasd@google.com,PCA of high dimensional random walks with comparison to neural network training
neurips,2018,0,4859,Kevin,Ellis,mit,MIT,ellisk@mit.edu,Learning Libraries of Subroutines for NeurallyGuided Bayesian Program Induction
neurips,2018,1,4859,Lucas,Morales,mit,MIT,lucasem@mit.edu,Learning Libraries of Subroutines for NeurallyGuided Bayesian Program Induction
neurips,2018,2,4859,Mathias,Sablé-Meyer,mit,MIT,mathsm@mit.edu,Learning Libraries of Subroutines for NeurallyGuided Bayesian Program Induction
neurips,2018,3,4859,Armando,Solar-Lezama,mit,MIT,asolar@csail.mit.edu,Learning Libraries of Subroutines for NeurallyGuided Bayesian Program Induction
neurips,2018,4,4859,Josh,Tenenbaum,mit,MIT,jbt@mit.edu,Learning Libraries of Subroutines for NeurallyGuided Bayesian Program Induction
neurips,2018,0,3643,Enayat,Ullah,jhu,Johns Hopkins University,enayat@jhu.edu,Streaming Kernel PCA with $\tilde{O}(\sqrt{n})$ Random Features
neurips,2018,1,3643,Poorya,Mianjy,jhu,Johns Hopkins University,mianjy@jhu.edu,Streaming Kernel PCA with $\tilde{O}(\sqrt{n})$ Random Features
neurips,2018,2,3643,Teodor Vanislavov,Marinov,jhu,Johns Hopkins University,tmarino2@jhu.edu,Streaming Kernel PCA with $\tilde{O}(\sqrt{n})$ Random Features
neurips,2018,3,3643,Raman,Arora,jhu,Johns Hopkins University,arora@cs.jhu.edu,Streaming Kernel PCA with $\tilde{O}(\sqrt{n})$ Random Features
neurips,2018,0,1941,Lionel,Gueguen,uber,UBER,lgueguen@uber.com,Faster Neural Networks Straight from JPEG
neurips,2018,1,1941,Alex,Sergeev,uber,"Uber Technologies Inc,",asergeev@uber.com,Faster Neural Networks Straight from JPEG
neurips,2018,2,1941,Ben,Kadlec,uber,Uber,bkadlec@uber.com,Faster Neural Networks Straight from JPEG
neurips,2018,3,1941,Rosanne,Liu,uber,Uber AI Labs,rosanne@uber.com,Faster Neural Networks Straight from JPEG
neurips,2018,4,1941,Jason,Yosinski,uber,Uber AI Labs; Recursion,yosinski@uber.com,Faster Neural Networks Straight from JPEG
neurips,2018,0,993,Fei,Jiang,hku,The University of Hong Kong,feijiang@hku.hk,Bayesian Model Selection Approach to Boundary Detection with Non-Local Priors
neurips,2018,1,993,Guosheng,Yin,hku,University of Hong Kong,gyin@hku.hk,Bayesian Model Selection Approach to Boundary Detection with Non-Local Priors
neurips,2018,2,993,Francesca,Dominici,harvard,Harvard University,fdominic@hsph.harvard.edu,Bayesian Model Selection Approach to Boundary Detection with Non-Local Priors
neurips,2018,0,2381,Yi,Tay,ntu,Nanyang Technological University,ytay017@e.ntu.edu.sg1,Densely Connected Attention Propagation for Reading Comprehension
neurips,2018,1,2381,Anh Tuan,Luu,a-star,Institute for Infocomm Research,at.luu@i2r.a-star.edu.sg2,Densely Connected Attention Propagation for Reading Comprehension
neurips,2018,2,2381,Siu Cheung,Hui,ntu,Nanyang Technological University,asschui@ntu.edu.sg3,Densely Connected Attention Propagation for Reading Comprehension
neurips,2018,3,2381,Jian,Su,a-star,"I2R, Singapore",sujian@i2r.a-star.edu.sg4,Densely Connected Attention Propagation for Reading Comprehension
neurips,2018,0,1236,Kuang,Xu,stanford,Stanford Graduate School of Business,kuangxu@stanford.edu,Query Complexity of Bayesian Private Learning
neurips,2018,0,1571,Marco,Ciccone,polimi,Politecnico di Milano,marco.ciccone@polimi.it,NAIS-Net: Stable Deep Networks from Non-Autonomous  Differential Equations
neurips,2018,1,1571,Marco,Gallieri,nnaisense,NNAISENSE,marco@nnaisense.com,NAIS-Net: Stable Deep Networks from Non-Autonomous  Differential Equations
neurips,2018,2,1571,Jonathan,Masci,nnaisense,NNAISENSE,jonathan@nnaisense.com,NAIS-Net: Stable Deep Networks from Non-Autonomous  Differential Equations
neurips,2018,3,1571,Christian,Osendorfer,nnaisense,NNAISENSE,christian@nnaisense.com,NAIS-Net: Stable Deep Networks from Non-Autonomous  Differential Equations
neurips,2018,4,1571,Faustino,Gomez,nnaisense,NNAISENSE,tino@nnaisense.com,NAIS-Net: Stable Deep Networks from Non-Autonomous  Differential Equations
neurips,2018,0,3124,Emilie,Kaufmann,,CNRS & CRIStAL (SequeL),,Sequential Test for the Lowest Mean: From Thompson to Murphy Sampling
neurips,2018,1,3124,Wouter,Koolen,,"Centrum Wiskunde & Informatica, Amsterdam",,Sequential Test for the Lowest Mean: From Thompson to Murphy Sampling
neurips,2018,2,3124,Aurélien,Garivier,,ENS Lyon,,Sequential Test for the Lowest Mean: From Thompson to Murphy Sampling
neurips,2018,0,2456,Lajanugen,Logeswaran,umich,University of Michigan,llajan@umich.edu,Content preserving text generation with attribute controls
neurips,2018,1,2456,Honglak,Lee,google,Google Brain,honglak@google.com,Content preserving text generation with attribute controls
neurips,2018,2,2456,Samy,Bengio,google,Google Brain,bengio@google.com,Content preserving text generation with attribute controls
neurips,2018,0,1776,Daniel,Johnson,hmc,Harvey Mudd College,ddjohnson@hmc.edu,Latent Gaussian Activity Propagation: Using Smoothness and Structure to Separate and Localize Sounds in Large Noisy Environments
neurips,2018,1,1776,Daniel,Gorelik,hmc,Harvey Mudd College,dgorelik@hmc.edu,Latent Gaussian Activity Propagation: Using Smoothness and Structure to Separate and Localize Sounds in Large Noisy Environments
neurips,2018,2,1776,Ross,Mawhorter,hmc,Harvey Mudd College,rmawhorter@hmc.edu,Latent Gaussian Activity Propagation: Using Smoothness and Structure to Separate and Localize Sounds in Large Noisy Environments
neurips,2018,3,1776,Kyle,Suver,hmc,Harvey Mudd College,ksuver@hmc.edu,Latent Gaussian Activity Propagation: Using Smoothness and Structure to Separate and Localize Sounds in Large Noisy Environments
neurips,2018,4,1776,Weiqing,Gu,hmc,Harvey Mudd College,gu@hmc.edu,Latent Gaussian Activity Propagation: Using Smoothness and Structure to Separate and Localize Sounds in Large Noisy Environments
neurips,2018,5,1776,Steven,Xing,intel,Intel Corporation,steven.xing@intel.com,Latent Gaussian Activity Propagation: Using Smoothness and Structure to Separate and Localize Sounds in Large Noisy Environments
neurips,2018,6,1776,Cody,Gabriel,intel,Intel Corporation,cody.gabriel@intel.com,Latent Gaussian Activity Propagation: Using Smoothness and Structure to Separate and Localize Sounds in Large Noisy Environments
neurips,2018,7,1776,Peter,Sankhagowit,intel,Intel Corporation,peter.sankhagowit@intel.com,Latent Gaussian Activity Propagation: Using Smoothness and Structure to Separate and Localize Sounds in Large Noisy Environments
neurips,2018,0,3440,Jayadev,Acharya,cornell,Cornell University,acharya@cornell.edu,Differentially Private Testing of Identity and Closeness of Discrete Distributions
neurips,2018,1,3440,Ziteng,Sun,cornell,Cornell University,zs335@cornell.edu,Differentially Private Testing of Identity and Closeness of Discrete Distributions
neurips,2018,2,3440,Huanyu,Zhang,cornell,Cornell University,hz388@cornell.edu,Differentially Private Testing of Identity and Closeness of Discrete Distributions
neurips,2018,0,2334,Quoc,Tran Dinh,unc,"Department of Statistics and Operations Research, University of North Carolina at Chapel Hill, North Carolina",quoctd@email.unc.edu,Non-Ergodic Alternating Proximal  Augmented Lagrangian Algorithms with Optimal Rates
neurips,2018,0,5773,Rajan,Udwani,mit,MIT,rudwani@alum.mit.edu,Multi-objective Maximization of Monotone Submodular Functions with Cardinality Constraint
neurips,2018,0,2582,Casper,Freksen,cs,Aarhus University,cfreksen@cs.au.dk,Fully Understanding The Hashing Trick
neurips,2018,1,2582,Lior,Kamma,cs,Aarhus University,lior.kamma@cs.au.dk,Fully Understanding The Hashing Trick
neurips,2018,2,2582,Kasper,Green Larsen,cs,"Aarhus University, MADALGO",larsen@cs.au.dk,Fully Understanding The Hashing Trick
neurips,2018,0,5356,Andrea,Tirinzoni,polimi,Politecnico di Milano,andrea.tirinzoni@polimi.it,Policy-Conditioned Uncertainty Sets for Robust Markov Decision Processes
neurips,2018,1,5356,Marek,Petrik,amazon,University of New Hampshire,cxiangli@amazon.com,Policy-Conditioned Uncertainty Sets for Robust Markov Decision Processes
neurips,2018,2,5356,Xiangli,Chen,unh,University of Illinois at Chicago,mpetrik@cs.unh.edu,Policy-Conditioned Uncertainty Sets for Robust Markov Decision Processes
neurips,2018,3,5356,Brian,Ziebart,uic,University of Illinois at Chicago,bziebart@uic.edu,Policy-Conditioned Uncertainty Sets for Robust Markov Decision Processes
neurips,2018,0,5535,Ashvin,Nair,berkeley,UC Berkeley,anair17@berkeley.edu,Visual Reinforcement Learning with Imagined Goals
neurips,2018,1,5535,Vitchyr,Pong,berkeley,UC Berkeley,vitchyr@berkeley.edu,Visual Reinforcement Learning with Imagined Goals
neurips,2018,2,5535,Murtaza,Dalal,berkeley,"University of California, Berkeley",mdalal@berkeley.edu,Visual Reinforcement Learning with Imagined Goals
neurips,2018,3,5535,Shikhar,Bahl,berkeley,UC Berkeley,shikharbahl@berkeley.edu,Visual Reinforcement Learning with Imagined Goals
neurips,2018,4,5535,Steven,Lin,berkeley,UC Berkeley,stevenlin598@berkeley.edu,Visual Reinforcement Learning with Imagined Goals
neurips,2018,5,5535,Sergey,Levine,berkeley,UC Berkeley,svlevine@berkeley.edu,Visual Reinforcement Learning with Imagined Goals
neurips,2018,0,6839,Golnaz,Ghiasi,,Google,,DropBlock: A regularization method for convolutional networks
neurips,2018,1,6839,Tsung-Yi,Lin,,Google Brain,,DropBlock: A regularization method for convolutional networks
neurips,2018,2,6839,Quoc,Le,,Google,,DropBlock: A regularization method for convolutional networks
neurips,2018,0,2889,Alberto,Bernacchia,cam,University of Cambridge,ab2347@cam.ac.uk,Exact natural gradient in deep linear networks and its application to the nonlinear case
neurips,2018,1,2889,Mate,Lengyel,cam,University of Cambridge,m.lengyel@eng.cam.ac.uk,Exact natural gradient in deep linear networks and its application to the nonlinear case
neurips,2018,2,2889,Guillaume,Hennequin,cam,Cambridge,g.hennequin@eng.cam.ac.uk,Exact natural gradient in deep linear networks and its application to the nonlinear case
neurips,2018,0,1960,Zhen,Zhang,wustl,WASHINGTON UNIVERSITY IN ST.LOUIS,zhen.zhang@wustl.edu,RetGK: Graph Kernels based on Return Probabilities of Random Walks
neurips,2018,1,1960,Mianzhi,Wang,wustl,Washington University in St. Louis,mianzhi.wang@wustl.edu,RetGK: Graph Kernels based on Return Probabilities of Random Walks
neurips,2018,2,1960,Yijian,Xiang,wustl,Washington University in St. Louis,yijian.xiang@wustl.edu,RetGK: Graph Kernels based on Return Probabilities of Random Walks
neurips,2018,3,1960,Yan,Huang,wustl,Washington University in St. Louis,yanhuang640@wustl.edu,RetGK: Graph Kernels based on Return Probabilities of Random Walks
neurips,2018,4,1960,Arye,Nehorai,wustl,WASHINGTON UNIVERSITY IN ST.LOUIS,nehorai@wustl.edu,RetGK: Graph Kernels based on Return Probabilities of Random Walks
neurips,2018,0,687,Taylor,Mordan,lip6,"Sorbonne Université, LIP6",taylor.mordan@lip6.fr,Revisiting Multi-Task Learning with ROCK: a Deep Residual Auxiliary Block for Visual Detection
neurips,2018,1,687,Nicolas,THOME,cnam,Cnam,nicolas.thome@cnam.fr,Revisiting Multi-Task Learning with ROCK: a Deep Residual Auxiliary Block for Visual Detection
neurips,2018,2,687,Gilles,Henaff,thalesgroup,Thales Optronique S.A.S.,gilles.henaff@fr.thalesgroup.com,Revisiting Multi-Task Learning with ROCK: a Deep Residual Auxiliary Block for Visual Detection
neurips,2018,3,687,Matthieu,Cord,lip6,Sorbonne University,matthieu.cord@lip6.fr,Revisiting Multi-Task Learning with ROCK: a Deep Residual Auxiliary Block for Visual Detection
neurips,2018,0,1485,Zhiqiang,Xu,,Baidu Inc.,,Gradient Descent Meets Shift-and-Invert Preconditioning for Eigenvector Computation
neurips,2018,0,1687,Edward,Hughes,,DeepMind,,Inequity aversion improves cooperation in intertemporal social dilemmas
neurips,2018,1,1687,Joel,Leibo,,DeepMind,,Inequity aversion improves cooperation in intertemporal social dilemmas
neurips,2018,2,1687,Matthew,Phillips,,DeepMind,,Inequity aversion improves cooperation in intertemporal social dilemmas
neurips,2018,3,1687,Karl,Tuyls,,DeepMind,,Inequity aversion improves cooperation in intertemporal social dilemmas
neurips,2018,4,1687,Edgar,Dueñez-Guzman,,DeepMind,,Inequity aversion improves cooperation in intertemporal social dilemmas
neurips,2018,5,1687,Antonio,García Castañeda,,DeepMind,,Inequity aversion improves cooperation in intertemporal social dilemmas
neurips,2018,6,1687,Iain,Dunning,,DeepMind,,Inequity aversion improves cooperation in intertemporal social dilemmas
neurips,2018,7,1687,Tina,Zhu,,DeepMind,,Inequity aversion improves cooperation in intertemporal social dilemmas
neurips,2018,8,1687,Kevin,McKee,,DeepMind,,Inequity aversion improves cooperation in intertemporal social dilemmas
neurips,2018,9,1687,Raphael,Koster,,DeepMind,,Inequity aversion improves cooperation in intertemporal social dilemmas
neurips,2018,10,1687,Heather,Roff,,DeepMind,,Inequity aversion improves cooperation in intertemporal social dilemmas
neurips,2018,11,1687,Thore,Graepel,,DeepMind,,Inequity aversion improves cooperation in intertemporal social dilemmas
neurips,2018,0,6383,Raymond,Li,,Polytechnique Montréal,,Towards Deep Conversational Recommendations
neurips,2018,1,6383,Samira,Ebrahimi Kahou,,Microsoft,,Towards Deep Conversational Recommendations
neurips,2018,2,6383,Hannes,Schulz,,"Microsoft Research, Montreal",,Towards Deep Conversational Recommendations
neurips,2018,3,6383,Vincent,Michalski,,Université de Montréal,,Towards Deep Conversational Recommendations
neurips,2018,4,6383,Laurent,Charlin,,MILA / U.Montreal,,Towards Deep Conversational Recommendations
neurips,2018,5,6383,Chris,Pal,,"MILA, Polytechnique Montréal, Element AI",,Towards Deep Conversational Recommendations
neurips,2018,0,2866,Michael,Tschannen,ethz,ETH Zurich,michaelt@nari.ee.ethz.ch,Deep Generative Models for Distribution-Preserving Lossy Compression
neurips,2018,1,2866,Eirikur,Agustsson,google,ETH Zurich,eirikur@google.com,Deep Generative Models for Distribution-Preserving Lossy Compression
neurips,2018,2,2866,Mario,Lucic,google,Google Brain,lucic@google.com,Deep Generative Models for Distribution-Preserving Lossy Compression
neurips,2018,0,6847,Saumya,Jetley,ox,University of Oxford,sjetley@robots.ox.ac.uk,"With Friends Like These, Who Needs Adversaries?"
neurips,2018,1,6847,Nicholas,Lord,ox,University of Oxford/FiveAI,nicklord@robots.ox.ac.uk,"With Friends Like These, Who Needs Adversaries?"
neurips,2018,2,6847,Philip,Torr,ox,University of Oxford,phst@robots.ox.ac.uk,"With Friends Like These, Who Needs Adversaries?"
neurips,2018,0,3182,Lijun,Wu,sysu,Sun Yat-sen University,1wulijun3@mail2.sysu.edu.cn,Learning to Teach with Dynamic Loss Functions
neurips,2018,1,3182,Fei,Tian,sysu,Miicrosoft Research,stsljh@mail.sysu.edu.cn,Learning to Teach with Dynamic Loss Functions
neurips,2018,2,3182,Yingce,Xia,microsoft,Microsoft Research Asia,2fetia@microsoft.com,Learning to Teach with Dynamic Loss Functions
neurips,2018,3,3182,Yang,Fan,microsoft,University of Science and Technology of China,yingce.xia@microsoft.com,Learning to Teach with Dynamic Loss Functions
neurips,2018,4,3182,Tao,Qin,microsoft,Microsoft Research,taoqin@microsoft.com,Learning to Teach with Dynamic Loss Functions
neurips,2018,5,3182,Lai,Jian-Huang,microsoft,Sun Yat-sen University,tie-yan.liu@microsoft.com,Learning to Teach with Dynamic Loss Functions
neurips,2018,6,3182,Tie-Yan,Liu,ustc,Microsoft Research Asia,3fyabc@mail.ustc.edu.cn,Learning to Teach with Dynamic Loss Functions
neurips,2018,0,2284,Shahin,Shahrampour,tamu,Texas A&M University,shahin@tamu.edu,Learning Bounds for Greedy Approximation with Explicit Feature Maps from Multiple Kernels
neurips,2018,1,2284,Vahid,Tarokh,duke,Duke University,vahid.tarokh@duke.edu,Learning Bounds for Greedy Approximation with Explicit Feature Maps from Multiple Kernels
neurips,2018,0,5337,Rasul,Tutunov,prowler,PROWLER.io,rasul@prowler.io,Distributed Multitask Reinforcement Learning with Quadratic Convergence
neurips,2018,1,5337,Dongho,Kim,prowler,PROWLER.io,dongho@prowler.io,Distributed Multitask Reinforcement Learning with Quadratic Convergence
neurips,2018,2,5337,Haitham,Bou Ammar,prowler,PROWLER.io,haitham@prowler.io,Distributed Multitask Reinforcement Learning with Quadratic Convergence
neurips,2018,0,5728,Zi,Yin,stanford,Stanford University,vsachi@stanford.edu,The Global Anchor Method for Quantifying Linguistic Shifts and Domain Adaptation
neurips,2018,1,5728,Vin,Sachidananda,gmail,Stanford University,s09600974@gmail.com,The Global Anchor Method for Quantifying Linguistic Shifts and Domain Adaptation
neurips,2018,2,5728,Balaji,Prabhakar,stanford,Stanford Univeristy,balaji@stanford.edu,The Global Anchor Method for Quantifying Linguistic Shifts and Domain Adaptation
neurips,2018,0,95,Yixi,Xu,purdue,Purdue University,xu573@purdue.edu,Understanding Weight Normalized Deep Neural Networks with Rectified Linear Units
neurips,2018,1,95,Xiao,Wang,purdue,Purdue University,wangxiao@purdue.edu,Understanding Weight Normalized Deep Neural Networks with Rectified Linear Units
neurips,2018,0,543,Hang,Gao,columbia,Columbia University,hg2469@columbia.edu,Low-shot Learning via Covariance-Preserving Adversarial Augmentation Networks
neurips,2018,1,543,Zheng,Shou,columbia,Columbia University,zs2262@columbia.edu,Low-shot Learning via Covariance-Preserving Adversarial Augmentation Networks
neurips,2018,2,543,Alireza,Zareian,columbia,Columbia University,az2407@columbia.edu,Low-shot Learning via Covariance-Preserving Adversarial Augmentation Networks
neurips,2018,3,543,Hanwang,Zhang,columbia,NTU,sc250@columbia.edu,Low-shot Learning via Covariance-Preserving Adversarial Augmentation Networks
neurips,2018,4,543,Shih-Fu,Chang,ntu,Columbia University,hanwangzhang@ntu.edu.sg,Low-shot Learning via Covariance-Preserving Adversarial Augmentation Networks
neurips,2018,0,2068,Jie,Xu,pitt,Xidian University,jie.xu@pitt.edu,Bilevel Distance Metric Learning for Robust Image Recognition
neurips,2018,1,2068,Lei,Luo,pitt,University of Pittsburgh,leiluo2017@pitt.edu,Bilevel Distance Metric Learning for Robust Image Recognition
neurips,2018,2,2068,Cheng,Deng,gmail,Xidian University,chdeng.xd@gmail.com,Bilevel Distance Metric Learning for Robust Image Recognition
neurips,2018,3,2068,Heng,Huang,pitt,University of Pittsburgh,heng.huang@pitt.edu,Bilevel Distance Metric Learning for Robust Image Recognition
neurips,2018,0,2077,Amir,Dezfouli,gmail,"Data61, CSIRO",akdezfuli@gmail.com,Integrated accounts of behavioral and neuroimaging data using flexible recurrent neural network models
neurips,2018,1,2077,Richard,Morris,gmail,U Sydney,richardumorris@gmail.com,Integrated accounts of behavioral and neuroimaging data using flexible recurrent neural network models
neurips,2018,2,2077,Fabio,Ramos,ucl,University of Sydney,p.dayan@ucl.ac.uk,Integrated accounts of behavioral and neuroimaging data using flexible recurrent neural network models
neurips,2018,3,2077,Peter,Dayan,sydney,"Gatsby Unit, UCL",fabio.ramos@sydney.edu.au,Integrated accounts of behavioral and neuroimaging data using flexible recurrent neural network models
neurips,2018,4,2077,Bernard,Balleine,unsw,UNSW,bernard.balleine@unsw.edu.au,Integrated accounts of behavioral and neuroimaging data using flexible recurrent neural network models
neurips,2018,0,2404,Yao,Li,ucdavis,"University of California, Davis",yaoli@ucdavis.edu,Learning from Group Comparisons: Exploiting Higher Order Interactions
neurips,2018,1,2404,Minhao,Cheng,ucla,"University of California, Davis",mhcheng@ucla.edu,Learning from Group Comparisons: Exploiting Higher Order Interactions
neurips,2018,2,2404,Kevin,Fujii,ucdavis,UC Davis Department of Statistics,kmfujii@ucdavis.edu,Learning from Group Comparisons: Exploiting Higher Order Interactions
neurips,2018,3,2404,Fushing,Hsieh,ucdavis,UC Davis Department of Statistics,fhsieh@ucdavis.edu,Learning from Group Comparisons: Exploiting Higher Order Interactions
neurips,2018,4,2404,Cho-Jui,Hsieh,ucla,"UCLA, Google Research",chohsieh@cs.ucla.edu,Learning from Group Comparisons: Exploiting Higher Order Interactions
neurips,2018,0,175,Siyuan,Huang,ucla,"University of California, Los Angeles",huangsiyuan@ucla.edu,"Cooperative Holistic Scene Understanding: Unifying 3D Object, Layout, and Camera Pose Estimation"
neurips,2018,1,175,Siyuan,Qi,ucla,UCLA,syqi@cs.ucla.edu,"Cooperative Holistic Scene Understanding: Unifying 3D Object, Layout, and Camera Pose Estimation"
neurips,2018,2,175,Yinxue,Xiao,ucla,"University of California, Los Angeles",yinxuex@ucla.edu,"Cooperative Holistic Scene Understanding: Unifying 3D Object, Layout, and Camera Pose Estimation"
neurips,2018,3,175,Yixin,Zhu,ucla,"University of California, Los Angeles",yixin.zhu@ucla.edu,"Cooperative Holistic Scene Understanding: Unifying 3D Object, Layout, and Camera Pose Estimation"
neurips,2018,4,175,Ying Nian,Wu,ucla,"University of California, Los Angeles",ywu@stat.ucla.edu,"Cooperative Holistic Scene Understanding: Unifying 3D Object, Layout, and Camera Pose Estimation"
neurips,2018,5,175,Song-Chun,Zhu,ucla,UCLA,sczhu@stat.ucla.edu,"Cooperative Holistic Scene Understanding: Unifying 3D Object, Layout, and Camera Pose Estimation"
neurips,2018,0,1847,Kevin,Jamieson,washington,U Washington,jamieson@cs.washington.edu,A Bandit Approach to Sequential Experimental Design with False Discovery Control
neurips,2018,1,1847,Lalit,Jain,washington,University of Washington,lalitj@cs.washington.edu,A Bandit Approach to Sequential Experimental Design with False Discovery Control
neurips,2018,0,355,Peiqi,Wang,tsinghua,Tsinghua University,wpq14@mails.tsinghua.edu.cn,HitNet: Hybrid Ternary Recurrent Neural Network
neurips,2018,1,355,Xinfeng,Xie,tsinghua,UCSB,liguoqi@mail.tsinghua.edu.cn,HitNet: Hybrid Ternary Recurrent Neural Network
neurips,2018,2,355,Lei,Deng,tsinghua,"University of California, Santa Barbara",wds@mail.tsinghua.edu.cn,HitNet: Hybrid Ternary Recurrent Neural Network
neurips,2018,3,355,Guoqi,Li,ucsb,Tsinghua University,xinfeng@ucsb.edu,HitNet: Hybrid Ternary Recurrent Neural Network
neurips,2018,4,355,Dongsheng,Wang,ucsb,Tsinghua University,leideng@ucsb.edu,HitNet: Hybrid Ternary Recurrent Neural Network
neurips,2018,5,355,Yuan,Xie,ucsb,"University of California, Santa Barbara",yuanxie@ucsb.edu,HitNet: Hybrid Ternary Recurrent Neural Network
neurips,2018,0,725,Sumit,Shrestha,nus,Temasek Laboratories @ National University of Singapore,tslsbs@nus.edu.sg,SLAYER: Spike Layer Error Reassignment in Time
neurips,2018,1,725,Garrick,Orchard,nus,National University of Singapore,tslgmo@nus.edu.sg,SLAYER: Spike Layer Error Reassignment in Time
neurips,2018,0,2512,Farzan,Farnia,stanford,Stanford University,farnia@stanford.edu,A Convex Duality Framework for GANs
neurips,2018,1,2512,David,Tse,stanford,Stanford University,dntse@stanford.edu,A Convex Duality Framework for GANs
neurips,2018,0,1478,Michele,Donini,,Istituto Italiano di Tecnologia,,Empirical Risk Minimization Under Fairness Constraints
neurips,2018,1,1478,Luca,Oneto,,University of Genoa,,Empirical Risk Minimization Under Fairness Constraints
neurips,2018,2,1478,Shai,Ben-David,,Universitys of Waterloo,,Empirical Risk Minimization Under Fairness Constraints
neurips,2018,3,1478,John,Shawe-Taylor,,UCL,,Empirical Risk Minimization Under Fairness Constraints
neurips,2018,4,1478,Massimiliano,Pontil,,IIT,,Empirical Risk Minimization Under Fairness Constraints
neurips,2018,0,3572,Filipe,de Avila Belbute-Peres,cmu,Carnegie Mellon University,filiped@cs.cmu.edu,End-to-End Differentiable Physics for Learning and Control
neurips,2018,1,3572,Kevin,Smith,mit,MIT,k2smith@mit.edu,End-to-End Differentiable Physics for Learning and Control
neurips,2018,2,3572,Kelsey,Allen,mit,MIT,krallen@mit.edu,End-to-End Differentiable Physics for Learning and Control
neurips,2018,3,3572,Josh,Tenenbaum,mit,MIT,jbt@mit.edu,End-to-End Differentiable Physics for Learning and Control
neurips,2018,4,3572,J. Zico,Kolter,cmu,Carnegie Mellon University / Bosch Center for AI,zkolter@cs.cmu.edu,End-to-End Differentiable Physics for Learning and Control
neurips,2018,0,1294,Alexander,Liu,ntu,National Taiwan University,b03902034@ntu.edu.tw,A Unified Feature Disentangler for Multi-Domain Image Translation and Manipulation
neurips,2018,1,1294,Yen-Cheng,Liu,gatech,Georgia Tech,ycliu@gatech.edu,A Unified Feature Disentangler for Multi-Domain Image Translation and Manipulation
neurips,2018,2,1294,Yu-Ying,Yeh,ucsd,"University of California, San Diego",yuyeh@eng.ucsd.edu,A Unified Feature Disentangler for Multi-Domain Image Translation and Manipulation
neurips,2018,3,1294,Yu-Chiang Frank,Wang,ntu,National Taiwan University,ycwang@ntu.edu.tw,A Unified Feature Disentangler for Multi-Domain Image Translation and Manipulation
neurips,2018,0,2513,Alan,Malek,mit,MIT,amalek@mit.edu,Horizon-Independent Minimax Linear Regression
neurips,2018,1,2513,Peter,Bartlett,berkeley,UC Berkeley,bartlett@cs.berkeley.edu,Horizon-Independent Minimax Linear Regression
neurips,2018,0,6901,Raghav,Somani,microsoft,Microsoft Research Lab - India,t-rasom@microsoft.com,Support Recovery for Orthogonal Matching Pursuit: Upper and Lower bounds
neurips,2018,1,6901,Chirag,Gupta,cmu,Carnegie Mellon University,chiragg@andrew.cmu.edu,Support Recovery for Orthogonal Matching Pursuit: Upper and Lower bounds
neurips,2018,2,6901,Prateek,Jain,microsoft,Microsoft Research,prajain@microsoft.com,Support Recovery for Orthogonal Matching Pursuit: Upper and Lower bounds
neurips,2018,3,6901,Praneeth,Netrapalli,microsoft,Microsoft Research,praneeth@microsoft.com,Support Recovery for Orthogonal Matching Pursuit: Upper and Lower bounds
neurips,2018,0,2018,Chaitanya,Ryali,ucsd,UC San Diego,rckrishn@eng.ucsd.edu,Beauty-in-averageness and its contextual modulations: A Bayesian statistical account
neurips,2018,1,2018,Angela,Yu,ucsd,UC San Diego,ajyu@ucsd.edu,Beauty-in-averageness and its contextual modulations: A Bayesian statistical account
neurips,2018,0,1640,Benjamin,Aubin,,Ipht Saclay,,The committee machine: Computational to statistical gaps in learning a two-layers neural network
neurips,2018,1,1640,Antoine,Maillard,,Ecole Normale Supérieure,,The committee machine: Computational to statistical gaps in learning a two-layers neural network
neurips,2018,2,1640,jean,barbier,,EPFL,,The committee machine: Computational to statistical gaps in learning a two-layers neural network
neurips,2018,3,1640,Florent,Krzakala,,École Normale Supérieure,,The committee machine: Computational to statistical gaps in learning a two-layers neural network
neurips,2018,4,1640,Nicolas,Macris,,EPFL,,The committee machine: Computational to statistical gaps in learning a two-layers neural network
neurips,2018,5,1640,Lenka,Zdeborová,,CEA Saclay,,The committee machine: Computational to statistical gaps in learning a two-layers neural network
neurips,2018,0,614,Alhussein,Fawzi,google,DeepMind,afawzi@google.com,Adversarial vulnerability for any classifier
neurips,2018,1,614,Hamza,Fawzi,cam,University of Cambridge,h.fawzi@damtp.cam.ac.uk,Adversarial vulnerability for any classifier
neurips,2018,2,614,Omar,Fawzi,ens-lyon,ENS Lyon,omar.fawzi@ens-lyon.fr,Adversarial vulnerability for any classifier
neurips,2018,0,526,YAN,ZHENG,tju,Tianjin University,yanzheng@tju.edu.cn,A Deep Bayesian Policy Reuse Approach Against Non-Stationary Agents
neurips,2018,1,526,Zhaopeng,Meng,tju,"School of Computer Software, Tianjin University",mengzp@tju.edu.cn,A Deep Bayesian Policy Reuse Approach Against Non-Stationary Agents
neurips,2018,2,526,Jianye,Hao,tju,Tianjin University,jianye.hao@tju.edu.cn,A Deep Bayesian Policy Reuse Approach Against Non-Stationary Agents
neurips,2018,3,526,Zongzhang,Zhang,suda,Soochow University,zzzhang@suda.edu.cn,A Deep Bayesian Policy Reuse Approach Against Non-Stationary Agents
neurips,2018,4,526,Tianpei,Yang,tju,Tianjin University,tpyang@tju.edu.cn,A Deep Bayesian Policy Reuse Approach Against Non-Stationary Agents
neurips,2018,5,526,Changjie,Fan,netease,Netease,fanchangjie@netease.com,A Deep Bayesian Policy Reuse Approach Against Non-Stationary Agents
neurips,2018,0,1934,Gamaleldin,Elsayed,,Google Brain,,Adversarial Examples that Fool both Computer Vision and Time-Limited Humans
neurips,2018,1,1934,Shreya,Shankar,,Stanford University,,Adversarial Examples that Fool both Computer Vision and Time-Limited Humans
neurips,2018,2,1934,Brian,Cheung,,UC Berkeley,,Adversarial Examples that Fool both Computer Vision and Time-Limited Humans
neurips,2018,3,1934,Nicolas,Papernot,,Google Brain,,Adversarial Examples that Fool both Computer Vision and Time-Limited Humans
neurips,2018,4,1934,Alexey,Kurakin,,Google Brain,,Adversarial Examples that Fool both Computer Vision and Time-Limited Humans
neurips,2018,5,1934,Ian,Goodfellow,,Google,,Adversarial Examples that Fool both Computer Vision and Time-Limited Humans
neurips,2018,6,1934,Jascha,Sohl-Dickstein,,Google Brain,,Adversarial Examples that Fool both Computer Vision and Time-Limited Humans
neurips,2018,0,1119,Yue,Zhao,cuhk,The Chinese University of Hong Kong,zy317@ie.cuhk.edu.hk,Trajectory Convolution for Action Recognition
neurips,2018,1,1119,Yuanjun,Xiong,amazon,Amazon,yuanjx@amazon.com,Trajectory Convolution for Action Recognition
neurips,2018,2,1119,Dahua,Lin,cuhk,The Chinese University of Hong Kong,dhlin@ie.cuhk.edu.hk,Trajectory Convolution for Action Recognition
neurips,2018,0,1837,Kwang-Sung,Jun,gmail,UW-Madison,kwangsung.jun@gmail.com,Adversarial Attacks on Stochastic Bandits
neurips,2018,1,1837,Lihong,Li,wisc,Google Inc.,ma234@wisc.edu,Adversarial Attacks on Stochastic Bandits
neurips,2018,2,1837,Yuzhe,Ma,google,University of Wisconsin-Madison,lihong@google.com,Adversarial Attacks on Stochastic Bandits
neurips,2018,3,1837,Jerry,Zhu,wisc,University of Wisconsin-Madison,jerryzhu@cs.wisc.edu,Adversarial Attacks on Stochastic Bandits
neurips,2018,0,621,Shauharda,Khadka,oregonstate,Oregon State University,khadkas@oregonstate.edu,Evolution-Guided Policy Gradient in Reinforcement Learning
neurips,2018,1,621,Kagan,Tumer,oregonstate,Oregon State University US,kagan.tumer@oregonstate.edu,Evolution-Guided Policy Gradient in Reinforcement Learning
neurips,2018,0,3389,Raman,Arora,jhu,Johns Hopkins University,arora@cs.jhu.edu,Policy Regret in Repeated Games
neurips,2018,1,3389,Michael,Dinitz,jhu,JHU,mdinitz@cs.jhu.edu,Policy Regret in Repeated Games
neurips,2018,2,3389,Teodor Vanislavov,Marinov,jhu,Johns Hopkins University,tmarino2@jhu.edu,Policy Regret in Repeated Games
neurips,2018,3,3389,Mehryar,Mohri,nyu,Courant Inst. of Math. Sciences & Google Research,mohri@cims.nyu.edu,Policy Regret in Repeated Games
neurips,2018,0,3449,Nathan,Kallus,cornell,Cornell University,kallus@cornell.edu,Causal Inference with Noisy and Missing Covariates via Matrix Factorization
neurips,2018,1,3449,Xiaojie,Mao,cornell,Cornell University,xm77@cornell.edu,Causal Inference with Noisy and Missing Covariates via Matrix Factorization
neurips,2018,2,3449,Madeleine,Udell,cornell,Cornell University,udell@cornell.edu,Causal Inference with Noisy and Missing Covariates via Matrix Factorization
neurips,2018,0,3138,Michael,Teng,ox,University of Oxford (visiting at University of British Columbia),mteng@robots.ox.ac.uk,Bayesian Distributed Stochastic Gradient Descent
neurips,2018,1,3138,Frank,Wood,ubc,University of British Columbia,fwood@cs.ubc.ca,Bayesian Distributed Stochastic Gradient Descent
neurips,2018,0,6785,Ji,Xu,columbia,Columbia University,jixu@cs.columbia.edu,Benefits of over-parameterization with EM
neurips,2018,1,6785,Daniel,Hsu,columbia,Columbia University,djhsu@cs.columbia.edu,Benefits of over-parameterization with EM
neurips,2018,2,6785,Arian,Maleki,columbia,Columbia University,arian@stat.columbia.edu,Benefits of over-parameterization with EM
neurips,2018,0,3692,Marina,Meila,,University of Washington,,How to tell when a clustering is (approximately) correct using convex relaxations
neurips,2018,0,1588,Stefan,Webb,,University of Oxford,,Faithful Inversion of Generative Models for Effective Amortized Inference
neurips,2018,1,1588,Adam,Golinski,,University of Oxford,,Faithful Inversion of Generative Models for Effective Amortized Inference
neurips,2018,2,1588,Rob,Zinkov,,University of Oxford,,Faithful Inversion of Generative Models for Effective Amortized Inference
neurips,2018,3,1588,Siddharth,N,,Unversity of Oxford,,Faithful Inversion of Generative Models for Effective Amortized Inference
neurips,2018,4,1588,Tom,Rainforth,,University of Oxford,,Faithful Inversion of Generative Models for Effective Amortized Inference
neurips,2018,5,1588,Yee Whye,Teh,,"University of Oxford, DeepMind",,Faithful Inversion of Generative Models for Effective Amortized Inference
neurips,2018,6,1588,Frank,Wood,,University of British Columbia,,Faithful Inversion of Generative Models for Effective Amortized Inference
neurips,2018,0,2041,Yu,Ji,tsinghua,Tsinghua University,jiy15@mails.tsinghua.edu.cn,TETRIS: TilE-matching the TRemendous Irregular Sparsity
neurips,2018,1,2041,Ling,Liang,tsinghua,UCSB,zhang-yy15@mails.tsinghua.edu.cn,TETRIS: TilE-matching the TRemendous Irregular Sparsity
neurips,2018,2,2041,Lei,Deng,tsinghua,UCSB,zyh02@tsinghua.edu.cn,TETRIS: TilE-matching the TRemendous Irregular Sparsity
neurips,2018,3,2041,Youyang,Zhang,ucsb,Tsinghua University,lingliang@ece.ucsb.edu,TETRIS: TilE-matching the TRemendous Irregular Sparsity
neurips,2018,4,2041,Youhui,Zhang,ucsb,Tsinghua University,leideng@ece.ucsb.edu,TETRIS: TilE-matching the TRemendous Irregular Sparsity
neurips,2018,5,2041,Yuan,Xie,ucsb,UCSB,yuanxie@ece.ucsb.edu,TETRIS: TilE-matching the TRemendous Irregular Sparsity
neurips,2018,0,3682,Insu,Han,kaist,KAIST,insu.han@kaist.ac.kr,Stochastic Chebyshev Gradient Descent for Spectral Optimization
neurips,2018,1,3682,Haim,Avron,kaist,Tel Aviv University,jinwoos@kaist.ac.kr,Stochastic Chebyshev Gradient Descent for Spectral Optimization
neurips,2018,2,3682,Jinwoo,Shin,tau,KAIST; AITRICS,haimav@post.tau.ac.il,Stochastic Chebyshev Gradient Descent for Spectral Optimization
neurips,2018,0,3364,Mikio,Aoi,princeton,Princeton University,maoi@princeton.edu,Model-based targeted dimensionality reduction for neuronal population data
neurips,2018,1,3364,Jonathan,Pillow,princeton,Princeton University,pillow@princeton.edu,Model-based targeted dimensionality reduction for neuronal population data
neurips,2018,0,1146,Chang,Xiao,columbia,Columbia University,chang@cs.columbia.edu,BourGAN: Generative Networks with Metric Embeddings
neurips,2018,1,1146,Peilin,Zhong,columbia,Columbia University,peilin@cs.columbia.edu,BourGAN: Generative Networks with Metric Embeddings
neurips,2018,2,1146,Changxi,Zheng,columbia,Columbia University,cxz@cs.columbia.edu,BourGAN: Generative Networks with Metric Embeddings
neurips,2018,0,6444,Aaron,Havens,iastate,University of Illinois Urbana-Champaign,ajhavens@iastate.edu,Online Robust Policy Learning in the Presence of Unknown Adversaries
neurips,2018,1,6444,Zhanhong,Jiang,iastate,Iowa State University,zhjiang@iastate.edu,Online Robust Policy Learning in the Presence of Unknown Adversaries
neurips,2018,2,6444,Soumik,Sarkar,iastate,Iowa State University,soumiks@iastate.edu,Online Robust Policy Learning in the Presence of Unknown Adversaries
neurips,2018,0,5669,Chih-Kuan,Yeh,cmu,Carnegie Mellon University,cjyeh@cs.cmu.edu,Representer Point Selection for Explaining Deep Neural Networks
neurips,2018,1,5669,Joon,Kim,cmu,Carnegie Mellon University,joonsikk@cs.cmu.edu,Representer Point Selection for Explaining Deep Neural Networks
neurips,2018,2,5669,Ian En-Hsu,Yen,cmu,Carnegie Mellon University,eyan@cs.cmu.edu,Representer Point Selection for Explaining Deep Neural Networks
neurips,2018,3,5669,Pradeep,Ravikumar,cmu,Carnegie Mellon University,pradeepr@cs.cmu.edu,Representer Point Selection for Explaining Deep Neural Networks
neurips,2018,0,5521,Sami,Abu-El-Haija,isi,Information Sciences Institute @ USC,haija@isi.edu,Watch Your Step: Learning Node Embeddings via Graph Attention
neurips,2018,1,5521,Bryan,Perozzi,acm,Google AI,bperozzi@acm.org,Watch Your Step: Learning Node Embeddings via Graph Attention
neurips,2018,2,5521,Rami,Al-Rfou,google,Google Research,rmyeid@google.com,Watch Your Step: Learning Node Embeddings via Graph Attention
neurips,2018,3,5521,Alexander,Alemi,google,Google,alemi@google.com,Watch Your Step: Learning Node Embeddings via Graph Attention
neurips,2018,0,569,Lijun,Zhang,nju,Nanjing University (NJU),zhanglj@lamda.nju.edu.cn,$\ell_1$-regression with Heavy-tailed Distributions
neurips,2018,1,569,Zhi-Hua,Zhou,nju,Nanjing University,zhouzh@lamda.nju.edu.cn,$\ell_1$-regression with Heavy-tailed Distributions
neurips,2018,0,2387,Wenbo,Wang,binghamton,Binghamton University,wang2@math.binghamton.edu,Learning Confidence Sets using Support Vector Machines
neurips,2018,1,2387,Xingye,Qiao,binghamton,Binghamton University,qiao@math.binghamton.edu,Learning Confidence Sets using Support Vector Machines
neurips,2018,0,1717,Tianqi,Chen,,University of Washington,,Learning to Optimize Tensor Programs
neurips,2018,1,1717,Lianmin,Zheng,,Shanghai Jiaotong University,,Learning to Optimize Tensor Programs
neurips,2018,2,1717,Eddie,Yan,,university of washington,,Learning to Optimize Tensor Programs
neurips,2018,3,1717,Ziheng,Jiang,,Fudan University,,Learning to Optimize Tensor Programs
neurips,2018,4,1717,Thierry,Moreau,,university of washington,,Learning to Optimize Tensor Programs
neurips,2018,5,1717,Luis,Ceze,,University of Washington,,Learning to Optimize Tensor Programs
neurips,2018,6,1717,Carlos,Guestrin,,University of Washington,,Learning to Optimize Tensor Programs
neurips,2018,7,1717,Arvind,Krishnamurthy,,University of Washington,,Learning to Optimize Tensor Programs
neurips,2018,0,1781,JING,LI,gmail,"University of Nantes, LS2N lab",jingli.univ@gmail.com,Hybrid-MST: A Hybrid Active Sampling Strategy for Pairwise Preference Aggregation
neurips,2018,1,1781,Rafal,Mantiuk,cam,University of Cambridge,rkm38@cam.ac.uk,Hybrid-MST: A Hybrid Active Sampling Strategy for Pairwise Preference Aggregation
neurips,2018,2,1781,Junle,Wang,gmail,Tencent,wangjunle@gmail.com,Hybrid-MST: A Hybrid Active Sampling Strategy for Pairwise Preference Aggregation
neurips,2018,3,1781,Suiyi,Ling,univ-nantes,université de nantes,suiyi.ling@univ-nantes.fr,Hybrid-MST: A Hybrid Active Sampling Strategy for Pairwise Preference Aggregation
neurips,2018,4,1781,Patrick,Le Callet,univ-nantes,"""Universite de Nantes, France""",patrick.lecallet@univ-nantes.fr,Hybrid-MST: A Hybrid Active Sampling Strategy for Pairwise Preference Aggregation
neurips,2018,0,3135,Marek,Wydmuch,poznan,Poznan University of Technology,mwydmuch@cs.put.poznan.pl,A no-regret generalization of hierarchical softmax to extreme multi-label classification
neurips,2018,1,3135,Kalina,Jasinska,poznan,Allegro.pl,kjasinska@cs.put.poznan.pl,A no-regret generalization of hierarchical softmax to extreme multi-label classification
neurips,2018,2,3135,Mikhail,Kuznetsov,oath,Yahoo! Research,kuznetsov@oath.com,A no-regret generalization of hierarchical softmax to extreme multi-label classification
neurips,2018,3,3135,Róbert,Busa-Fekete,oath,Yahoo! Research,busafekete@oath.com,A no-regret generalization of hierarchical softmax to extreme multi-label classification
neurips,2018,4,3135,Krzysztof,Dembczynski,poznan,Poznan University of Technology,kdembczynski@cs.put.poznan.pl,A no-regret generalization of hierarchical softmax to extreme multi-label classification
neurips,2018,0,5689,Chen,Dan,cmu,Carnegie Mellon University,cdan@cs.cmu.edu,The Sample Complexity of Semi-Supervised Learning with Nonparametric Mixture Models
neurips,2018,1,5689,Liu,Leqi,cmu,Carnegie Mellon University,leqil@cs.cmu.edu,The Sample Complexity of Semi-Supervised Learning with Nonparametric Mixture Models
neurips,2018,2,5689,Bryon,Aragam,cmu,Carnegie Mellon University,naragam@cs.cmu.edu,The Sample Complexity of Semi-Supervised Learning with Nonparametric Mixture Models
neurips,2018,3,5689,Pradeep,Ravikumar,cmu,Carnegie Mellon University,pradeepr@cs.cmu.edu,The Sample Complexity of Semi-Supervised Learning with Nonparametric Mixture Models
neurips,2018,4,5689,Eric,Xing,cmu,Petuum Inc. /  Carnegie Mellon University,epxing@cs.cmu.edu,The Sample Complexity of Semi-Supervised Learning with Nonparametric Mixture Models
neurips,2018,0,2620,Weihao,Kong,stanford,Stanford University,whkong@stanford.edu,Estimating Learnability in the Sublinear Data Regime
neurips,2018,1,2620,Gregory,Valiant,stanford,Stanford University,gvaliant@cs.stanford.edu,Estimating Learnability in the Sublinear Data Regime
neurips,2018,0,2459,Siwei,Wang,tsinghua,"IIIS, Tsinghua University",wangsw15@mails.tsinghua.edu.cn,Multi-armed Bandits with Compensation
neurips,2018,1,2459,Longbo,Huang,tsinghua,"IIIS, Tsinghua Univeristy",longbohuang@tsinghua.edu.cn,Multi-armed Bandits with Compensation
neurips,2018,0,378,Bo,Dai,cuhk,The Chinese University of Hong Kong,bdai@ie.cuhk.edu.hk,A Neural Compositional Paradigm for Image Captioning
neurips,2018,1,378,Sanja,Fidler,toronto,University of Toronto,fidler@cs.toronto.edu,A Neural Compositional Paradigm for Image Captioning
neurips,2018,2,378,Dahua,Lin,cuhk,The Chinese University of Hong Kong,dhlin@ie.cuhk.edu.hk,A Neural Compositional Paradigm for Image Captioning
neurips,2018,0,776,Yunwen,Lei,sustc,Southern University of Science and Technology,leiyw@sustc.edu.cn,Stochastic Composite Mirror Descent: Optimal Bounds with High Probabilities
neurips,2018,1,776,Ke,Tang,sustc,Southern University of Science and Technology,tangk3@sustc.edu.cn,Stochastic Composite Mirror Descent: Optimal Bounds with High Probabilities
neurips,2018,0,2453,Ricson,Cheng,cmu,Carnegie Mellon University,ricsonc@andrew.cmu.edu,Geometry-Aware Recurrent Neural Networks for Active Visual Recognition
neurips,2018,1,2453,Ziyan,Wang,cmu,Carnegie Mellon University,ziyanw1@andrew.cmu.edu,Geometry-Aware Recurrent Neural Networks for Active Visual Recognition
neurips,2018,2,2453,Katerina,Fragkiadaki,cmu,Carnegie Mellon University,katef@cs.cmu.edu,Geometry-Aware Recurrent Neural Networks for Active Visual Recognition
neurips,2018,0,4951,Borja,Ibarz,google,DeepMind,bibarz@google.com,Reward learning from human preferences and demonstrations in Atari
neurips,2018,1,4951,Jan,Leike,google,DeepMind,leike@google.com,Reward learning from human preferences and demonstrations in Atari
neurips,2018,2,4951,Tobias,Pohlen,google,DeepMind,pohlen@google.com,Reward learning from human preferences and demonstrations in Atari
neurips,2018,3,4951,Geoffrey,Irving,openai,OpenAI,irving@openai.com,Reward learning from human preferences and demonstrations in Atari
neurips,2018,4,4951,Shane,Legg,openai,DeepMind,damodei@openai.com,Reward learning from human preferences and demonstrations in Atari
neurips,2018,5,4951,Dario,Amodei,google,OpenAI,legg@google.com,Reward learning from human preferences and demonstrations in Atari
neurips,2018,0,3779,Xuhui,Fan,unsw,University of New South Wales,xuhui.fan@unsw.edu.au,Rectangular Bounding Process
neurips,2018,1,3779,Bin,Li,fudan,Fudan University,libin@fudan.edu.cn,Rectangular Bounding Process
neurips,2018,2,3779,Scott,SIsson,unsw,,scott.sisson@unsw.edu.au,Rectangular Bounding Process
neurips,2018,0,5046,Yang,Song,stanford,Stanford University,yangsong@cs.stanford.edu,Constructing Unrestricted Adversarial Examples with Generative Models
neurips,2018,1,5046,Rui,Shu,stanford,Stanford University,ruishu@cs.stanford.edu,Constructing Unrestricted Adversarial Examples with Generative Models
neurips,2018,2,5046,Nate,Kushman,microsoft,Microsoft Research Cambridge,nkushman@microsoft.com,Constructing Unrestricted Adversarial Examples with Generative Models
neurips,2018,3,5046,Stefano,Ermon,stanford,Stanford,ermon@cs.stanford.edu,Constructing Unrestricted Adversarial Examples with Generative Models
neurips,2018,0,1359,Ruichu,Cai,gdut,Guangdong University of Technology,cairuichu@gdut.edu.cn,Causal Discovery from Discrete Data using Hidden Compact Representation
neurips,2018,1,1359,Jie,Qiao,gmail,Guangdong University of Technology,qiaojie.chn@gmail.com,Causal Discovery from Discrete Data using Hidden Compact Representation
neurips,2018,2,1359,Kun,Zhang,cmu,CMU,kunz1@andrew.cmu.edu,Causal Discovery from Discrete Data using Hidden Compact Representation
neurips,2018,3,1359,Zhenjie,Zhang,yitu-inc,"Singapore R&D, Yitu Technology Ltd.,",zhenjie.zhang@yitu-inc.com,Causal Discovery from Discrete Data using Hidden Compact Representation
neurips,2018,4,1359,Zhifeng,Hao,gdut,Guangdong University of Technology,zfhao@gdut.edu.cn,Causal Discovery from Discrete Data using Hidden Compact Representation
neurips,2018,0,548,Lifang,He,gmail,Cornell University,lifanghescut@gmail.com,Boosted Sparse and Low-Rank Tensor Regression
neurips,2018,1,548,Kun,Chen,uconn,University of Connecticut,kun.chen@uconn.edu,Boosted Sparse and Low-Rank Tensor Regression
neurips,2018,2,548,Wanwan,Xu,uconn,University of Connecticut,wanwan.xu@uconn.edu,Boosted Sparse and Low-Rank Tensor Regression
neurips,2018,3,548,Jiayu,Zhou,gmail,Michigan State University,dearjiayu@gmail.com,Boosted Sparse and Low-Rank Tensor Regression
neurips,2018,4,548,Fei,Wang,cornell,Cornell University,few2001@med.cornell.edu,Boosted Sparse and Low-Rank Tensor Regression
neurips,2018,0,319,Zhuwen,Li,,Intel Labs,,Combinatorial Optimization with Graph Convolutional Networks and Guided Tree Search
neurips,2018,1,319,Qifeng,Chen,,HKUST,,Combinatorial Optimization with Graph Convolutional Networks and Guided Tree Search
neurips,2018,2,319,Vladlen,Koltun,,Intel Labs,,Combinatorial Optimization with Graph Convolutional Networks and Guided Tree Search
neurips,2018,0,3600,Amir,Asadi,,Princeton University,,Chaining Mutual Information and Tightening Generalization Bounds
neurips,2018,1,3600,Emmanuel,Abbe,,Princeton University,,Chaining Mutual Information and Tightening Generalization Bounds
neurips,2018,2,3600,Sergio,Verdu,,Princeton University,,Chaining Mutual Information and Tightening Generalization Bounds
neurips,2018,0,3361,Menghan,Wang,zju,Zhejiang University,wangmengh@zju.edu.cn,Modeling Dynamic Missingness of Implicit Feedback for Recommendation
neurips,2018,1,3361,Mingming,Gong,zju,University of Pittsburgh,xlzheng@zju.edu.cn,Modeling Dynamic Missingness of Implicit Feedback for Recommendation
neurips,2018,2,3361,Xiaolin,Zheng,pitt,Zhejiang University,mig73@pitt.edu,Modeling Dynamic Missingness of Implicit Feedback for Recommendation
neurips,2018,3,3361,Kun,Zhang,cmu,CMU,kunz1@cmu.edu,Modeling Dynamic Missingness of Implicit Feedback for Recommendation
neurips,2018,0,4982,Zachary,Lipton,cmu,Carnegie Mellon University,zlipton@cmu.edu,Does mitigating ML's impact disparity require treatment disparity?
neurips,2018,1,4982,Julian,McAuley,cmu,UCSD,achould@cmu.edu,Does mitigating ML's impact disparity require treatment disparity?
neurips,2018,2,4982,Alexandra,Chouldechova,ucsd,CMU,jmcauley@cs.ucsd.edu,Does mitigating ML's impact disparity require treatment disparity?
neurips,2018,0,6729,Yubei,Chen,,"EECS, UC Berkeley",,The Sparse Manifold Transform
neurips,2018,1,6729,Dylan,Paiton,,"University of California, Berkeley",,The Sparse Manifold Transform
neurips,2018,2,6729,Bruno,Olshausen,,Redwood Center/UC Berkeley,,The Sparse Manifold Transform
neurips,2018,0,5781,Chelsea,Finn,berkeley,UC Berkeley,cbfinn@eecs.berkeley.edu,Probabilistic Model-Agnostic Meta-Learning
neurips,2018,1,5781,Kelvin,Xu,berkeley,UC Berkeley,kelvinxu@eecs.berkeley.edu,Probabilistic Model-Agnostic Meta-Learning
neurips,2018,2,5781,Sergey,Levine,berkeley,UC Berkeley,svlevine@eecs.berkeley.edu,Probabilistic Model-Agnostic Meta-Learning
neurips,2018,0,3047,Egor,Burkov,,Samsung,,Deep Neural Networks with Box Convolutions
neurips,2018,1,3047,Victor,Lempitsky,,Samsung,,Deep Neural Networks with Box Convolutions
neurips,2018,0,5425,Anna,Thomas,stanford,Stanford,thomasat@stanford.edu,Learning Compressed Transforms with Low Displacement Rank
neurips,2018,1,5425,Albert,Gu,stanford,Stanford,albertgu@stanford.edu,Learning Compressed Transforms with Low Displacement Rank
neurips,2018,2,5425,Tri,Dao,stanford,Stanford University,trid@stanford.edu,Learning Compressed Transforms with Low Displacement Rank
neurips,2018,3,5425,Atri,Rudra,buffalo,"University at Buffalo, SUNY",atri@buffalo.edu,Learning Compressed Transforms with Low Displacement Rank
neurips,2018,4,5425,Christopher,Ré,stanford,Stanford,chrismre@cs.stanford.edu,Learning Compressed Transforms with Low Displacement Rank
neurips,2018,0,268,Ziang,Yan,tsinghua,"Automation Department, Tsinghua University",yza18@mails.tsinghua.edu.cn,Deep Defense: Training DNNs with Improved Adversarial Robustness
neurips,2018,1,268,Yiwen,Guo,intel,Intel Labs China,yiwen.guo@intel.com,Deep Defense: Training DNNs with Improved Adversarial Robustness
neurips,2018,2,268,Changshui,Zhang,tsinghua,Tsinghua University,zcs@mail.tsinghua.edu.cn,Deep Defense: Training DNNs with Improved Adversarial Robustness
neurips,2018,0,968,Nesime,Tatbul,mit,Intel Labs and MIT,tatbul@csail.mit.edu,Precision and Recall for Time Series
neurips,2018,1,968,Tae Jun,Lee,brown,Microsoft,tae_jun_lee@alumni.brown.edu,Precision and Recall for Time Series
neurips,2018,2,968,Stan,Zdonik,brown,Brown University,sbz@cs.brown.edu,Precision and Recall for Time Series
neurips,2018,3,968,Mejbah,Alam,intel,Intel Labs,mejbah.alam@intel.com,Precision and Recall for Time Series
neurips,2018,4,968,Justin,Gottschlich,intel,Intel Labs,justin.gottschlich@intel.com,Precision and Recall for Time Series
neurips,2018,0,839,Ignacio,Rocco,,Inria,,Neighbourhood Consensus Networks
neurips,2018,1,839,Mircea,Cimpoi,,"CIIRC, CTU Prague",,Neighbourhood Consensus Networks
neurips,2018,2,839,Relja,Arandjelovi,,DeepMind,,Neighbourhood Consensus Networks
neurips,2018,3,839,Akihiko,Torii,,"Tokyo Institute of Technology, Japan",,Neighbourhood Consensus Networks
neurips,2018,4,839,Tomas,Pajdla,,Czech Technical University in Prague,,Neighbourhood Consensus Networks
neurips,2018,5,839,Josef,Sivic,,Inria and Czech Technical University,,Neighbourhood Consensus Networks
neurips,2018,0,178,Daniel,Cullina,princeton,Princeton University,dcullina@princeton.edu,PAC-learning in the presence of adversaries
neurips,2018,1,178,Arjun Nitin,Bhagoji,princeton,Princeton University,abhagoji@princeton.edu,PAC-learning in the presence of adversaries
neurips,2018,2,178,Prateek,Mittal,princeton,Princeton University,pmittal@princeton.edu,PAC-learning in the presence of adversaries
neurips,2018,0,1446,Kevin,Scaman,,"Huawei Technologies, Noah's Ark",,Optimal Algorithms for Non-Smooth Distributed Optimization in Networks
neurips,2018,1,1446,Francis,Bach,,INRIA - Ecole Normale Superieure,,Optimal Algorithms for Non-Smooth Distributed Optimization in Networks
neurips,2018,2,1446,Sebastien,Bubeck,,Microsoft Research,,Optimal Algorithms for Non-Smooth Distributed Optimization in Networks
neurips,2018,3,1446,Laurent,Massoulié,,Inria,,Optimal Algorithms for Non-Smooth Distributed Optimization in Networks
neurips,2018,4,1446,Yin Tat,Lee,,UW,,Optimal Algorithms for Non-Smooth Distributed Optimization in Networks
neurips,2018,0,3370,Jack,Baker,lancaster,Lancaster University,j.baker1@lancaster.ac.uk,Large-Scale Stochastic Sampling from the Probability Simplex
neurips,2018,1,3370,Paul,Fearnhead,uw,Lancaster University,ebfox@uw.edu,Large-Scale Stochastic Sampling from the Probability Simplex
neurips,2018,2,3370,Emily,Fox,lancaster,"University of Washington, Apple",p.fearnhead@lancaster.ac.uk,Large-Scale Stochastic Sampling from the Probability Simplex
neurips,2018,3,3370,Christopher,Nemeth,lancaster,Lancaster University,c.nemeth@lancaster.ac.uk,Large-Scale Stochastic Sampling from the Probability Simplex
neurips,2018,0,3040,Andrea,Tirinzoni,polimi,Politecnico di Milano,andrea.tirinzoni@polimi.it,Transfer of Value Functions via Variational Methods
neurips,2018,1,3040,Rafael,Rodriguez Sanchez,polimi,Politecnico di Milano,rafaelalberto.rodriguez@polimi.it,Transfer of Value Functions via Variational Methods
neurips,2018,2,3040,Marcello,Restelli,polimi,Politecnico di Milano,marcello.restelli@polimi.it,Transfer of Value Functions via Variational Methods
neurips,2018,0,6407,Manzil,Zaheer,google,Google,manzilzaheer@google.com,Adaptive Methods for Nonconvex Optimization
neurips,2018,1,6407,Sashank,Reddi,google,Google,sashank@google.com,Adaptive Methods for Nonconvex Optimization
neurips,2018,2,6407,Devendra,Sachan,cmu,Carnegie Mellon University,dsachan@andrew.cmu.edu,Adaptive Methods for Nonconvex Optimization
neurips,2018,3,6407,Satyen,Kale,google,Google,satyenkale@google.com,Adaptive Methods for Nonconvex Optimization
neurips,2018,4,6407,Sanjiv,Kumar,google,Google Research,sanjivk@google.com,Adaptive Methods for Nonconvex Optimization
neurips,2018,0,1246,Shibani,Santurkar,mit,MIT,shibani@mit.edu,How Does Batch Normalization Help Optimization?
neurips,2018,1,1246,Dimitris,Tsipras,mit,MIT,tsipras@mit.edu,How Does Batch Normalization Help Optimization?
neurips,2018,2,1246,Andrew,Ilyas,mit,MIT,ailyas@mit.edu,How Does Batch Normalization Help Optimization?
neurips,2018,3,1246,Aleksander,Madry,mit,MIT,madry@mit.edu,How Does Batch Normalization Help Optimization?
neurips,2018,0,3226,Kaiyu,Yue,baidu,Baidu Inc.,yuekaiyu@baidu.com,Compact Generalized Non-local Network
neurips,2018,1,3226,Ming,Sun,baidu,baidu,sunming05@baidu.com,Compact Generalized Non-local Network
neurips,2018,2,3226,Yuchen,Yuan,baidu,Baidu Inc.,yuanyuchen02@baidu.com,Compact Generalized Non-local Network
neurips,2018,3,3226,Feng,Zhou,baidu,Carnegie Mellon University,zhoufeng09@baidu.com,Compact Generalized Non-local Network
neurips,2018,4,3226,Errui,Ding,baidu,Baidu Inc.,dingerrui@baidu.com,Compact Generalized Non-local Network
neurips,2018,5,3226,Fuxin,Xu,csu,Central South University,fxxu@csu.edu.cn,Compact Generalized Non-local Network
neurips,2018,0,2928,yunlong,yu,tju,Tianjin University,yuyunlong@tju.edu.cn,Stacked Semantics-Guided Attention Model for Fine-Grained Zero-Shot Learning
neurips,2018,1,2928,Zhong,Ji,tju,Tianjin University,jizhong@tju.edu.cn,Stacked Semantics-Guided Attention Model for Fine-Grained Zero-Shot Learning
neurips,2018,2,2928,Yanwei,Fu,tju,"Fudan University, Shanghai;  AItrics Inc.  Seoul",jcguo@tju.edu.cn,Stacked Semantics-Guided Attention Model for Fine-Grained Zero-Shot Learning
neurips,2018,3,2928,Jichang,Guo,tju,Tianjin University,pyw@tju.edu.cn,Stacked Semantics-Guided Attention Model for Fine-Grained Zero-Shot Learning
neurips,2018,4,2928,Yanwei,Pang,fudan,Tianjin University,yanweifu@fudan.edu.cn,Stacked Semantics-Guided Attention Model for Fine-Grained Zero-Shot Learning
neurips,2018,5,2928,Zhongfei (Mark),Zhang,binghamton,Binghamton University,zhongfei@cs.binghamton.edu,Stacked Semantics-Guided Attention Model for Fine-Grained Zero-Shot Learning
neurips,2018,0,3001,Boyuan,Pan,zju,Zhejiang University,panby@zju.edu.cn,MacNet: Transferring Knowledge from Machine Comprehension to Sequence-to-Sequence Models
neurips,2018,1,3001,Yazheng,Yang,zju,Zhejiang University,yazheng_yang@zju.edu.cn,MacNet: Transferring Knowledge from Machine Comprehension to Sequence-to-Sequence Models
neurips,2018,2,3001,Hao,Li,zju,Zhejiang University,haolics@zju.edu.cn,MacNet: Transferring Knowledge from Machine Comprehension to Sequence-to-Sequence Models
neurips,2018,3,3001,Zhou,Zhao,zju,Zhejiang University,zhaozhou@zju.edu.cn,MacNet: Transferring Knowledge from Machine Comprehension to Sequence-to-Sequence Models
neurips,2018,4,3001,Yueting,Zhuang,zju,Zhejiang University,yzhuang@zju.edu.cn,MacNet: Transferring Knowledge from Machine Comprehension to Sequence-to-Sequence Models
neurips,2018,5,3001,Deng,Cai,zju,Zhejiang University,dcai@zju.edu.cn,MacNet: Transferring Knowledge from Machine Comprehension to Sequence-to-Sequence Models
neurips,2018,6,3001,Xiaofei,He,fabu,Zhejiang University,xiaofeihe@fabu.ai,MacNet: Transferring Knowledge from Machine Comprehension to Sequence-to-Sequence Models
neurips,2018,0,1804,Yun Kuen,Cheung,sutd,Singapore University of Technology and Design,yunkuen_cheung@sutd.edu.sg,Multiplicative Weights Updates with Constant Step-Size in Graphical Constant-Sum Games
neurips,2018,0,5033,Haipeng,Luo,usc,University of Southern California,haipengl@usc.edu,Efficient Online Portfolio with Logarithmic Regret
neurips,2018,1,5033,Chen-Yu,Wei,usc,University of Southern California,chenyu.wei@usc.edu,Efficient Online Portfolio with Logarithmic Regret
neurips,2018,2,5033,Kai,Zheng,pku,Peking University,zhengk92@pku.edu.cn,Efficient Online Portfolio with Logarithmic Regret
neurips,2018,0,3402,Jonas,Adler,kth,KTH - Royal Institute of Technology,jonasadl@kth.se,Banach Wasserstein GAN
neurips,2018,1,3402,Sebastian,Lunz,cam,University of Cambridge,lunz@math.cam.ac.uk,Banach Wasserstein GAN
neurips,2018,0,1006,Cem,Keskin,google,Google Inc.,cemkeskin@google.com,SplineNets: Continuous Neural Decision Graphs
neurips,2018,1,1006,Shahram,Izadi,google,Google,shahrami@google.com,SplineNets: Continuous Neural Decision Graphs
neurips,2018,0,6467,Yuanxiang,Gao,utoronto,University of Toronto,yuanxiang@ece.utoronto.ca,Post: Device Placement with Cross-Entropy Minimization and Proximal Policy Optimization
neurips,2018,1,6467,Li,Chen,louisiana,University of Louisiana at Lafayette,li.chen@louisiana.edu,Post: Device Placement with Cross-Entropy Minimization and Proximal Policy Optimization
neurips,2018,2,6467,Baochun,Li,toronto,University of Toronto,bli@ece.toronto.edu,Post: Device Placement with Cross-Entropy Minimization and Proximal Policy Optimization
neurips,2018,0,280,Mikhail,Figurnov,google,DeepMind,mfigurnov@google.com,Implicit Reparameterization Gradients
neurips,2018,1,280,Shakir,Mohamed,google,DeepMind,shakir@google.com,Implicit Reparameterization Gradients
neurips,2018,2,280,Andriy,Mnih,google,DeepMind,amnih@google.com,Implicit Reparameterization Gradients
neurips,2018,0,92,Jun-Yan,Zhu,,MIT,,Visual Object Networks: Image Generation with Disentangled 3D Representations
neurips,2018,1,92,Zhoutong,Zhang,,MIT,,Visual Object Networks: Image Generation with Disentangled 3D Representations
neurips,2018,2,92,Chengkai,Zhang,,Massachusetts Institute of Technology,,Visual Object Networks: Image Generation with Disentangled 3D Representations
neurips,2018,3,92,Jiajun,Wu,,MIT,,Visual Object Networks: Image Generation with Disentangled 3D Representations
neurips,2018,4,92,Antonio,Torralba,,Massachusetts Institute of Technology,,Visual Object Networks: Image Generation with Disentangled 3D Representations
neurips,2018,5,92,Josh,Tenenbaum,,MIT,,Visual Object Networks: Image Generation with Disentangled 3D Representations
neurips,2018,6,92,Bill,Freeman,,MIT/Google,,Visual Object Networks: Image Generation with Disentangled 3D Representations
neurips,2018,0,4861,Renqian,Luo,ustc,University of Science and Technology of China,1lrq@mail.ustc.edu.cn,Neural Architecture Optimization
neurips,2018,1,4861,Fei,Tian,ustc,Miicrosoft Research,cheneh@ustc.edu.cn,Neural Architecture Optimization
neurips,2018,2,4861,Tao,Qin,microsoft,Microsoft Research,2fetia@microsoft.com,Neural Architecture Optimization
neurips,2018,3,4861,Enhong,Chen,microsoft,University of Science and Technology of China,taoqin@microsoft.com,Neural Architecture Optimization
neurips,2018,4,4861,Tie-Yan,Liu,microsoft,Microsoft Research Asia,tie-yan.liu@microsoft.com,Neural Architecture Optimization
neurips,2018,0,2222,Edward,Choi,google,Google,edwardchoi@google.com,MiME: Multilevel Medical Embedding of Electronic Health Records for Predictive Healthcare
neurips,2018,1,2222,Cao,Xiao,ibm,IBM Research,cxiao@us.ibm.com,MiME: Multilevel Medical Embedding of Electronic Health Records for Predictive Healthcare
neurips,2018,2,2222,Walter,Stewart,yahoo,No Affiliation,wfs502000@yahoo.com,MiME: Multilevel Medical Embedding of Electronic Health Records for Predictive Healthcare
neurips,2018,3,2222,Jimeng,Sun,gatech,Georgia Tech,jsun@cc.gatech.edu,MiME: Multilevel Medical Embedding of Electronic Health Records for Predictive Healthcare
neurips,2018,0,1022,Jinyan,Liu,hku,The University of Hong Kong,zhiyi@cs.hku.hk,Learning Optimal Reserve Price against Non-myopic Bidders
neurips,2018,1,1022,Zhiyi,Huang,hku,The University of Hong Kong,jyliu@cs.hku.hk,Learning Optimal Reserve Price against Non-myopic Bidders
neurips,2018,2,1022,Xiangning,Wang,hku,The University of Hong Kong,xnwang@cs.hku.hk,Learning Optimal Reserve Price against Non-myopic Bidders
neurips,2018,0,3698,Wonseok,Jeon,kaist,KAIST,wsjeon@ai.kaist.ac.kr,A Bayesian Approach to Generative Adversarial Imitation Learning
neurips,2018,1,3698,Seokin,Seo,kaist,KAIST,siseo@ai.kaist.ac.kr,A Bayesian Approach to Generative Adversarial Imitation Learning
neurips,2018,2,3698,Kee-Eung,Kim,kaist,KAIST,kekim@cs.kaist.ac.kr,A Bayesian Approach to Generative Adversarial Imitation Learning
neurips,2018,0,4977,Duc Thien,Nguyen,smu,Singapore Management University,dtnguyen.2014@smu.edu.sg,Credit Assignment For Collective Multiagent RL With Global Rewards
neurips,2018,1,4977,Akshat,Kumar,smu,Singapore Management University,akshatkumar@smu.edu.sg,Credit Assignment For Collective Multiagent RL With Global Rewards
neurips,2018,2,4977,Hoong Chuin,Lau,smu,Singapore Management University,hclau@smu.edu.sg,Credit Assignment For Collective Multiagent RL With Global Rewards
neurips,2018,0,3725,xu,lan,,"Queen Mary, University of London",,Knowledge Distillation by On-the-Fly Native Ensemble
neurips,2018,1,3725,Xiatian,Zhu,,"Queen Mary University, London, UK",,Knowledge Distillation by On-the-Fly Native Ensemble
neurips,2018,2,3725,Shaogang,Gong,,Queen Mary University of London,,Knowledge Distillation by On-the-Fly Native Ensemble
neurips,2018,0,2054,Eszter,Vértes,ucl,"Gatsby Unit, UCL",eszter@gatsby.ucl.ac.uk,Flexible and accurate inference and learning for deep generative models
neurips,2018,1,2054,Maneesh,Sahani,ucl,"Gatsby Unit, UCL",maneesh@gatsby.ucl.ac.uk,Flexible and accurate inference and learning for deep generative models
neurips,2018,0,6481,Tam,Le,riken,RIKEN AIP,tam.le@riken.jp,Persistence Fisher Kernel: A Riemannian Manifold Kernel for Persistence Diagrams
neurips,2018,1,6481,Makoto,Yamada,riken,Kyoto University / RIKEN AIP,makoto.yamada@riken.jp,Persistence Fisher Kernel: A Riemannian Manifold Kernel for Persistence Diagrams
neurips,2018,0,1578,Raanan,Rohekar,intel,Intel Corporation,raanan.yehezkel@intel.com,Constructing Deep Neural Networks by Bayesian Network Structure Learning
neurips,2018,1,1578,Shami,Nisimov,intel,intel,shami.nisimov@intel.com,Constructing Deep Neural Networks by Bayesian Network Structure Learning
neurips,2018,2,1578,Yaniv,Gurwicz,intel,Intel AI Lab,yaniv.gurwicz@intel.com,Constructing Deep Neural Networks by Bayesian Network Structure Learning
neurips,2018,3,1578,Guy,Koren,intel,Intel,guy.koren@intel.com,Constructing Deep Neural Networks by Bayesian Network Structure Learning
neurips,2018,4,1578,Gal,Novik,intel,Intel,gal.novik@intel.com,Constructing Deep Neural Networks by Bayesian Network Structure Learning
neurips,2018,0,3607,Tyler,Johnson,washington,University of Washington,tbjohns@washington.edu,"Training Deep Models Faster with Robust, Approximate Importance Sampling"
neurips,2018,1,3607,Carlos,Guestrin,washington,University of Washington,guestrin@cs.washington.edu,"Training Deep Models Faster with Robust, Approximate Importance Sampling"
neurips,2018,0,6783,Renato,Negrinho,cmu,Carnegie Mellon University,negrinho@cs.cmu.edu,Learning Beam Search Policies via Imitation Learning
neurips,2018,1,6783,Matthew,Gormley,cmu,Carnegie Mellon University,mgormley@cs.cmu.edu,Learning Beam Search Policies via Imitation Learning
neurips,2018,2,6783,Geoffrey,Gordon,cmu,MSR Montréal & CMU,ggordon@cs.cmu.edu,Learning Beam Search Policies via Imitation Learning
neurips,2018,0,814,Yonghong,Luo,nankai,Nankai University,luoyonghong@dbis.nankai.edu.cn,Multivariate Time Series Imputation with Generative Adversarial Networks
neurips,2018,1,814,Xiangrui,Cai,nankai,Nankai University,caixiangrui@dbis.nankai.edu.cn,Multivariate Time Series Imputation with Generative Adversarial Networks
neurips,2018,2,814,Ying,ZHANG,nankai,Nankai Univeristy,yingzhang@nankai.edu.cn,Multivariate Time Series Imputation with Generative Adversarial Networks
neurips,2018,3,814,Jun,Xu,ruc,Renmin University of China,junxu@ruc.edu.cn,Multivariate Time Series Imputation with Generative Adversarial Networks
neurips,2018,4,814,Yuan,xiaojie,nankai,Nankai Univeristy,yuanxj@nankai.edu.cn,Multivariate Time Series Imputation with Generative Adversarial Networks
neurips,2018,0,177,Cong Han,Lim,gatech,Georgia Tech,clim31@gatech.edu,An Efficient Pruning Algorithm for Robust Isotonic Regression
neurips,2018,0,792,Jin-Hwa,Kim,sktbrain,SK T-Brain,jnhwkim@sktbrain.com,Bilinear Attention Networks
neurips,2018,1,792,Jaehyun,Jun,snu,Seoul National University,jhjun@bi.snu.ac.kr,Bilinear Attention Networks
neurips,2018,2,792,Byoung-Tak,Zhang,snu,Seoul National University & Surromind Robotics,btzhang@bi.snu.ac.kr,Bilinear Attention Networks
neurips,2018,0,2740,Vikash,Goel,uwaterloo,University of Waterloo,v5goel@uwaterloo.ca,Unsupervised Video Object Segmentation for Deep Reinforcement Learning
neurips,2018,1,2740,Jameson,Weng,uwaterloo,University of Waterloo,jj2weng@uwaterloo.ca,Unsupervised Video Object Segmentation for Deep Reinforcement Learning
neurips,2018,2,2740,Pascal,Poupart,uwaterloo,University of Waterloo & RBC Borealis AI,ppoupart@uwaterloo.ca,Unsupervised Video Object Segmentation for Deep Reinforcement Learning
neurips,2018,0,2893,Yunho,Jeon,kaist,KAIST,jyh2986@kaist.ac.kr,Constructing Fast Network through Deconstruction of Convolution
neurips,2018,1,2893,Junmo,Kim,kaist,KAIST,junmo.kim@kaist.ac.kr,Constructing Fast Network through Deconstruction of Convolution
neurips,2018,0,6595,Amit,Dhurandhar,ibm,IBM Research,adhuran@us.ibm.com,Improving Simple Models with Confidence Profiles
neurips,2018,1,6595,Karthikeyan,Shanmugam,ibm,"IBM Research, NY",rluss@us.ibm.com,Improving Simple Models with Confidence Profiles
neurips,2018,2,6595,Ronny,Luss,ibm,IBM Research,karthikeyan.shanmugam2@ibm.com,Improving Simple Models with Confidence Profiles
neurips,2018,3,6595,Peder,Olsen,ibm,IBM,pederao@us.ibm.com,Improving Simple Models with Confidence Profiles
neurips,2018,0,3171,Qiuyuan,Huang,microsoft,Microsoft Research AI,qihua@microsoft.com,Turbo Learning for CaptionBot and DrawingBot
neurips,2018,1,3171,Pengchuan,Zhang,microsoft,Microsoft Research,penzhan@microsoft.com,Turbo Learning for CaptionBot and DrawingBot
neurips,2018,2,3171,Dapeng,Wu,ieee,University of Florida,dpwu@ieee.org,Turbo Learning for CaptionBot and DrawingBot
neurips,2018,3,3171,Lei,Zhang,microsoft,Microsoft Research,leizhang@microsoft.com,Turbo Learning for CaptionBot and DrawingBot
neurips,2018,0,5037,Fabio,Vitale,inria,Sapienza University of Rome,fabio.vitale@inria.fr,Online Reciprocal Recommendation with Theoretical Performance Guarantees
neurips,2018,1,5037,Nikos,Parotsidis,uniroma2,University of Rome Tor Vergata,nikos.parotsidis@uniroma2.it,Online Reciprocal Recommendation with Theoretical Performance Guarantees
neurips,2018,2,5037,Claudio,Gentile,gmail,INRIA,cla.gentile@gmail.com,Online Reciprocal Recommendation with Theoretical Performance Guarantees
neurips,2018,0,544,Michel,Deudon,polytechnique,Ecole Polytechnique,michel.deudon@polytechnique.edu,Learning semantic similarity in a continuous space
neurips,2018,0,1356,Yao,Liu,stanford,Stanford University,yaoliu@stanford.edu,Representation Balancing MDPs for Off-policy Policy Evaluation
neurips,2018,1,1356,Omer,Gottesman,gmail,Harvard University,aniruddhraghu@gmail.com,Representation Balancing MDPs for Off-policy Policy Evaluation
neurips,2018,2,1356,Aniruddh,Raghu,harvard,Massachusetts Institute of Technology,gottesman@fas.harvard.edu,Representation Balancing MDPs for Off-policy Policy Evaluation
neurips,2018,3,1356,Matthieu,Komorowski,gmail,Imperial College London / MIT,matthieu.komorowski@gmail.com,Representation Balancing MDPs for Off-policy Policy Evaluation
neurips,2018,4,1356,Aldo,Faisal,imperial,Imperial College London,a.faisal@imperial.ac.uk,Representation Balancing MDPs for Off-policy Policy Evaluation
neurips,2018,5,1356,Finale,Doshi-Velez,harvard,Harvard,finale@seas.harvard.edu,Representation Balancing MDPs for Off-policy Policy Evaluation
neurips,2018,6,1356,Emma,Brunskill,stanford,Stanford University,ebrun@cs.stanford.edu,Representation Balancing MDPs for Off-policy Policy Evaluation
neurips,2018,0,186,Shice,Liu,ict,"Institute of Computing Technology, Chinese Academy of Sciences",liushice@ict.ac.cn,See and Think: Disentangling Semantic Scene Completion
neurips,2018,1,186,YU,HU,ict,"Institute of Computing Technology, Chinese Academy of Sciences",huyu@ict.ac.cn,See and Think: Disentangling Semantic Scene Completion
neurips,2018,2,186,Yiming,Zeng,ict,Institute of Computing Technology Chinese Academy of Sciences,zengyiming@ict.ac.cn,See and Think: Disentangling Semantic Scene Completion
neurips,2018,3,186,Qiankun,Tang,ict,"Institute of Computing Technology, Chinese Academy of Sciences",tangqiankun@ict.ac.cn,See and Think: Disentangling Semantic Scene Completion
neurips,2018,4,186,Beibei,Jin,ict,"Institute of Computing Technology, Chinese Academy of Sciences",jinbeibei@ict.ac.cn,See and Think: Disentangling Semantic Scene Completion
neurips,2018,5,186,Yinhe,Han,ict,"Institute of Computing Technology, Chinese Academy of Sciences",yinhes@ict.ac.cn,See and Think: Disentangling Semantic Scene Completion
neurips,2018,6,186,Xiaowei,Li,ict,"Institute of Computing Technology, Chinese Academy of Sciences",lxw@ict.ac.cn,See and Think: Disentangling Semantic Scene Completion
neurips,2018,0,3164,Michal,Rolinek,mpg,Max Planck Institute for Intelligent Systems,michal.rolinek@tuebingen.mpg.de,L4: Practical loss-based stepsize adaptation for deep learning
neurips,2018,1,3164,Georg,Martius,mpg,MPI for Intelligent Systems,georg.martius@tuebingen.mpg.de,L4: Practical loss-based stepsize adaptation for deep learning
neurips,2018,0,5133,James,Whittington,ox,University of Oxford,james.whittington@magd.ox.ac.uk,Generalisation of structural knowledge in the hippocampal-entorhinal system
neurips,2018,1,5133,Timothy,Muller,gmail,University of Oxford,timothymuller127@gmail.com,Generalisation of structural knowledge in the hippocampal-entorhinal system
neurips,2018,2,5133,Shirely,Mark,ucl,University College London,s.mark@ucl.ac.uk,Generalisation of structural knowledge in the hippocampal-entorhinal system
neurips,2018,3,5133,Caswell,Barry,ucl,University College London,caswell.barry@ucl.ac.uk,Generalisation of structural knowledge in the hippocampal-entorhinal system
neurips,2018,4,5133,Tim,Behrens,ox,University of Oxford,behrens@fmrib.ox.ac.uk,Generalisation of structural knowledge in the hippocampal-entorhinal system
neurips,2018,0,988,Robert,Wang,uwo,Aeryon Labs,jwan563@uwo.ca,Pelee: A Real-Time Object Detection System on Mobile Devices
neurips,2018,1,988,Xiang,Li,uwo,Western University,lxiang2@uwo.ca,Pelee: A Real-Time Object Detection System on Mobile Devices
neurips,2018,2,988,Charles,Ling,uwo,University of Western Ontario,charles.ling@uwo.ca,Pelee: A Real-Time Object Detection System on Mobile Devices
neurips,2018,0,5706,Abhishek,Kumar,ibm,Google,abhishk@us.ibm.com,Co-regularized Alignment for Unsupervised Domain Adaptation
neurips,2018,1,5706,Prasanna,Sattigeri,ibm,IBM Research,psattig@us.ibm.com,Co-regularized Alignment for Unsupervised Domain Adaptation
neurips,2018,2,5706,Kahini,Wadhawan,ibm,IBM Research,kahini.wadhawan@ibm.com,Co-regularized Alignment for Unsupervised Domain Adaptation
neurips,2018,3,5706,Leonid,Karlinsky,ibm,IBM-Research,leonidka@il.ibm.com,Co-regularized Alignment for Unsupervised Domain Adaptation
neurips,2018,4,5706,Rogerio,Feris,ibm,IBM Research AI,rsferis@us.ibm.com,Co-regularized Alignment for Unsupervised Domain Adaptation
neurips,2018,5,5706,Bill,Freeman,mit,MIT/Google,billf@mit.edu,Co-regularized Alignment for Unsupervised Domain Adaptation
neurips,2018,6,5706,Gregory,Wornell,mit,MIT,gww@mit.edu,Co-regularized Alignment for Unsupervised Domain Adaptation
neurips,2018,0,608,Zeyuan,Allen-Zhu,mit,Microsoft Research,zeyuan@csail.mit.edu,How To Make the Gradients Small Stochastically: Even Faster Convex and Nonconvex SGD
neurips,2018,0,6406,Yanjun,Han,stanford,Stanford University,yjhan@stanford.edu,Entropy Rate Estimation for Markov Chains with Large State Space
neurips,2018,1,6406,Jiantao,Jiao,berkeley,"University of California, Berkeley",jiantao@berkeley.edu,Entropy Rate Estimation for Markov Chains with Large State Space
neurips,2018,2,6406,Chuan-Zheng,Lee,stanford,Stanford University,czlee@stanford.edu,Entropy Rate Estimation for Markov Chains with Large State Space
neurips,2018,3,6406,Tsachy,Weissman,stanford,Stanford University,tsachy@stanford.edu,Entropy Rate Estimation for Markov Chains with Large State Space
neurips,2018,4,6406,Yihong,Wu,yale,Yale University,yihong.wu@yale.edu,Entropy Rate Estimation for Markov Chains with Large State Space
neurips,2018,5,6406,Tiancheng,Yu,foxmail,Tsinghua University,thueeyutc14@foxmail.com,Entropy Rate Estimation for Markov Chains with Large State Space
neurips,2018,0,5112,Gintare Karolina,Dziugaite,,University of Cambridge,,Data-dependent PAC-Bayes priors via differential privacy
neurips,2018,1,5112,Daniel,Roy,,Univ of Toronto & Vector,,Data-dependent PAC-Bayes priors via differential privacy
neurips,2018,0,6384,Joel Ruben Antony,Moniz,,Carnegie Mellon University,,"Unsupervised Depth Estimation, 3D Face Rotation and Replacement"
neurips,2018,1,6384,Christopher,Beckham,,MILA,,"Unsupervised Depth Estimation, 3D Face Rotation and Replacement"
neurips,2018,2,6384,Simon,Rajotte,,Polytechnique Montréal,,"Unsupervised Depth Estimation, 3D Face Rotation and Replacement"
neurips,2018,3,6384,Sina,Honari,,University of Montreal,,"Unsupervised Depth Estimation, 3D Face Rotation and Replacement"
neurips,2018,4,6384,Chris,Pal,,"MILA, Polytechnique Montréal, Element AI",,"Unsupervised Depth Estimation, 3D Face Rotation and Replacement"
neurips,2018,0,3018,Romain,Lopez,berkeley,UC Berkeley,romain_lopez@berkeley.edu,Information Constraints on Auto-Encoding Variational Bayes
neurips,2018,1,3018,Jeffrey,Regier,berkeley,UC Berkeley,regier@berkeley.edu,Information Constraints on Auto-Encoding Variational Bayes
neurips,2018,2,3018,Michael,Jordan,berkeley,UC Berkeley,niryosef@berkeley.edu,Information Constraints on Auto-Encoding Variational Bayes
neurips,2018,3,3018,Nir,Yosef,berkeley,UC Berkeley,jordan@cs.berkeley.edu,Information Constraints on Auto-Encoding Variational Bayes
neurips,2018,0,231,Amo,Tong,udel,University of Delaware,amotong@udel.edu,On Misinformation Containment in Online Social Networks
neurips,2018,1,231,Ding-Zhu,Du,utdallas,University of Texas at Dallas,weiliwu@utdallas.edu,On Misinformation Containment in Online Social Networks
neurips,2018,2,231,Weili,Wu,utdallas,University of Texas at Dallas,dzdu@utdallas.edu,On Misinformation Containment in Online Social Networks
neurips,2018,0,6836,Matthew D.,Hoffman,google,Google,mhoffman@google.com,Autoconj: Recognizing and Exploiting Conjugacy Without a Domain-Specific Language
neurips,2018,1,6836,Matthew,Johnson,google,,mattjj@google.com,Autoconj: Recognizing and Exploiting Conjugacy Without a Domain-Specific Language
neurips,2018,2,6836,Dustin,Tran,google,,trandustin@google.com,Autoconj: Recognizing and Exploiting Conjugacy Without a Domain-Specific Language
neurips,2018,0,3213,Bolton,Bailey,illinois,University of Illinois Urbana-Champaign,boltonb2@illinois.edu,Size-Noise Tradeoffs in Generative Networks
neurips,2018,1,3213,Matus,Telgarsky,illinois,UIUC,mjt@illinois.edu,Size-Noise Tradeoffs in Generative Networks
neurips,2018,0,1598,Pan,Xu,ucla,UCLA,panxu@cs.ucla.edu,Global Convergence of Langevin Dynamics Based Algorithms for Nonconvex Optimization
neurips,2018,1,1598,Jinghui,Chen,ucla,University of Virginia,knowzou@cs.ucla.edu,Global Convergence of Langevin Dynamics Based Algorithms for Nonconvex Optimization
neurips,2018,2,1598,Difan,Zou,virginia,"University of California, Los Angeles",jc4zg@virginia.edu,Global Convergence of Langevin Dynamics Based Algorithms for Nonconvex Optimization
neurips,2018,3,1598,Quanquan,Gu,ucla,UCLA,qgu@cs.ucla.edu,Global Convergence of Langevin Dynamics Based Algorithms for Nonconvex Optimization
neurips,2018,0,3021,Jianjun,Yuan,umn,University of Minnesota,yuanx270@umn.edu,Online convex optimization for cumulative constraints
neurips,2018,1,3021,Andrew,Lamperski,umn,University of Minnesota,alampers@umn.edu,Online convex optimization for cumulative constraints
neurips,2018,0,2545,Neal,Jean,stanford,Stanford University,nealjean@cs.stanford.edu,Semi-supervised Deep Kernel Learning: Regression with Unlabeled Data by Minimizing Predictive Variance
neurips,2018,1,2545,Sang Michael,Xie,stanford,Stanford University,xie@cs.stanford.edu,Semi-supervised Deep Kernel Learning: Regression with Unlabeled Data by Minimizing Predictive Variance
neurips,2018,2,2545,Stefano,Ermon,stanford,Stanford,ermon@cs.stanford.edu,Semi-supervised Deep Kernel Learning: Regression with Unlabeled Data by Minimizing Predictive Variance
neurips,2018,0,3582,Fabian,Sinz,,University Tübingen,,Stimulus domain transfer in recurrent models for large scale cortical population prediction on video
neurips,2018,1,3582,Alexander,Ecker,,University of Tuebingen,,Stimulus domain transfer in recurrent models for large scale cortical population prediction on video
neurips,2018,2,3582,Paul,Fahey,,Bayl,,Stimulus domain transfer in recurrent models for large scale cortical population prediction on video
neurips,2018,3,3582,Edgar,Walker,,Baylor College of Medicine,,Stimulus domain transfer in recurrent models for large scale cortical population prediction on video
neurips,2018,4,3582,Erick,Cobos,,Baylor College of Medicine,,Stimulus domain transfer in recurrent models for large scale cortical population prediction on video
neurips,2018,5,3582,Emmanouil,Froudarakis,,Baylor College of Medicine,,Stimulus domain transfer in recurrent models for large scale cortical population prediction on video
neurips,2018,6,3582,Dimitri,Yatsenko,,Baylor College of Medicine,,Stimulus domain transfer in recurrent models for large scale cortical population prediction on video
neurips,2018,7,3582,Zachary,Pitkow,,BCM/Rice,,Stimulus domain transfer in recurrent models for large scale cortical population prediction on video
neurips,2018,8,3582,Jacob,Reimer,,Baylor College of Medicine,,Stimulus domain transfer in recurrent models for large scale cortical population prediction on video
neurips,2018,9,3582,Andreas,Tolias,,Baylor College of Medicine,,Stimulus domain transfer in recurrent models for large scale cortical population prediction on video
neurips,2018,0,188,Sekitoshi,Kanai,ntt,"NTT, Keio University",kanai.sekitoshi@lab.ntt.co.jp,Sigsoftmax: Reanalysis of the Softmax Bottleneck
neurips,2018,1,188,Yasuhiro,Fujiwara,ntt,NTT Software Innovation Center,yamanaka.yuki@lab.ntt.co.jp,Sigsoftmax: Reanalysis of the Softmax Bottleneck
neurips,2018,2,188,Yuki,Yamanaka,ntt,NTT Secure Platform Laboratories,fujiwara.yasuhiro@lab.ntt.co.jp,Sigsoftmax: Reanalysis of the Softmax Bottleneck
neurips,2018,3,188,Shuichi,Adachi,keio,Keio University,adachi.shuichi@appi.keio.ac.jp,Sigsoftmax: Reanalysis of the Softmax Bottleneck
neurips,2018,0,798,Xing,Yan,cuhk,The Chinese University of Hong Kong,xyan@se.cuhk.edu.hk,Parsimonious Quantile Regression of Financial Asset Tail Dynamics via Sequential Learning
neurips,2018,1,798,Weizhong,Zhang,gmail,Zhejiang University,zhangweizhongzju@gmail.com,Parsimonious Quantile Regression of Financial Asset Tail Dynamics via Sequential Learning
neurips,2018,2,798,Lin,Ma,gmail,Tencent AI Lab,forest.linma@gmail.com,Parsimonious Quantile Regression of Financial Asset Tail Dynamics via Sequential Learning
neurips,2018,3,798,Wei,Liu,columbia,Tencent AI Lab,wl2223@columbia.edu,Parsimonious Quantile Regression of Financial Asset Tail Dynamics via Sequential Learning
neurips,2018,4,798,Qi,Wu,cityu,City University of Hong Kong,qiwu55@cityu.edu.hk,Parsimonious Quantile Regression of Financial Asset Tail Dynamics via Sequential Learning
neurips,2018,0,3719,Yonatan,Gur,stanford,Stanford University,ygur@stanford.edu,Adaptive Learning with Unknown Information Flows
neurips,2018,1,3719,Ahmadreza,Momeni,stanford,Stanford University,amomenis@stanford.edu,Adaptive Learning with Unknown Information Flows
neurips,2018,0,931,Arash,Vahdat,quadrant,Quadrant.ai (D-Wave),arash@quadrant.ai,DVAE#: Discrete Variational Autoencoders with Relaxed Boltzmann Priors
neurips,2018,1,931,Evgeny,Andriyash,quadrant,D-Wave,evgeny@quadrant.ai,DVAE#: Discrete Variational Autoencoders with Relaxed Boltzmann Priors
neurips,2018,2,931,William,Macready,quadrant,D-Wave,bill@quadrant.ai,DVAE#: Discrete Variational Autoencoders with Relaxed Boltzmann Priors
neurips,2018,0,6428,MohammadReza,Nazari,lehigh,Lehigh University,mon314@lehigh.edu,Reinforcement Learning for Solving the Vehicle Routing Problem
neurips,2018,1,6428,Afshin,Oroojlooy,lehigh,SAS Institute,afo214@lehigh.edu,Reinforcement Learning for Solving the Vehicle Routing Problem
neurips,2018,2,6428,Lawrence,Snyder,lehigh,Lehigh University,takac@lehigh.edu,Reinforcement Learning for Solving the Vehicle Routing Problem
neurips,2018,3,6428,Martin,Takac,lehigh,Lehigh University,lvs2@lehigh.edu,Reinforcement Learning for Solving the Vehicle Routing Problem
neurips,2018,0,2007,Amir,Khoshaman,gmail,D-Wave Systems Inc,khoshaman@gmail.com,GumBolt: Extending Gumbel trick to Boltzmann priors
neurips,2018,1,2007,Mohammad,Amin,dwavesys,D-Wave Systems Inc,mhsamin@dwavesys.com,GumBolt: Extending Gumbel trick to Boltzmann priors
neurips,2018,0,2125,SHIYU,LIANG,illinois,UIUC,sliang26@illinois.edu,Adding One Neuron Can Eliminate All Bad Local Minima
neurips,2018,1,2125,Ruoyu,Sun,illinois,University of Illinois at Urbana-Champaign,ruoyus@illinois.edu,Adding One Neuron Can Eliminate All Bad Local Minima
neurips,2018,2,2125,Jason,Lee,usc,University of Southern California,jasonlee@marshall.usc.edu,Adding One Neuron Can Eliminate All Bad Local Minima
neurips,2018,3,2125,R.,Srikant,illinois,University of Illinois at Urbana-Champaign,rsrikant@illinois.edu,Adding One Neuron Can Eliminate All Bad Local Minima
neurips,2018,0,1099,Elad,Hoffer,gmail,Technion,elad.hoffer@gmail.com,Norm matters: efficient and accurate normalization schemes in deep networks
neurips,2018,1,1099,Ron,Banner,gmail,Intel - Artificial Intelligence Products Group (AIPG),itaygolan@gmail.com,Norm matters: efficient and accurate normalization schemes in deep networks
neurips,2018,2,1099,Itay,Golan,gmail,Technion,daniel.soudry@gmail.com,Norm matters: efficient and accurate normalization schemes in deep networks
neurips,2018,3,1099,Daniel,Soudry,intel,Technion,ron.banner@intel.com,Norm matters: efficient and accurate normalization schemes in deep networks
neurips,2018,0,1212,Matthew,Joseph,upenn,University of Pennsylvania,majos@cis.upenn.edu,Local Differential Privacy for Evolving Data
neurips,2018,1,1212,Aaron,Roth,neu,University of Pennsylvania,jullman@ccs.neu.edu,Local Differential Privacy for Evolving Data
neurips,2018,2,1212,Jonathan,Ullman,upenn,Northeastern University,aaroth@cis.upenn.edu,Local Differential Privacy for Evolving Data
neurips,2018,3,1212,Bo,Waggoner,gmail,Microsoft,bowaggoner@gmail.com,Local Differential Privacy for Evolving Data
neurips,2018,0,390,Xiaoxiao,Guo,,IBM Research,,Dialog-based Interactive Image Retrieval
neurips,2018,1,390,Hui,Wu,,IBM Research,,Dialog-based Interactive Image Retrieval
neurips,2018,2,390,Yu,Cheng,,Microsoft AI & Research,,Dialog-based Interactive Image Retrieval
neurips,2018,3,390,Steven,Rennie,,Fusemachines,,Dialog-based Interactive Image Retrieval
neurips,2018,4,390,Gerald,Tesauro,,IBM TJ Watson Research Center,,Dialog-based Interactive Image Retrieval
neurips,2018,5,390,Rogerio,Feris,,IBM Research AI,,Dialog-based Interactive Image Retrieval
neurips,2018,0,2250,Dan,Alistarh,ist,IST Austria,dan.alistarh@ist.ac.at,Byzantine Stochastic Gradient Descent
neurips,2018,1,2250,Zeyuan,Allen-Zhu,mit,Microsoft Research,zeyuan@csail.mit.edu,Byzantine Stochastic Gradient Descent
neurips,2018,2,2250,Jerry,Li,berkeley,Berkeley,jerryzli@berkeley.edu,Byzantine Stochastic Gradient Descent
neurips,2018,0,4901,RUI,GAO,gatech,GEORGIA TECH,rgao32@gatech.edu,Robust Hypothesis Testing Using Wasserstein Uncertainty Sets
neurips,2018,1,4901,Liyan,Xie,gatech,Georgia Institute of Technology,lxie49@gatech.edu,Robust Hypothesis Testing Using Wasserstein Uncertainty Sets
neurips,2018,2,4901,Yao,Xie,gatech,Georgia Institute of Technology,yao.xie@isye.gatech.edu,Robust Hypothesis Testing Using Wasserstein Uncertainty Sets
neurips,2018,3,4901,Huan,Xu,gatech,Georgia Inst. of Technology,huan.xu@isye.gatech.edu,Robust Hypothesis Testing Using Wasserstein Uncertainty Sets
neurips,2018,0,6432,Alessandro,Achille,google,UCLA,eccles@google.com,Life-Long Disentangled Representation Learning with Cross-Domain Latent Homologies
neurips,2018,1,6432,Tom,Eccles,google,DeepMind,lmatthey@google.com,Life-Long Disentangled Representation Learning with Cross-Domain Latent Homologies
neurips,2018,2,6432,Loic,Matthey,google,DeepMind,cpburgess@google.com,Life-Long Disentangled Representation Learning with Cross-Domain Latent Homologies
neurips,2018,3,6432,Chris,Burgess,google,DeepMind,nwatters@google.com,Life-Long Disentangled Representation Learning with Cross-Domain Latent Homologies
neurips,2018,4,6432,Nicholas,Watters,google,Google DeepMind,lerchner@google.com,Life-Long Disentangled Representation Learning with Cross-Domain Latent Homologies
neurips,2018,5,6432,Alexander,Lerchner,google,DeepMind,irinah@google.com,Life-Long Disentangled Representation Learning with Cross-Domain Latent Homologies
neurips,2018,6,6432,Irina,Higgins,ucla,DeepMind,achille@cs.ucla.edu,Life-Long Disentangled Representation Learning with Cross-Domain Latent Homologies
neurips,2018,0,7994,Kevin,Bello,purdue,Purdue University,jhonorio@purdue.edu,Computationally and statistically efficient learning of causal Bayes nets using path queries
neurips,2018,1,7994,Jean,Honorio,purdue,Purdue University,kbellome@purdue.edu,Computationally and statistically efficient learning of causal Bayes nets using path queries
neurips,2018,0,6582,Yingxiang,Yang,,University of Illinois at Urbana Champaign,,Predictive Approximate Bayesian Computation via Saddle Points
neurips,2018,1,6582,Bo,Dai,,Google Brain,,Predictive Approximate Bayesian Computation via Saddle Points
neurips,2018,2,6582,Negar,Kiyavash,,Georgia Tech,,Predictive Approximate Bayesian Computation via Saddle Points
neurips,2018,3,6582,Niao,He,,UIUC,,Predictive Approximate Bayesian Computation via Saddle Points
neurips,2018,0,5143,Bo,Han,,RIKEN & UTS,,Co-teaching: Robust training of deep neural networks with extremely noisy labels
neurips,2018,1,5143,Quanming,Yao,,4Paradigm,,Co-teaching: Robust training of deep neural networks with extremely noisy labels
neurips,2018,2,5143,Xingrui,Yu,,University of Technology Sydney,,Co-teaching: Robust training of deep neural networks with extremely noisy labels
neurips,2018,3,5143,Gang,Niu,,RIKEN,,Co-teaching: Robust training of deep neural networks with extremely noisy labels
neurips,2018,4,5143,Miao,Xu,,RIKEN AIP,,Co-teaching: Robust training of deep neural networks with extremely noisy labels
neurips,2018,5,5143,Weihua,Hu,,The University of Tokyo,,Co-teaching: Robust training of deep neural networks with extremely noisy labels
neurips,2018,6,5143,Ivor,Tsang,,"University of Technology, Sydney",,Co-teaching: Robust training of deep neural networks with extremely noisy labels
neurips,2018,7,5143,Masashi,Sugiyama,,RIKEN / University of Tokyo,,Co-teaching: Robust training of deep neural networks with extremely noisy labels
neurips,2018,0,1573,Lénaïc,Chizat,inria,INRIA,lenaic.chizat@inria.fr,On the Global Convergence of Gradient Descent for Over-parameterized Models using Optimal Transport
neurips,2018,1,1573,Francis,Bach,inria,INRIA - Ecole Normale Superieure,francis.bach@inria.fr,On the Global Convergence of Gradient Descent for Over-parameterized Models using Optimal Transport
neurips,2018,0,1147,Thomas,Pumir,princeton,Princeton University,tpumir@princeton.edu,Smoothed analysis of the low-rank approach for smooth semidefinite programs
neurips,2018,1,1147,Samy,Jelassi,princeton,Princeton University,sjelassi@princeton.edu,Smoothed analysis of the low-rank approach for smooth semidefinite programs
neurips,2018,2,1147,Nicolas,Boumal,princeton,Princeton,nboumal@math.princeton.edu,Smoothed analysis of the low-rank approach for smooth semidefinite programs
neurips,2018,0,2098,Roshan,Shariff,,University of Alberta,,Differentially Private Contextual Linear Bandits
neurips,2018,1,2098,Or,Sheffet,,University of Alberta,,Differentially Private Contextual Linear Bandits
neurips,2018,0,6471,Imanol,Schlag,idsia,IDSIA,juergen@idsia.ch,Learning to Reason with Third Order Tensor Products
neurips,2018,1,6471,Jürgen,Schmidhuber,idsia,"Swiss AI Lab, IDSIA (USI & SUPSI) - NNAISENSE",imanol@idsia.ch,Learning to Reason with Third Order Tensor Products
neurips,2018,0,6722,Zhang-Wei,Hong,,National Tsing Hua University,,Diversity-Driven Exploration Strategy for Deep Reinforcement Learning
neurips,2018,1,6722,Tzu-Yun,Shann,,University of British Columbia,,Diversity-Driven Exploration Strategy for Deep Reinforcement Learning
neurips,2018,2,6722,Shih-Yang,Su,,Virginia Tech,,Diversity-Driven Exploration Strategy for Deep Reinforcement Learning
neurips,2018,3,6722,Yi-Hsiang,Chang,,,,Diversity-Driven Exploration Strategy for Deep Reinforcement Learning
neurips,2018,4,6722,Tsu-Jui,Fu,,Academia Sinica,,Diversity-Driven Exploration Strategy for Deep Reinforcement Learning
neurips,2018,5,6722,Chun-Yi,Lee,,National Tsing Hua University,,Diversity-Driven Exploration Strategy for Deep Reinforcement Learning
neurips,2018,0,3826,Pierre,Baldi,uci,UC Irvine,pfbaldi@uci.edu,On Neuronal Capacity
neurips,2018,1,3826,Roman,Vershynin,uci,UCI,rvershyn@uci.edu,On Neuronal Capacity
neurips,2018,0,8035,Patrick,Chen,ucla,UCLA,patrickchen@g.ucla.edu,GroupReduce: Block-Wise Low-Rank Approximation for Neural Language Model Shrinking
neurips,2018,1,8035,Si,Si,google,Google Research,sisidaisy@google.com,GroupReduce: Block-Wise Low-Rank Approximation for Neural Language Model Shrinking
neurips,2018,2,8035,Yang,Li,google,Google,liyang@google.com,GroupReduce: Block-Wise Low-Rank Approximation for Neural Language Model Shrinking
neurips,2018,3,8035,Ciprian,Chelba,google,Google,ciprianchelba@google.com,GroupReduce: Block-Wise Low-Rank Approximation for Neural Language Model Shrinking
neurips,2018,4,8035,Cho-Jui,Hsieh,ucla,"UCLA, Google Research",chohsieh@cs.ucla.edu,GroupReduce: Block-Wise Low-Rank Approximation for Neural Language Model Shrinking
neurips,2018,0,3122,Colin,Graber,illinois,University of Illinois at Urbana-Champaign,cgraber2@illinois.edu,Deep Structured Prediction with Nonlinear Output Transformations
neurips,2018,1,3122,Ofer,Meshi,google,Google,meshi@google.com,Deep Structured Prediction with Nonlinear Output Transformations
neurips,2018,2,3122,Alexander,Schwing,illinois,University of Illinois at Urbana-Champaign,aschwing@illinois.edu,Deep Structured Prediction with Nonlinear Output Transformations
neurips,2018,0,3356,Zhouyuan,Huo,pitt,University of Pittsburgh,zhouyuan.huo@pitt.edu,Training Neural Networks Using Features Replay
neurips,2018,1,3356,Bin,Gu,gmail,Pittsburgh University,jsgubin@gmail.com,Training Neural Networks Using Features Replay
neurips,2018,2,3356,Heng,Huang,pitt,University of Pittsburgh,heng.huang@pitt.edu,Training Neural Networks Using Features Replay
neurips,2018,0,2155,Flavio,Chierichetti,uniroma1,Sapienza University,flavio@di.uniroma1.it,Mallows Models for Top-k Lists
neurips,2018,1,2155,Anirban,Dasgupta,gmail,IIT Gandhinagar,anirban.dasgupta@gmail.com,Mallows Models for Top-k Lists
neurips,2018,2,2155,Shahrzad,Haddadan,uniroma1,"Sapienza University, Rome, Italy",shahrzad.haddadan@uniroma1.it,Mallows Models for Top-k Lists
neurips,2018,3,2155,Ravi,Kumar,gmail,Google,ravi.k53@gmail.com,Mallows Models for Top-k Lists
neurips,2018,4,2155,Silvio,Lattanzi,gmail,Google Research,silviolat@gmail.com,Mallows Models for Top-k Lists
neurips,2018,0,2336,Boyla,Mainsah,,Duke University,,Information-based Adaptive Stimulus Selection to Optimize Communication Efficiency in Brain-Computer Interfaces
neurips,2018,1,2336,Dmitry,Kalika,,Johns Hopkins Applied Physics Laboratory,,Information-based Adaptive Stimulus Selection to Optimize Communication Efficiency in Brain-Computer Interfaces
neurips,2018,2,2336,Leslie,Collins,,Duke University,,Information-based Adaptive Stimulus Selection to Optimize Communication Efficiency in Brain-Computer Interfaces
neurips,2018,3,2336,Siyuan,Liu,,Duke University,,Information-based Adaptive Stimulus Selection to Optimize Communication Efficiency in Brain-Computer Interfaces
neurips,2018,4,2336,Chandra,Throckmorton,,Duke University,,Information-based Adaptive Stimulus Selection to Optimize Communication Efficiency in Brain-Computer Interfaces
neurips,2018,0,68,Jeremias,Knoblauch,warwick,Warwick University,j.knoblauch@warwick.ac.uk,Doubly Robust Bayesian Inference for Non-Stationary Streaming Data with $\beta$-Divergences
neurips,2018,1,68,Jack,Jewson,warwick,University of Warwick,j.e.jewson@warwick.ac.uk,Doubly Robust Bayesian Inference for Non-Stationary Streaming Data with $\beta$-Divergences
neurips,2018,2,68,Theodoros,Damoulas,warwick,University of Warwick        The Alan Turing Institute,t.damoulas@warwick.ac.uk,Doubly Robust Bayesian Inference for Non-Stationary Streaming Data with $\beta$-Divergences
neurips,2018,0,6510,Risi,Kondor,uchicago,U. Chicago,risi@uchicago.edu,ClebschGordan Nets: a Fully Fourier Space Spherical Convolutional Neural Network
neurips,2018,1,6510,Zhen,Lin,uchicago,The University of Chicago,zlin7@uchicago.edu,ClebschGordan Nets: a Fully Fourier Space Spherical Convolutional Neural Network
neurips,2018,2,6510,Shubhendu,Trivedi,ttic,Brown University,shubhendu@ttic.edu,ClebschGordan Nets: a Fully Fourier Space Spherical Convolutional Neural Network
neurips,2018,0,3144,Hao,Li,umd,"University of Maryland, Amazon AI",haoli@cs.umd.edu,Visualizing the Loss Landscape of Neural Nets
neurips,2018,1,3144,Zheng,Xu,umd,"University of Maryland, College Park",xuzh@cs.umd.edu,Visualizing the Loss Landscape of Neural Nets
neurips,2018,2,3144,Gavin,Taylor,umd,US Naval Academy,tomg@cs.umd.edu,Visualizing the Loss Landscape of Neural Nets
neurips,2018,3,3144,Christoph,Studer,usna,Cornell University,taylor@usna.edu,Visualizing the Loss Landscape of Neural Nets
neurips,2018,4,3144,Tom,Goldstein,cornell,University of Maryland,studer@cornell.edu,Visualizing the Loss Landscape of Neural Nets
neurips,2018,0,1194,Eric,Balkanski,harvard,Harvard University,ericbalkanski@g.harvard.edu,Non-monotone Submodular Maximization in Exponentially Fewer Iterations
neurips,2018,1,1194,Adam,Breuer,harvard,Harvard University,breuer@g.harvard.edu,Non-monotone Submodular Maximization in Exponentially Fewer Iterations
neurips,2018,2,1194,Yaron,Singer,harvard,Harvard University,yaron@seas.harvard.edu,Non-monotone Submodular Maximization in Exponentially Fewer Iterations
neurips,2018,0,1344,Liuyi,Yao,buffalo,State University of New York at Buffalo,liuyiyao@buffalo.edu,Representation Learning for Treatment Effect Estimation from Observational Data
neurips,2018,1,1344,Sheng,Li,uga,University of Georgia,sheng.li@uga.edu,Representation Learning for Treatment Effect Estimation from Observational Data
neurips,2018,2,1344,Yaliang,Li,tencent,Tencent Medical AI Lab,yaliangli@tencent.com,Representation Learning for Treatment Effect Estimation from Observational Data
neurips,2018,3,1344,Mengdi,Huai,buffalo,State University of New York at Buffalo,mengdihu@buffalo.edu,Representation Learning for Treatment Effect Estimation from Observational Data
neurips,2018,4,1344,Jing,Gao,buffalo,University at Buffalo,jing@buffalo.edu,Representation Learning for Treatment Effect Estimation from Observational Data
neurips,2018,5,1344,Aidong,Zhang,buffalo,SUNY Buffalo,azhang@buffalo.edu,Representation Learning for Treatment Effect Estimation from Observational Data
neurips,2018,0,2901,Chenshen,Wu,uab,Computer Vision Center,chenshen@cvc.uab.es,Memory Replay GANs: Learning to Generate New Categories without Forgetting
neurips,2018,1,2901,Luis,Herranz,uab,Computer Vision Center,lherranz@cvc.uab.es,Memory Replay GANs: Learning to Generate New Categories without Forgetting
neurips,2018,2,2901,Xialei,Liu,uab,Computer Vision Center,xialei@cvc.uab.es,Memory Replay GANs: Learning to Generate New Categories without Forgetting
neurips,2018,3,2901,yaxing,wang,uab,Centre de Visió per Computador (CVC),yaxing@cvc.uab.es,Memory Replay GANs: Learning to Generate New Categories without Forgetting
neurips,2018,4,2901,Joost,van de Weijer,uab,Computer Vision Center Barcelona,joost@cvc.uab.es,Memory Replay GANs: Learning to Generate New Categories without Forgetting
neurips,2018,5,2901,Bogdan,Raducanu,uab,Computer Vision Center,bogdan@cvc.uab.es,Memory Replay GANs: Learning to Generate New Categories without Forgetting
neurips,2018,0,37,Constantinos,Daskalakis,mit,MIT,costis@csail.mit.edu,HOGWILD!-Gibbs can be PanAccurate
neurips,2018,1,37,Nishanth,Dikkala,mit,MIT,nishanthd@csail.mit.edu,HOGWILD!-Gibbs can be PanAccurate
neurips,2018,2,37,Siddhartha,Jayanti,mit,MIT,jayanti@mit.edu,HOGWILD!-Gibbs can be PanAccurate
neurips,2018,0,1098,Runsheng,Yu,gmail,"Xiaomi Intelligent Technology Co., Ltd",runshengyu@gmail.com,DeepExposure: Learning to Expose Photos with Asynchronously Reinforced Adversarial Learning
neurips,2018,1,1098,Wenyu,Liu,pku,Peking University,liuwenyu@pku.edu.cn,DeepExposure: Learning to Expose Photos with Asynchronously Reinforced Adversarial Learning
neurips,2018,2,1098,Yasen,Zhang,xiaomi,Xiaomi AI Lab,zhangyasen@xiaomi.com,DeepExposure: Learning to Expose Photos with Asynchronously Reinforced Adversarial Learning
neurips,2018,3,1098,Zhi,Qu,xiaomi,Xiaomi AI Lab,quzhi@xiaomi.com,DeepExposure: Learning to Expose Photos with Asynchronously Reinforced Adversarial Learning
neurips,2018,4,1098,Deli,Zhao,xiaomi,Xiaomi AI Lab,zhaodeli@xiaomi.com,DeepExposure: Learning to Expose Photos with Asynchronously Reinforced Adversarial Learning
neurips,2018,5,1098,Bo,Zhang,xiaomi,Xiaomi Corp.,zhangbo@xiaomi.com,DeepExposure: Learning to Expose Photos with Asynchronously Reinforced Adversarial Learning
neurips,2018,0,5310,Yi,Hao,ucsd,"University of California, San Diego",yih179@eng.ucsd.edu,Data Amplification: A Unified and Competitive Approach to Property Estimation
neurips,2018,1,5310,Alon,Orlitsky,ucsd,"University of California, San Diego",alon@eng.ucsd.edu,Data Amplification: A Unified and Competitive Approach to Property Estimation
neurips,2018,2,5310,Ananda Theertha,Suresh,google,Google,theertha@google.com,Data Amplification: A Unified and Competitive Approach to Property Estimation
neurips,2018,3,5310,Yihong,Wu,yale,Yale University,yihong.wu@yale.edu,Data Amplification: A Unified and Competitive Approach to Property Estimation
neurips,2018,0,2770,Ari,Morcos,gmail,Facebook AI Research,arimorcos@gmail.com,Insights on representational similarity in neural networks with canonical correlation
neurips,2018,1,2770,Maithra,Raghu,gmail,Cornell University and Google Brain,maithrar@gmail.com,Insights on representational similarity in neural networks with canonical correlation
neurips,2018,2,2770,Samy,Bengio,google,Google Brain,bengio@google.com,Insights on representational similarity in neural networks with canonical correlation
neurips,2018,0,576,Shali,Jiang,wustl,Washington University in St. Louis,jiang.s@wustl.edu,Efficient nonmyopic batch active search
neurips,2018,1,576,Gustavo,Malkomes,wustl,Washington University in St. Louis,luizgustavo@wustl.edu,Efficient nonmyopic batch active search
neurips,2018,2,576,Matthew,Abbott,cmu,Washington University in St. Louis,moseleyb@andrew.cmu.edu,Efficient nonmyopic batch active search
neurips,2018,3,576,Benjamin,Moseley,wustl,Carnegie Mellon University,mbabbott@wustl.edu,Efficient nonmyopic batch active search
neurips,2018,4,576,Roman,Garnett,wustl,Washington University in St. Louis,garnett@wustl.edu,Efficient nonmyopic batch active search
neurips,2018,0,5456,Jessie,Huang,mcgill,McGill University,jiexi.huang@mcgill.ca,Learning Safe Policies with Expert Guidance
neurips,2018,1,5456,Fa,Wu,mcgill,McGill,fa.wu2@mcgill.ca,Learning Safe Policies with Expert Guidance
neurips,2018,2,5456,Doina,Precup,mcgill,McGill University / DeepMind Montreal,dprecup@cs.mcgill.ca,Learning Safe Policies with Expert Guidance
neurips,2018,3,5456,Yang,Cai,mcgill,McGill University,cai@cs.mcgill.ca,Learning Safe Policies with Expert Guidance
neurips,2018,0,142,Wenye,Li,cuhk,"The Chinese University of Hong Kong, Shenzhen",wyli@cuhk.edu.cn,Fast Similarity Search via Optimal Sparse Lifting
neurips,2018,1,142,Jingwei,Mao,cuhk,"The Chinese University of Hong Kong, Shenzhen",yinzhang@cuhk.edu.cn,Fast Similarity Search via Optimal Sparse Lifting
neurips,2018,2,142,Yin,Zhang,cuhk,"The Chinese University of Hong Kong, Shenzhen",shuguangcui@cuhk.edu.cn,Fast Similarity Search via Optimal Sparse Lifting
neurips,2018,3,142,Shuguang,Cui,cuhk,"The Chinese University of Hong Kong, Shenzhen",216019005@link.cuhk.edu.cn,Fast Similarity Search via Optimal Sparse Lifting
neurips,2018,0,2051,Raman,Arora,,Johns Hopkins University,,Differentially Private Robust Low-Rank Approximation
neurips,2018,1,2051,Vladimir,braverman,,Johns Hopkins University,,Differentially Private Robust Low-Rank Approximation
neurips,2018,2,2051,Jalaj,Upadhyay,,Johns Hopkins University,,Differentially Private Robust Low-Rank Approximation
neurips,2018,0,1625,Murat,Sensoy,ozyegin,Ozyegin University,murat.sensoy@ozyegin.edu.tr,Evidential Deep Learning to Quantify Classification Uncertainty
neurips,2018,1,1625,Lance,Kaplan,ieee,U.S. Army Research Laboratory,lkaplan@ieee.org,Evidential Deep Learning to Quantify Classification Uncertainty
neurips,2018,2,1625,Melih,Kandemir,bosch,Bosch Center for Artificial Intelligence (BCAI),melih.kandemir@bosch.com,Evidential Deep Learning to Quantify Classification Uncertainty
neurips,2018,0,585,Omer,Ben-Porat,,Technion  Israel Institute of Technology,omerbp@campus,A Game-Theoretic Approach to Recommendation Systems with Strategic Content Providers
neurips,2018,1,585,Moshe,Tennenholtz,technion,Technion--Israel Institute of Technology,moshe@ie.technion.ac.il,A Game-Theoretic Approach to Recommendation Systems with Strategic Content Providers
neurips,2018,0,560,Zhenhua,Liu,pku,Peking University,liu-zh@pku.edu.cn,Frequency-Domain Dynamic Pruning for Convolutional Neural Networks
neurips,2018,1,560,Jizheng,Xu,microsoft,Bytedance Inc.,jzxu@microsoft.com,Frequency-Domain Dynamic Pruning for Convolutional Neural Networks
neurips,2018,2,560,Xiulian,Peng,microsoft,Microsoft Research,xipe@microsoft.com,Frequency-Domain Dynamic Pruning for Convolutional Neural Networks
neurips,2018,3,560,Ruiqin,Xiong,pku,Peking University,rqxiong@pku.edu.cn,Frequency-Domain Dynamic Pruning for Convolutional Neural Networks
neurips,2018,0,5353,Jung-Su,Ha,lics,KAIST,jsha@lics.,Adaptive Path-Integral Autoencoders: Representation Learning and Planning for Dynamical Systems
neurips,2018,1,5353,Young-Jin,Park,lics,KAIST,yjpark@lics.,Adaptive Path-Integral Autoencoders: Representation Learning and Planning for Dynamical Systems
neurips,2018,2,5353,Hyeok-Joo,Chae,lics,KAIST,hjchae@lics.,Adaptive Path-Integral Autoencoders: Representation Learning and Planning for Dynamical Systems
neurips,2018,3,5353,Soon-Seo,Park,lics,KAIST,sspark@lics.,Adaptive Path-Integral Autoencoders: Representation Learning and Planning for Dynamical Systems
neurips,2018,4,5353,Han-Lim,Choi,kaist,Korea Advanced Institute of Science and Technology,hanlimc@kaist.ac.kr,Adaptive Path-Integral Autoencoders: Representation Learning and Planning for Dynamical Systems
neurips,2018,0,6492,Clément,Canonne,stanford,Stanford University,ccanonne@stanford.edu,Testing for Families of Distributions via the Fourier Transform
neurips,2018,1,6492,Ilias,Diakonikolas,usc,University of Southern California,diakonik@usc.edu,Testing for Families of Distributions via the Fourier Transform
neurips,2018,2,6492,Alistair,Stewart,gmail,University of Southern California,stewart.al@gmail.com,Testing for Families of Distributions via the Fourier Transform
neurips,2018,0,358,Christian,Kroer,,"Faceook, Core Data Science",,A Unified Framework for Extensive-Form Game Abstraction with Bounds
neurips,2018,1,358,Tuomas,Sandholm,,Carnegie Mellon University,,A Unified Framework for Extensive-Form Game Abstraction with Bounds
neurips,2018,0,3534,Raef,Bassily,,The Ohio State University,,Model-Agnostic Private Learning
neurips,2018,1,3534,Om,Thakkar,,Boston University,,Model-Agnostic Private Learning
neurips,2018,2,3534,Abhradeep,Guha Thakurta,,University of California Santa Cruz,,Model-Agnostic Private Learning
neurips,2018,0,3748,Sandeep,Subramanian,umontreal,University of Montreal,2sandeep.subramanian.1@umontreal.ca,Towards Text Generation with Adversarially Learned Neural Outlines
neurips,2018,1,3748,Sai Rajeswar,Mudumba,umontreal,University of Montreal,sai.rajeswar.mudumba@umontreal.ca,Towards Text Generation with Adversarially Learned Neural Outlines
neurips,2018,2,3748,Alessandro,Sordoni,umontreal,Microsoft Research Montreal,aaron.courville@umontreal.ca,Towards Text Generation with Adversarially Learned Neural Outlines
neurips,2018,3,3748,Adam,Trischler,polymtl,Microsoft,3christopher.pal@polymtl.ca,Towards Text Generation with Adversarially Learned Neural Outlines
neurips,2018,4,3748,Aaron,Courville,microsoft,U. Montreal,4alsordon@microsoft.com,Towards Text Generation with Adversarially Learned Neural Outlines
neurips,2018,5,3748,Chris,Pal,microsoft,"MILA, Polytechnique Montréal, Element AI",adam.trischler@microsoft.com,Towards Text Generation with Adversarially Learned Neural Outlines
neurips,2018,0,5394,Aditya,Kusupati,microsoft,Microsoft Research India,t-vekusu@microsoft.com,"FastGRNN: A Fast, Accurate, Stable and Tiny Kilobyte Sized Gated Recurrent Neural Network"
neurips,2018,1,5394,Manish,Singh,microsoft,Indian Institute of Technology Delhi,prajain@microsoft.com,"FastGRNN: A Fast, Accurate, Stable and Tiny Kilobyte Sized Gated Recurrent Neural Network"
neurips,2018,2,5394,Kush,Bhatia,microsoft,UC Berkeley,manik@microsoft.com,"FastGRNN: A Fast, Accurate, Stable and Tiny Kilobyte Sized Gated Recurrent Neural Network"
neurips,2018,3,5394,Ashish,Kumar,gmail,UC Berkeley,singhmanishiitd@gmail.com,"FastGRNN: A Fast, Accurate, Stable and Tiny Kilobyte Sized Gated Recurrent Neural Network"
neurips,2018,4,5394,Prateek,Jain,berkeley,Microsoft Research,kush@cs.berkeley.edu,"FastGRNN: A Fast, Accurate, Stable and Tiny Kilobyte Sized Gated Recurrent Neural Network"
neurips,2018,5,5394,Manik,Varma,berkeley,Microsoft Research India,ashish_kumar@berkeley.edu,"FastGRNN: A Fast, Accurate, Stable and Tiny Kilobyte Sized Gated Recurrent Neural Network"
neurips,2018,0,1910,Stefan,Neumann,univie,University of Vienna,stefan.neumann@univie.ac.at,Bipartite Stochastic Block Models with Tiny Clusters
neurips,2018,0,836,Mingsheng,Long,tsinghua,Tsinghua University,mingsheng@tsinghua.edu.cn,Conditional Adversarial Domain Adaptation
neurips,2018,1,836,ZHANGJIE,CAO,tsinghua,Stanford University,jimwang@tsinghua.edu.cn,Conditional Adversarial Domain Adaptation
neurips,2018,2,836,Jianmin,Wang,gmail,Tsinghua University,caozhangjie14@gmail.com,Conditional Adversarial Domain Adaptation
neurips,2018,3,836,Michael,Jordan,berkeley,UC Berkeley,jordan@berkeley.edu,Conditional Adversarial Domain Adaptation
neurips,2018,0,4930,Jianfei,Chen,,RealAI,chenjian14@mails,Stochastic Expectation Maximization with Variance Reduction
neurips,2018,1,4930,Jun,Zhu,tsinghua,Tsinghua University,dcszj@.tsinghua.edu.cn,Stochastic Expectation Maximization with Variance Reduction
neurips,2018,2,4930,Yee Whye,Teh,ox,"University of Oxford, DeepMind",y.w.teh@stats.ox.ac.uk,Stochastic Expectation Maximization with Variance Reduction
neurips,2018,3,4930,Tong,Zhang,tongzhang-ml,,tongzhang@tongzhang-ml.org,Stochastic Expectation Maximization with Variance Reduction
neurips,2018,0,6512,Felipe,Tobar,uchile,Universidad de Chile,ftobar@dim.uchile.cl,Bayesian Nonparametric Spectral Estimation
neurips,2018,0,3551,Kimin,Lee,,Korea Advanced Institute of Science and Technology,,A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks
neurips,2018,1,3551,Kibok,Lee,,University of Michigan,,A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks
neurips,2018,2,3551,Honglak,Lee,,Google / U. Michigan,,A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks
neurips,2018,3,3551,Jinwoo,Shin,,KAIST; AITRICS,,A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks
neurips,2018,0,1162,Robert,Hannah,,UCLA,,Breaking the Span Assumption Yields Fast Finite-Sum Minimization
neurips,2018,1,1162,Yanli,Liu,,UCLA,,Breaking the Span Assumption Yields Fast Finite-Sum Minimization
neurips,2018,2,1162,Daniel,O'Connor,,UCLA,,Breaking the Span Assumption Yields Fast Finite-Sum Minimization
neurips,2018,3,1162,Wotao,Yin,,"University of California, Los Angeles",,Breaking the Span Assumption Yields Fast Finite-Sum Minimization
neurips,2018,0,5326,Rachel,Cummings,gatech,Georgia Tech,rachelc@gatech.edu,Differential Privacy for Growing Databases
neurips,2018,1,5326,Sara,Krehbiel,gatech,University of Richmond,kevinlai@gatech.edu,Differential Privacy for Growing Databases
neurips,2018,2,5326,Kevin,Lai,richmond,Georgia Tech,krehbiel@richmond.edu,Differential Privacy for Growing Databases
neurips,2018,3,5326,Uthaipon,Tantipongpipat,gatech,Georgia Tech,tao@gatech.edu,Differential Privacy for Growing Databases
neurips,2018,0,99,Mrinmaya,Sachan,cmu,Carnegie Mellon University,mrinmays@cs.cmu.edu,Learning Pipelines with Limited Data and Domain Knowledge: A Study in Parsing Physics Problems
neurips,2018,1,99,Kumar Avinava,Dubey,cmu,Carnegie Mellon University,akdubey@cs.cmu.edu,Learning Pipelines with Limited Data and Domain Knowledge: A Study in Parsing Physics Problems
neurips,2018,2,99,Tom,Mitchell,cmu,Carnegie Mellon University,tom.mitchell@cs.cmu.edu,Learning Pipelines with Limited Data and Domain Knowledge: A Study in Parsing Physics Problems
neurips,2018,3,99,Dan,Roth,cmu,UPenn,epxing@cs.cmu.edu,Learning Pipelines with Limited Data and Domain Knowledge: A Study in Parsing Physics Problems
neurips,2018,4,99,Eric,Xing,upenn,Petuum Inc. /  Carnegie Mellon University,danroth@seas.upenn.edu,Learning Pipelines with Limited Data and Domain Knowledge: A Study in Parsing Physics Problems
neurips,2018,0,6129,Raaz,Dwivedi,berkeley,UC Berkeley,raaz.rsk@berkeley.edu,Theoretical guarantees for EM under misspecified Gaussian mixture models
neurips,2018,1,6129,nht,H,berkeley,"University of California, Berkeley",minhnhat@berkeley.edu,Theoretical guarantees for EM under misspecified Gaussian mixture models
neurips,2018,2,6129,Koulik,Khamaru,berkeley,University Of California Berkeley,koulik@berkeley.edu,Theoretical guarantees for EM under misspecified Gaussian mixture models
neurips,2018,3,6129,Martin,Wainwright,berkeley,UC Berkeley,wainwrig@berkeley.edu,Theoretical guarantees for EM under misspecified Gaussian mixture models
neurips,2018,4,6129,Michael,Jordan,berkeley,UC Berkeley,jordan@berkeley.edu,Theoretical guarantees for EM under misspecified Gaussian mixture models
neurips,2018,0,2718,Elad,Hazan,princeton,Princeton University,ehazan@cs.princeton.edu,Online Improper Learning with an Approximation Oracle
neurips,2018,1,2718,Wei,Hu,princeton,Princeton University,huwei@cs.princeton.edu,Online Improper Learning with an Approximation Oracle
neurips,2018,2,2718,Yuanzhi,Li,stanford,Princeton,yuanzhil@stanford.edu,Online Improper Learning with an Approximation Oracle
neurips,2018,3,2718,Zhiyuan,Li,princeton,Princeton University,zhiyuanli@cs.princeton.edu,Online Improper Learning with an Approximation Oracle
neurips,2018,0,6697,Dan,Hendrycks,berkeley,UC Berkeley,hendrycks@berkeley.edu,Using Trusted Data to Train Deep Networks on Labels Corrupted by Severe Noise
neurips,2018,1,6697,Mantas,Mazeika,ttic,University of Chicago,mantas@ttic.edu,Using Trusted Data to Train Deep Networks on Labels Corrupted by Severe Noise
neurips,2018,2,6697,Duncan,Wilson,unr,Leap Motion,duncanw@nevada.unr.edu,Using Trusted Data to Train Deep Networks on Labels Corrupted by Severe Noise
neurips,2018,3,6697,Kevin,Gimpel,ttic,,kgimpel@ttic.edu,Using Trusted Data to Train Deep Networks on Labels Corrupted by Severe Noise
neurips,2018,0,2947,Xiaoxi,He,ethz,ETH Zürich,hex@ethz.ch,Multi-Task Zipping via Layer-wise Neuron Sharing
neurips,2018,1,2947,Zimu,Zhou,ethz,ETH Zurich,zzhou@tik.ee.ethz.ch,Multi-Task Zipping via Layer-wise Neuron Sharing
neurips,2018,2,2947,Lothar,Thiele,ethz,ETH Zürich,thiele@ethz.ch,Multi-Task Zipping via Layer-wise Neuron Sharing
neurips,2018,0,2833,Stepan,Tulyakov,epfl,École polytechnique fédérale de Lausanne (EPFL),stepan.tulyakov@epfl.ch,Practical Deep Stereo (PDS): Toward applications-friendly deep stereo matching
neurips,2018,1,2833,Anton,Ivanov,epfl,EPFL,anton.ivanov@epfl.ch,Practical Deep Stereo (PDS): Toward applications-friendly deep stereo matching
neurips,2018,2,2833,François,Fleuret,idiap,Idiap Research Institute,francois.fleuret@idiap.ch,Practical Deep Stereo (PDS): Toward applications-friendly deep stereo matching
neurips,2018,0,2820,Bo,Han,,RIKEN & UTS,,Masking: A New Perspective of Noisy Supervision
neurips,2018,1,2820,Jiangchao,Yao,,Shanghai Jiao Tong University,,Masking: A New Perspective of Noisy Supervision
neurips,2018,2,2820,Gang,Niu,,RIKEN,,Masking: A New Perspective of Noisy Supervision
neurips,2018,3,2820,Mingyuan,Zhou,,University of Texas at Austin,,Masking: A New Perspective of Noisy Supervision
neurips,2018,4,2820,Ivor,Tsang,,"University of Technology, Sydney",,Masking: A New Perspective of Noisy Supervision
neurips,2018,5,2820,Ya,Zhang,,"Cooperative Medianet Innovation Center, Shang hai Jiao Tong University",,Masking: A New Perspective of Noisy Supervision
neurips,2018,6,2820,Masashi,Sugiyama,,RIKEN / University of Tokyo,,Masking: A New Perspective of Noisy Supervision
neurips,2018,0,2784,Yu,Zhang,gmail,HKUST,yu.zhang.ust@gmail.com,Learning to Multitask
neurips,2018,1,2784,Ying,Wei,tencent,Tencent AI Lab,judywei@tencent.com,Learning to Multitask
neurips,2018,2,2784,Qiang,Yang,ust,Hong Kong University of Science and Technology,qyang@cse.ust.hk,Learning to Multitask
neurips,2018,0,6494,Mitali,Bafna,harvard,Harvard University,mitalibafna@g.harvard.edu,Thwarting Adversarial Examples: An $L_0$-Robust Sparse Fourier Transform
neurips,2018,1,6494,Jack,Murtagh,harvard,Harvard University,jmurtagh@g.harvard.edu,Thwarting Adversarial Examples: An $L_0$-Robust Sparse Fourier Transform
neurips,2018,2,6494,Nikhil,Vyas,mit,MIT,nikhilv@mit.edu,Thwarting Adversarial Examples: An $L_0$-Robust Sparse Fourier Transform
neurips,2018,0,3695,Zakaria,Mhammedi,anu,The Australian National University,zak.mhammedi@anu.edu.au,"Constant Regret, Generalized Mixability, and Mirror Descent"
neurips,2018,1,3695,Robert,Williamson,anu,Australian National University & Data61,bob.williamson@anu.edu.au,"Constant Regret, Generalized Mixability, and Mirror Descent"
neurips,2018,0,1105,Zhihui,Zhu,jhu,Johns Hopkins University,zzhu29@jhu.edu,Dual Principal Component Pursuit: Improved Analysis and Efficient Algorithms
neurips,2018,1,1105,Yifan,Wang,shanghaitech,University of Washington,wangyf@shanghaitech.edu.cn,Dual Principal Component Pursuit: Improved Analysis and Efficient Algorithms
neurips,2018,2,1105,Daniel,Robinson,jhu,Johns Hopkins University,daniel.p.robinson@jhu.edu,Dual Principal Component Pursuit: Improved Analysis and Efficient Algorithms
neurips,2018,3,1105,Daniel,Naiman,jhu,Johns Hopkins University,daniel.naiman@jhu.edu,Dual Principal Component Pursuit: Improved Analysis and Efficient Algorithms
neurips,2018,4,1105,René,Vidal,jhu,Johns Hopkins University,rvidal@jhu.edu,Dual Principal Component Pursuit: Improved Analysis and Efficient Algorithms
neurips,2018,5,1105,Manolis,Tsakiris,shanghaitech,ShanghaiTech University,mtsakiris@shanghaitech.edu.cn,Dual Principal Component Pursuit: Improved Analysis and Efficient Algorithms
neurips,2018,0,3723,Namrata,Anand,stanford,Stanford University,namrataa@stanford.edu,Generative modeling for protein structures
neurips,2018,1,3723,Possu,Huang,stanford,Stanford University,possu@stanford.edu,Generative modeling for protein structures
neurips,2018,0,699,Austin,Benson,cornell,Cornell University,arb@cs.cornell.edu,Found Graph Data and Planted Vertex Covers
neurips,2018,1,699,Jon,Kleinberg,cornell,Cornell University,kleinber@cs.cornell.edu,Found Graph Data and Planted Vertex Covers
neurips,2018,0,1546,Flavio,Figueiredo,ufmg,Universidade Federal de Minas Gerais,flaviovdf@dcc.ufmg.br,Fast Estimation of Causal Interactions using Wold Processes
neurips,2018,1,1546,Guilherme,Resende Borges,ufmg,Universidade Federal de Minas Gerais,guilherme.borges@dcc.ufmg.br,Fast Estimation of Causal Interactions using Wold Processes
neurips,2018,2,1546,Pedro,O.S. Vaz de Melo,ufmg,"Universidade Federal de Minas Gerais, Brazil",olmo@dcc.ufmg.br,Fast Estimation of Causal Interactions using Wold Processes
neurips,2018,3,1546,Renato,Assunção,ufmg,UFMG,assuncao@dcc.ufmg.br,Fast Estimation of Causal Interactions using Wold Processes
neurips,2018,0,853,Edouard,Pauwels,,IRIT,,Relating Leverage Scores and Density using Regularized Christoffel Functions
neurips,2018,1,853,Francis,Bach,,INRIA - Ecole Normale Superieure,,Relating Leverage Scores and Density using Regularized Christoffel Functions
neurips,2018,2,853,Jean-Philippe,Vert,,Google,,Relating Leverage Scores and Density using Regularized Christoffel Functions
neurips,2018,0,3218,Kfir Y.,Levy,ethz,ETH,yehuda.levy@inf.ethz.ch,"Online Adaptive Methods, Universality and Acceleration"
neurips,2018,1,3218,Alp,Yurtsever,epfl,EPFL,alp.yurtsever@epfl.ch,"Online Adaptive Methods, Universality and Acceleration"
neurips,2018,2,3218,Volkan,Cevher,epfl,EPFL,volkan.cevher@epfl.ch,"Online Adaptive Methods, Universality and Acceleration"
neurips,2018,0,2657,Wonyeol,Lee,kaist,KAIST,wonyeol@kaist.ac.kr,Reparameterization Gradient for Non-differentiable Models
neurips,2018,1,2657,Hangyeol,Yu,kaist,KAIST,yhk1344@kaist.ac.kr,Reparameterization Gradient for Non-differentiable Models
neurips,2018,2,2657,Hongseok,Yang,kaist,KAIST,hongseok.yang@kaist.ac.kr,Reparameterization Gradient for Non-differentiable Models
neurips,2018,0,2435,Edoardo,Conti,,Facebook AML,,Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents
neurips,2018,1,2435,Vashisht,Madhavan,,Uber,,Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents
neurips,2018,2,2435,Felipe,Petroski Such,,Uber AI Labs,,Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents
neurips,2018,3,2435,Joel,Lehman,,Uber AI Labs,,Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents
neurips,2018,4,2435,Kenneth,Stanley,,Uber AI Labs and University of Central Florida,,Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents
neurips,2018,5,2435,Jeff,Clune,,Uber AI Labs,,Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents
neurips,2018,0,1561,Jean-Bastien,Grill,google,Google DeepMind,jbgrill@google.com,Optimistic optimization of a Brownian
neurips,2018,1,1561,Michal,Valko,inria,Inria Lille - Nord Europe,michal.valko@inria.fr,Optimistic optimization of a Brownian
neurips,2018,2,1561,Remi,Munos,google,DeepMind,munos@google.com,Optimistic optimization of a Brownian
neurips,2018,0,750,Cheng,Zhang,fredhutch,Fred Hutchinson Cancer Research Center,chengz23@fredhutch.org,Generalizing Tree Probability Estimation via Bayesian Networks
neurips,2018,1,750,Frederick A,Matsen IV,fredhutch,Fred Hutchinson Cancer Research Center,matsen@fredhutch.org,Generalizing Tree Probability Estimation via Bayesian Networks
neurips,2018,0,1441,Christoph,Zimmer,bosch,Bosch Center for Artificial Intelligence,christoph.zimmer@de.bosch.com,Safe Active Learning for Time-Series Modeling with Gaussian Processes
neurips,2018,1,1441,Mona,Meister,bosch,Robert Bosch GmbH,mona.meister@de.bosch.com,Safe Active Learning for Time-Series Modeling with Gaussian Processes
neurips,2018,2,1441,Duy,Nguyen-Tuong,bosch,Bosch Center for AI,duy.nguyen-tuong@de.bosch.com,Safe Active Learning for Time-Series Modeling with Gaussian Processes
neurips,2018,0,2789,Gennaro,Auricchio,universitadipavia,University of Pavia,gennaro.auricchio01@universitadipavia.it,Computing Kantorovich-Wasserstein Distances on $d$-dimensional histograms using $(d+1)$-partite graphs
neurips,2018,1,2789,Federico,Bassetti,unipv,Politecnico di Milano,stefano.gualandi@unipv.it,Computing Kantorovich-Wasserstein Distances on $d$-dimensional histograms using $(d+1)$-partite graphs
neurips,2018,2,2789,Stefano,Gualandi,unipv,University of Pavia,marco.veneroni@unipv.it,Computing Kantorovich-Wasserstein Distances on $d$-dimensional histograms using $(d+1)$-partite graphs
neurips,2018,3,2789,Marco,Veneroni,polimi,University of Pavia,federico.bassetti@polimi.it,Computing Kantorovich-Wasserstein Distances on $d$-dimensional histograms using $(d+1)$-partite graphs
neurips,2018,0,2093,Seyed Mehran,Kazemi,ubc,University of British Columbia,smkazemi@cs.ubc.ca,SimplE Embedding for Link Prediction in Knowledge Graphs
neurips,2018,1,2093,David,Poole,ubc,University of British Columbia,poole@cs.ubc.ca,SimplE Embedding for Link Prediction in Knowledge Graphs
neurips,2018,0,6693,Rafael,Frongillo,colorado,CU Boulder,raf@colorado.edu,Bounded-Loss Private Prediction Markets
neurips,2018,1,6693,Bo,Waggoner,colorado,Microsoft,bwag@colorado.edu,Bounded-Loss Private Prediction Markets
neurips,2018,0,5008,Jonathan,Kadmon,stanford,Stanford University,kadmonj@stanford.edu,Statistical mechanics of low-rank tensor decomposition
neurips,2018,1,5008,Surya,Ganguli,stanford,Stanford,sganguli@stanford.edu,Statistical mechanics of low-rank tensor decomposition
neurips,2018,0,1239,Cedric,Josz,gmail,UC Berkeley,cedric.josz@gmail.com,A theory on the absence of spurious solutions for nonconvex and nonsmooth optimization
neurips,2018,1,1239,Yi,Ouyang,gmail,Preferred Networks,ouyangyii@gmail.com,A theory on the absence of spurious solutions for nonconvex and nonsmooth optimization
neurips,2018,2,1239,Richard,Zhang,berkeley,"University of California, Berkeley",ryz@berkeley.edu,A theory on the absence of spurious solutions for nonconvex and nonsmooth optimization
neurips,2018,3,1239,Javad,Lavaei,berkeley,"University of California, Berkeley",lavaei@berkeley.edu,A theory on the absence of spurious solutions for nonconvex and nonsmooth optimization
neurips,2018,4,1239,Somayeh,Sojoudi,berkeley,"University of California, Berkeley",sojoudi@berkeley.edu,A theory on the absence of spurious solutions for nonconvex and nonsmooth optimization
neurips,2018,0,5380,Anna,Korba,,TELECOM PARISTECH,,A Structured Prediction Approach for Label Ranking
neurips,2018,1,5380,Alexandre,Garcia,,Telecom ParisTech,,A Structured Prediction Approach for Label Ranking
neurips,2018,2,5380,Florence,d'Alché-Buc,,"LTCI,Télécom ParisTech, University of Paris-Saclay",,A Structured Prediction Approach for Label Ranking
neurips,2018,0,153,Mark,Rowland,cam,University of Cambridge,mr504@cam.ac.uk,Geometrically Coupled Monte Carlo Sampling
neurips,2018,1,153,Krzysztof,Choromanski,google,Google Brain Robotics,kchoro@google.com,Geometrically Coupled Monte Carlo Sampling
neurips,2018,2,153,François,Chalus,gmail,Credit Suisse & University of Cambridge,chalusf3@gmail.com,Geometrically Coupled Monte Carlo Sampling
neurips,2018,3,153,Aldo,Pacchiano,berkeley,UC Berkeley,pacchiano@berkeley.edu,Geometrically Coupled Monte Carlo Sampling
neurips,2018,4,153,Tamas,Sarlos,google,Google Research,stamas@google.com,Geometrically Coupled Monte Carlo Sampling
neurips,2018,5,153,Richard,Turner,cam,University of Cambridge,ret26@cam.ac.uk,Geometrically Coupled Monte Carlo Sampling
neurips,2018,6,153,Adrian,Weller,cam,University of Cambridge,aw665@cam.ac.uk,Geometrically Coupled Monte Carlo Sampling
neurips,2018,0,657,Zeyuan,Allen-Zhu,mit,Microsoft Research,zeyuan@csail.mit.edu,The Lingering of Gradients: How to Reuse Gradients Over Time
neurips,2018,1,657,David,Simchi-Levi,mit,MIT,dslevi@mit.edu,The Lingering of Gradients: How to Reuse Gradients Over Time
neurips,2018,2,657,Xinshang,Wang,mit,MIT,xinshang@mit.edu,The Lingering of Gradients: How to Reuse Gradients Over Time
neurips,2018,0,4941,Wenruo,Bai,uw,University of Washington,wrbai@uw.edu,Submodular Maximization via Gradient Ascent: The Case of Deep Submodular   Functions
neurips,2018,1,4941,William,Stafford Noble,uw,University of Washington,wnoble@uw.edu,Submodular Maximization via Gradient Ascent: The Case of Deep Submodular   Functions
neurips,2018,2,4941,Jeff,Bilmes,uw,"University of Washington, Seattle",bilmes@uw.edu,Submodular Maximization via Gradient Ascent: The Case of Deep Submodular   Functions
neurips,2018,0,2188,Sebastian,Stich,,EPFL,,Sparsified SGD with Memory
neurips,2018,1,2188,Jean-Baptiste,Cordonnier,,EPFL,,Sparsified SGD with Memory
neurips,2018,2,2188,Martin,Jaggi,,EPFL,,Sparsified SGD with Memory
neurips,2018,0,1881,Yi,Zhou,,The Ohio State University,,Convergence of Cubic Regularization for Nonconvex Optimization under KL Property
neurips,2018,1,1881,Zhe,Wang,,Ohio State University,,Convergence of Cubic Regularization for Nonconvex Optimization under KL Property
neurips,2018,2,1881,Yingbin,Liang,,The Ohio State University,,Convergence of Cubic Regularization for Nonconvex Optimization under KL Property
neurips,2018,0,1253,Gregory,Plumb,cmu,CMU,gdplumb@andrew.cmu.edu,Model Agnostic Supervised Local Explanations
neurips,2018,1,1253,Denali,Molitor,ucla,"University of California, Los Angeles",dmolitor@math.ucla.edu,Model Agnostic Supervised Local Explanations
neurips,2018,2,1253,Ameet,Talwalkar,cmu,CMU,talwalkar@cmu.edu,Model Agnostic Supervised Local Explanations
neurips,2018,0,2777,Jianqiao,Zhu,warwick,University of Warwick,j.zhu@warwick.ac.uk,Mental Sampling in Multimodal Representations
neurips,2018,1,2777,Adam,Sanborn,warwick,University of Warwick,a.n.sanborn@warwick.ac.uk,Mental Sampling in Multimodal Representations
neurips,2018,2,2777,Nick,Chater,wbs,Warwick Business School,nick.chater@wbs.ac.uk,Mental Sampling in Multimodal Representations
neurips,2018,0,1058,Simon,Lyddon,ox,University of Oxford,lyddon@stats.ox.ac.uk,Nonparametric learning from Bayesian models with randomized objective functions
neurips,2018,1,1058,Stephen,Walker,utexas,University of Texas at Austin,s.g.walker@math.utexas.edu,Nonparametric learning from Bayesian models with randomized objective functions
neurips,2018,2,1058,Chris,Holmes,ox,University of Oxford,cholmes@stats.ox.ac.uk,Nonparametric learning from Bayesian models with randomized objective functions
neurips,2018,0,496,Zi,Yin,gmail,Stanford University,s0960974@gmail.com,On the Dimensionality of Word Embedding
neurips,2018,1,496,Yuanyuan,Shen,microsoft,Stanford University & Microsoft,Yuanyuan.Shen@microsoft.com,On the Dimensionality of Word Embedding
neurips,2018,0,6405,Theo,Lacombe,inria,Inria Saclay,theo.lacombe@inria.fr,Large Scale computation of Means and Clusters for Persistence Diagrams using Optimal Transport
neurips,2018,1,6405,Marco,Cuturi,google,"Université Paris-Saclay, CREST - ENSAE",cuturi@google.com,Large Scale computation of Means and Clusters for Persistence Diagrams using Optimal Transport
neurips,2018,2,6405,Steve,OUDOT,inria,inria,steve.oudot@inria.fr,Large Scale computation of Means and Clusters for Persistence Diagrams using Optimal Transport
neurips,2018,0,1693,Nicolo,Fusi,microsoft,Microsoft Research,nfusi@microsoft.com,Probabilistic Matrix Factorization for Automated Machine Learning
neurips,2018,1,1693,Rishit,Sheth,microsoft,Microsoft Research New England,rishet@microsoft.com,Probabilistic Matrix Factorization for Automated Machine Learning
neurips,2018,2,1693,Melih,Elibol,berkeley,UC Berkeley,elibol@cs.berkeley.edu,Probabilistic Matrix Factorization for Automated Machine Learning
neurips,2018,0,3646,Yu-Shao,Peng,htc,HTC Research,ys_peng@htc.com,REFUEL: Exploring Sparse Features in Deep Reinforcement Learning for Fast Disease Diagnosis
neurips,2018,1,3646,Kai-Fu,Tang,htc,HTC Research,kevin_tang@htc.com,REFUEL: Exploring Sparse Features in Deep Reinforcement Learning for Fast Disease Diagnosis
neurips,2018,2,3646,Hsuan-Tien,Lin,ntu,Appier/National Taiwan University,htlin@csie.ntu.edu.tw,REFUEL: Exploring Sparse Features in Deep Reinforcement Learning for Fast Disease Diagnosis
neurips,2018,3,3646,Edward,Chang,htc,,edward_chang@htc.com,REFUEL: Exploring Sparse Features in Deep Reinforcement Learning for Fast Disease Diagnosis
neurips,2018,0,4892,Dominik,Linzner,tu-darmstadt,TU Darmstadt,dominik.linzner@bcs.tu-darmstadt.de,Cluster Variational Approximations for Structure Learning of Continuous-Time Bayesian Networks from Incomplete Data
neurips,2018,1,4892,Heinz,Koeppl,tu-darmstadt,Technische Universität Darmstadt,heinz.koeppl@bcs.tu-darmstadt.de,Cluster Variational Approximations for Structure Learning of Continuous-Time Bayesian Networks from Incomplete Data
neurips,2018,0,1538,Xiao,Yan,cuhk,The Chinese University of Hong Kong,xyan@cse.cuhk.edu.hk,Norm-Ranging LSH for Maximum Inner Product Search
neurips,2018,1,1538,Jinfeng,Li,cuhk,The Chinese University of Hong Kong,jfli@cse.cuhk.edu.hk,Norm-Ranging LSH for Maximum Inner Product Search
neurips,2018,2,1538,Xinyan,Dai,cuhk,The Chinese University of Hong Kong,xydai@cse.cuhk.edu.hk,Norm-Ranging LSH for Maximum Inner Product Search
neurips,2018,3,1538,Hongzhi,Chen,cuhk,CUHK,hzchen@cse.cuhk.edu.hk,Norm-Ranging LSH for Maximum Inner Product Search
neurips,2018,4,1538,James,Cheng,cuhk,The Chinese University of Hong Kong,jcheng@cse.cuhk.edu.hk,Norm-Ranging LSH for Maximum Inner Product Search
neurips,2018,0,6577,Boris,Muzellec,ensae,ENSAE ParisTech,boris.muzellec@ensae.fr,Generalizing Point Embeddings using the Wasserstein Space of Elliptical Distributions
neurips,2018,1,6577,Marco,Cuturi,google,"Université Paris-Saclay, CREST - ENSAE",cuturi@google.com,Generalizing Point Embeddings using the Wasserstein Space of Elliptical Distributions
neurips,2018,0,2935,Dimitrios,Milios,eurecom,EURECOM,dimitrios.milios@eurecom.fr,Dirichlet-based Gaussian Processes for Large-scale Calibrated Classification
neurips,2018,1,2935,Raffaello,Camoriano,eurecom,Istituto Italiano di Tecnologia,pietro.michiardi@eurecom.fr,Dirichlet-based Gaussian Processes for Large-scale Calibrated Classification
neurips,2018,2,2935,Pietro,Michiardi,iit,EURECOM,raffaello.camoriano@iit.it,Dirichlet-based Gaussian Processes for Large-scale Calibrated Classification
neurips,2018,3,2935,Lorenzo,Rosasco,mit,University of Genova- MIT - IIT,lrosasco@mit.edu,Dirichlet-based Gaussian Processes for Large-scale Calibrated Classification
neurips,2018,4,2935,Maurizio,Filippone,eurecom,EURECOM,maurizio.filippone@eurecom.fr,Dirichlet-based Gaussian Processes for Large-scale Calibrated Classification
neurips,2018,0,6253,Yuntian,Deng,,Harvard University,dengyuntian@seas,Latent Alignment and Variational Attention
neurips,2018,1,6253,Yoon,Kim,,Harvard University,yoonkim@seas,Latent Alignment and Variational Attention
neurips,2018,2,6253,Justin,Chiu,,Harvard University,justinchiu@g,Latent Alignment and Variational Attention
neurips,2018,3,6253,Demi,Guo,,Harvard,dguo@college,Latent Alignment and Variational Attention
neurips,2018,4,6253,Alexander,Rush,harvard,Harvard,srush@seas.harvard.edu,Latent Alignment and Variational Attention
neurips,2018,0,902,Jesse,Krijthe,gmail,Radboud University Nijmegen,jkrijthe@gmail.com,The Pessimistic Limits and Possibilities of Margin-based Losses in Semi-supervised Learning
neurips,2018,1,902,Marco,Loog,tudelft,Delft University of Technology,m.loog@tudelft.nl,The Pessimistic Limits and Possibilities of Margin-based Losses in Semi-supervised Learning
neurips,2018,0,2338,Soheil,Feizi,umd,"University of Maryland, College Park",sfeizi@cs.umd.edu,Porcupine Neural Networks: Approximating Neural Network Landscapes
neurips,2018,1,2338,Hamid,Javadi,rice,Stanford University,hrhakim@rice.edu,Porcupine Neural Networks: Approximating Neural Network Landscapes
neurips,2018,2,2338,Jesse,Zhang,stanford,Stanford University,dntse@stanford.edu,Porcupine Neural Networks: Approximating Neural Network Landscapes
neurips,2018,3,2338,David,Tse,stanford,Stanford University,jessez@stanford.edu,Porcupine Neural Networks: Approximating Neural Network Landscapes
neurips,2018,0,3233,Huishuai,Zhang,,Microsoft Research Asia,,On the Local Hessian in Back-propagation
neurips,2018,1,3233,Wei,Chen,,Microsoft Research,,On the Local Hessian in Back-propagation
neurips,2018,2,3233,Tie-Yan,Liu,,Microsoft Research Asia,,On the Local Hessian in Back-propagation
neurips,2018,0,1783,Arno,Solin,aalto,Aalto University,arno.solin@aalto.fi,Infinite-Horizon Gaussian Processes
neurips,2018,1,1783,James,Hensman,prowler,PROWLER.io,james@prowler.io,Infinite-Horizon Gaussian Processes
neurips,2018,2,1783,Richard,Turner,cam,University of Cambridge,ret26@cam.ac.uk,Infinite-Horizon Gaussian Processes
neurips,2018,0,4855,Qi,Liu,nus,Facebook AI Research,qiliu@u.nus.edu,Constrained Graph Variational Autoencoders for Molecule Design
neurips,2018,1,4855,Miltiadis,Allamanis,microsoft,Microsoft Research,miallama@microsoft.com,Constrained Graph Variational Autoencoders for Molecule Design
neurips,2018,2,4855,Marc,Brockschmidt,microsoft,Microsoft Research,mabrocks@microsoft.com,Constrained Graph Variational Autoencoders for Molecule Design
neurips,2018,3,4855,Alexander,Gaunt,microsoft,Microsoft Research,algaunt@microsoft.com,Constrained Graph Variational Autoencoders for Molecule Design
neurips,2018,0,5696,Tao,Chen,cmu,Carnegie Mellon University,taoc1@cs.cmu.edu,Hardware Conditioned Policies for Multi-Robot Transfer Learning
neurips,2018,1,5696,Adithyavairavan,Murali,cmu,Carnegie Mellon University Robotics Institute,amurali@cs.cmu.edu,Hardware Conditioned Policies for Multi-Robot Transfer Learning
neurips,2018,2,5696,Abhinav,Gupta,cmu,Facebook AI Research/CMU,abhinavg@cs.cmu.edu,Hardware Conditioned Policies for Multi-Robot Transfer Learning
neurips,2018,0,5227,Fariborz,Salehi,caltech,California Institute of Technology,fsalehi@caltech.edu,Learning without the Phase: Regularized PhaseMax Achieves Optimal Sample Complexity
neurips,2018,1,5227,Ehsan,Abbasi,caltech,Caltech,eabbasi@caltech.edu,Learning without the Phase: Regularized PhaseMax Achieves Optimal Sample Complexity
neurips,2018,2,5227,Babak,Hassibi,caltech,Caltech,hassibi@caltech.edu,Learning without the Phase: Regularized PhaseMax Achieves Optimal Sample Complexity
neurips,2018,0,412,Emilien,Dupont,slb,Oxford University,dupont@slb.com,Learning Disentangled Joint Continuous and Discrete Representations
neurips,2018,0,3818,Guanhong,Tao,purdue,Purdue University,taog@cs.purdue.edu,Attacks Meet Interpretability: Attribute-steered Detection of Adversarial Samples
neurips,2018,1,3818,Shiqing,Ma,purdue,Purdue University,ma229@cs.purdue.edu,Attacks Meet Interpretability: Attribute-steered Detection of Adversarial Samples
neurips,2018,2,3818,Yingqi,Liu,purdue,Purdue University,liu1751@cs.purdue.edu,Attacks Meet Interpretability: Attribute-steered Detection of Adversarial Samples
neurips,2018,3,3818,Xiangyu,Zhang,purdue,Purdue University,xyzhang@cs.purdue.edu,Attacks Meet Interpretability: Attribute-steered Detection of Adversarial Samples
neurips,2018,0,6532,Giulia,Denevi,,IIT/UNIGE,,Learning To Learn Around A Common Mean
neurips,2018,1,6532,Carlo,Ciliberto,,Imperial College London,,Learning To Learn Around A Common Mean
neurips,2018,2,6532,Dimitris,Stamos,,University College London,,Learning To Learn Around A Common Mean
neurips,2018,3,6532,Massimiliano,Pontil,,IIT & UCL,,Learning To Learn Around A Common Mean
neurips,2018,0,1702,Rasmus,Palm,dtu,Technical University Denmark,rapal@dtu.dk,Recurrent Relational Networks
neurips,2018,1,1702,Ulrich,Paquet,google,DeepMind,upaq@google.com,Recurrent Relational Networks
neurips,2018,2,1702,Ole,Winther,dtu,Technical University of Denmark,olwi@dtu.dk,Recurrent Relational Networks
neurips,2018,0,2527,Erik,Lindgren,utexas,University of Texas at Austin,erikml@utexas.edu,Experimental Design for Cost-Aware Learning of Causal Graphs
neurips,2018,1,2527,Murat,Kocaoglu,ibm,IBM Research,murat@ibm.com,Experimental Design for Cost-Aware Learning of Causal Graphs
neurips,2018,2,2527,Alexandros,Dimakis,utexas,"University of Texas, Austin",dimakis@austin.utexas.edu,Experimental Design for Cost-Aware Learning of Causal Graphs
neurips,2018,3,2527,Sriram,Vishwanath,utexas,University of Texas at Austin,sriram@ece.utexas.edu,Experimental Design for Cost-Aware Learning of Causal Graphs
neurips,2018,0,5798,Michael,Gimelfarb,utoronto,University of Toronto,mike.gimelfarb@mail.utoronto.ca,Reinforcement Learning with Multiple Experts: A Bayesian Model Combination Approach
neurips,2018,1,5798,Scott,Sanner,utoronto,University of Toronto,ssanner@mie.utoronto.ca,Reinforcement Learning with Multiple Experts: A Bayesian Model Combination Approach
neurips,2018,2,5798,Chi-Guhn,Lee,utoronto,University of Toronto,cglee@mie.utoronto.ca,Reinforcement Learning with Multiple Experts: A Bayesian Model Combination Approach
neurips,2018,0,5042,Brandon,Amos,,Carnegie Mellon University,,Differentiable MPC for End-to-end Planning and Control
neurips,2018,1,5042,Ivan,Jimenez,,Georgia Tech,,Differentiable MPC for End-to-end Planning and Control
neurips,2018,2,5042,Jacob,Sacks,,Georgia Institute of Technology,,Differentiable MPC for End-to-end Planning and Control
neurips,2018,3,5042,Byron,Boots,,Georgia Tech / Google Brain,,Differentiable MPC for End-to-end Planning and Control
neurips,2018,4,5042,J. Zico,Kolter,,Carnegie Mellon University / Bosch Center for AI,,Differentiable MPC for End-to-end Planning and Control
neurips,2018,0,1876,Sijia,Liu,,"MIT-IBM Watson AI Lab, IBM Research AI",,Zeroth-Order Stochastic Variance Reduction for Nonconvex Optimization
neurips,2018,1,1876,Bhavya,Kailkhura,,Lawrence Livermore National Lab,,Zeroth-Order Stochastic Variance Reduction for Nonconvex Optimization
neurips,2018,2,1876,Pin-Yu,Chen,,IBM Research AI,,Zeroth-Order Stochastic Variance Reduction for Nonconvex Optimization
neurips,2018,3,1876,Paishun,Ting,,University of Michigan,,Zeroth-Order Stochastic Variance Reduction for Nonconvex Optimization
neurips,2018,4,1876,Shiyu,Chang,,IBM T.J. Watson Research Center,,Zeroth-Order Stochastic Variance Reduction for Nonconvex Optimization
neurips,2018,5,1876,Lisa,Amini,,IBM Research,,Zeroth-Order Stochastic Variance Reduction for Nonconvex Optimization
neurips,2018,0,2486,Aaron,Sidford,stanford,Stanford,sidford@stanford.edu,Near-Optimal Time and Sample Complexities for Solving Markov Decision Processes with a Generative Model
neurips,2018,1,2486,Mengdi,Wang,princeton,Princeton University,mengdiw@princeton.edu,Near-Optimal Time and Sample Complexities for Solving Markov Decision Processes with a Generative Model
neurips,2018,2,2486,Xian,Wu,stanford,Stanford University,xwu20@stanford.edu,Near-Optimal Time and Sample Complexities for Solving Markov Decision Processes with a Generative Model
neurips,2018,3,2486,Lin,Yang,princeton,Princeton University,lin.yang@princeton.edu,Near-Optimal Time and Sample Complexities for Solving Markov Decision Processes with a Generative Model
neurips,2018,4,2486,Yinyu,Ye,stanford,Standord,yyye@stanford.edu,Near-Optimal Time and Sample Complexities for Solving Markov Decision Processes with a Generative Model
neurips,2018,0,3114,Dennis,Leung,uw,University of Southern California,dmhleung@uw.edu,Algebraic tests of general Gaussian latent tree models
neurips,2018,1,3114,Mathias,Drton,uw,University of Washington,md5@uw.edu,Algebraic tests of general Gaussian latent tree models
neurips,2018,0,2861,Takashi,Ishida,ms,"The University of Tokyo, RIKEN, SMAM",ishida@ms.,Binary Classification from Positive-Confidence Data
neurips,2018,1,2861,Gang,Niu,u-tokyo,RIKEN,sugi@k.u-tokyo.ac.jp,Binary Classification from Positive-Confidence Data
neurips,2018,2,2861,Masashi,Sugiyama,riken,RIKEN / University of Tokyo,gang.niu@riken.jp,Binary Classification from Positive-Confidence Data
neurips,2018,0,5066,Catherine,Wong,,MIT,,Transfer Learning with Neural AutoML
neurips,2018,1,5066,Neil,Houlsby,,Google,,Transfer Learning with Neural AutoML
neurips,2018,2,5066,Yifeng,Lu,,,,Transfer Learning with Neural AutoML
neurips,2018,3,5066,Andrea,Gesmundo,,Google,,Transfer Learning with Neural AutoML
neurips,2018,0,5291,Timur,Garipov,,Moscow State University,,"Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs"
neurips,2018,1,5291,Pavel,Izmailov,,Cornell University,,"Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs"
neurips,2018,2,5291,Dmitrii,Podoprikhin,,XTX markets,,"Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs"
neurips,2018,3,5291,Dmitry,Vetrov,,"Higher School of Economics, Samsung AI Center, Moscow",,"Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs"
neurips,2018,4,5291,Andrew,Wilson,,Cornell University,,"Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs"
neurips,2018,0,662,Hoda,Heidari,ethz,ETH Zürich,hheidari@inf.ethz.ch,Fairness Behind a Veil of Ignorance: A Welfare Analysis for Automated Decision Making
neurips,2018,1,662,Claudio,Ferrari,ethz,ETH Zürich,ferraric@ethz.ch,Fairness Behind a Veil of Ignorance: A Welfare Analysis for Automated Decision Making
neurips,2018,2,662,Krishna,Gummadi,mpi-sws,Max Planck Institute for Software Systems,gummadi@mpi-sws.org,Fairness Behind a Veil of Ignorance: A Welfare Analysis for Automated Decision Making
neurips,2018,3,662,Andreas,Krause,ethz,ETH Zurich,krausea@ethz.ch,Fairness Behind a Veil of Ignorance: A Welfare Analysis for Automated Decision Making
neurips,2018,0,2329,Rudy,Bunel,ox,Oxford University,rudy@robots.ox.ac.uk,A Unified View of Piecewise Linear Neural Network Verification
neurips,2018,1,2329,Ilker,Turkaslan,ox,University of Oxford,ilker.turkaslan@lmh.ox.ac.uk,A Unified View of Piecewise Linear Neural Network Verification
neurips,2018,2,2329,Philip,Torr,ox,University of Oxford,philip.torr@eng.ox.ac.uk,A Unified View of Piecewise Linear Neural Network Verification
neurips,2018,3,2329,Pushmeet,Kohli,google,DeepMind,pushmeet@google.com,A Unified View of Piecewise Linear Neural Network Verification
neurips,2018,4,2329,Pawan,Mudigonda,ox,University of Oxford,pawan@robots.ox.ac.uk,A Unified View of Piecewise Linear Neural Network Verification
neurips,2018,0,6609,Nicholas,Gallo,uci,UC Irvine,ngallo1@uci.edu,Lifted Weighted Mini-Bucket
neurips,2018,1,6609,Alexander,Ihler,uci,UC Irvine,ihler@ics.uci.edu,Lifted Weighted Mini-Bucket
neurips,2018,0,2089,Nitin,Bansal,tamu,Texas A&M University,bansa01@tamu.edu,Can We Gain More from Orthogonality Regularizations in Training Deep Networks?
neurips,2018,1,2089,Xiaohan,Chen,tamu,Texas A&M University,chernxh@tamu.edu,Can We Gain More from Orthogonality Regularizations in Training Deep Networks?
neurips,2018,2,2089,Zhangyang,Wang,tamu,TAMU,atlaswang@tamu.edu,Can We Gain More from Orthogonality Regularizations in Training Deep Networks?
neurips,2018,0,758,Yuxin,Chen,,Caltech,,Understanding the Role of Adaptivity in Machine Teaching: The Case of Version Space Learners
neurips,2018,1,758,Adish,Singla,,MPI-SWS,,Understanding the Role of Adaptivity in Machine Teaching: The Case of Version Space Learners
neurips,2018,2,758,Oisin,Mac Aodha,,California Institute of Technology,,Understanding the Role of Adaptivity in Machine Teaching: The Case of Version Space Learners
neurips,2018,3,758,Pietro,Perona,,California Institute of Technology,,Understanding the Role of Adaptivity in Machine Teaching: The Case of Version Space Learners
neurips,2018,4,758,Yisong,Yue,,Caltech,,Understanding the Role of Adaptivity in Machine Teaching: The Case of Version Space Learners
neurips,2018,0,5375,Asad,Haris,uw,University of Washington,aharis@uw.edu,Wavelet regression and additive models for irregularly spaced data
neurips,2018,1,5375,Ali,Shojaie,uw,,nrsimon@uw.edu,Wavelet regression and additive models for irregularly spaced data
neurips,2018,2,5375,Noah,Simon,uw,University of Washington,ashojaie@uw.edu,Wavelet regression and additive models for irregularly spaced data
neurips,2018,0,332,Qibin,Hou,,Nankai University,,Self-Erasing Network for Integral Object Attention
neurips,2018,1,332,PengTao,Jiang,,Nankai University,,Self-Erasing Network for Integral Object Attention
neurips,2018,2,332,Yunchao,Wei,,UIUC,,Self-Erasing Network for Integral Object Attention
neurips,2018,3,332,Ming-Ming,Cheng,,Nankai University,,Self-Erasing Network for Integral Object Attention
neurips,2018,0,1658,Shakarim,Soltanayev,unist,Ulsan National Institute of Science and Technology,shakarim@unist.ac.kr,Training deep learning based denoisers without ground truth data
neurips,2018,1,1658,Se Young,Chun,unist,UNIST,sychun@unist.ac.kr,Training deep learning based denoisers without ground truth data
neurips,2018,0,1286,Sanghack,Lee,purdue,Purdue University,lee2995@purdue.edu,Structural Causal Bandits: Where to Intervene?
neurips,2018,1,1286,Elias,Bareinboim,purdue,Purdue,eb@purdue.edu,Structural Causal Bandits: Where to Intervene?
neurips,2018,0,3793,Georgios,Theocharous,adobe,Adobe Research,theochar@adobe.com,Scalar Posterior Sampling with Applications
neurips,2018,1,3793,Zheng,Wen,adobe,Adobe Research,zwen@adobe.com,Scalar Posterior Sampling with Applications
neurips,2018,2,3793,Yasin,Abbasi Yadkori,adobe,Adobe Research,abbasiya@adobe.com,Scalar Posterior Sampling with Applications
neurips,2018,3,3793,Nikos,Vlassis,netflix,Netflix,nvlassis@netflix.com,Scalar Posterior Sampling with Applications
neurips,2018,0,5940,Gabriele,Farina,,Carnegie Mellon University,,Ex ante coordination and collusion in zero-sum multi-player extensive-form games
neurips,2018,1,5940,Andrea,Celli,,Politecnico di Milano,,Ex ante coordination and collusion in zero-sum multi-player extensive-form games
neurips,2018,2,5940,Nicola,Gatti,,Politecnico di Milano,,Ex ante coordination and collusion in zero-sum multi-player extensive-form games
neurips,2018,3,5940,Tuomas,Sandholm,,Carnegie Mellon University,,Ex ante coordination and collusion in zero-sum multi-player extensive-form games
neurips,2018,0,5367,Scott,Aaronson,utexas,UT Austin,aaronson@cs.utexas.edu,Online Learning of Quantum States
neurips,2018,1,5367,Xinyi,Chen,google,Google Brain,xinyic@google.com,Online Learning of Quantum States
neurips,2018,2,5367,Elad,Hazan,princeton,Princeton University,ehazan@cs.princeton.edu,Online Learning of Quantum States
neurips,2018,3,5367,Satyen,Kale,google,Google,satyenkale@google.com,Online Learning of Quantum States
neurips,2018,4,5367,Ashwin,Nayak,uwaterloo,University of Waterloo,ashwin.nayak@uwaterloo.ca,Online Learning of Quantum States
neurips,2018,0,1645,Avital,Oliver,google,Google Brain,avitalo@google.com,Realistic Evaluation of Deep Semi-Supervised Learning Algorithms
neurips,2018,1,1645,Augustus,Odena,google,Google Brain,augustusodena@google.com,Realistic Evaluation of Deep Semi-Supervised Learning Algorithms
neurips,2018,2,1645,Colin,Raffel,google,Google Brain Resident,craffel@google.com,Realistic Evaluation of Deep Semi-Supervised Learning Algorithms
neurips,2018,3,1645,Ekin Dogus,Cubuk,google,Google Brain,cubuk@google.com,Realistic Evaluation of Deep Semi-Supervised Learning Algorithms
neurips,2018,4,1645,Ian,Goodfellow,google,Google,goodfellow@google.com,Realistic Evaluation of Deep Semi-Supervised Learning Algorithms
neurips,2018,0,442,Guillaume,Bellec,tugraz,Graz University of Technology,bellec@igi.tugraz.at,Long short-term memory and Learning-to-learn in networks of spiking neurons
neurips,2018,1,442,Darjan,Salaj,tugraz,Graz University of Technology,salaj@igi.tugraz.at,Long short-term memory and Learning-to-learn in networks of spiking neurons
neurips,2018,2,442,Anand,Subramoney,tugraz,Graz University of Technology,subramoney@igi.tugraz.at,Long short-term memory and Learning-to-learn in networks of spiking neurons
neurips,2018,3,442,Robert,Legenstein,tugraz,Graz University of Technology,legenstein@igi.tugraz.at,Long short-term memory and Learning-to-learn in networks of spiking neurons
neurips,2018,4,442,Wolfgang,Maass,tugraz,Graz University of Technology,maass@igi.tugraz.at,Long short-term memory and Learning-to-learn in networks of spiking neurons
neurips,2018,0,1125,Pan,Li,,University of Illinois Urbana-Champaign,,Revisiting Decomposable Submodular Function Minimization with Incidence Relations
neurips,2018,1,1125,Olgica,Milenkovic,,University of Illinois at Urbana-Champaign,,Revisiting Decomposable Submodular Function Minimization with Incidence Relations
neurips,2018,0,828,Peng,Jiang,gmail,Shandong University,sdujump@gmail.com,DifNet: Semantic Segmentation by Diffusion Networks
neurips,2018,1,828,Fanglin,Gu,gmail,Shandong University,fanglin.gu@gmail.com,DifNet: Semantic Segmentation by Diffusion Networks
neurips,2018,2,828,Yunhai,Wang,gmail,Shandong University,cloudseawang@gmail.com,DifNet: Semantic Segmentation by Diffusion Networks
neurips,2018,3,828,Changhe,Tu,sdu,Shandong University,chtu@sdu.edu.cn,DifNet: Semantic Segmentation by Diffusion Networks
neurips,2018,4,828,Baoquan,Chen,gmail,Shandong University,baoquan.chen@gmail.com,DifNet: Semantic Segmentation by Diffusion Networks
neurips,2018,0,1357,Medhini,Narasimhan,illinois,UIUC,medhini2@illinois.edu,Out of the Box: Reasoning with Graph Convolution Nets for Factual Visual Question Answering
neurips,2018,1,1357,Svetlana,Lazebnik,illinois,UIUC,slazebni@illinois.edu,Out of the Box: Reasoning with Graph Convolution Nets for Factual Visual Question Answering
neurips,2018,2,1357,Alexander,Schwing,illinois,University of Illinois at Urbana-Champaign,aschwing@illinois.edu,Out of the Box: Reasoning with Graph Convolution Nets for Factual Visual Question Answering
neurips,2018,0,3588,Ilai,Bistritz,stanford,Stanford,bistritz@stanford.edu,Distributed Multi-Player Bandits - a Game of Thrones Approach
neurips,2018,1,3588,Amir,Leshem,biu,Bar-Ilan University,Amir.Leshem@biu.ac.il,Distributed Multi-Player Bandits - a Game of Thrones Approach
neurips,2018,0,3437,David,Eriksson,cornell,Cornell University,kd383@cornell.edu,Scaling Gaussian Process Regression with Derivatives
neurips,2018,1,3437,Kun,Dong,cornell,Cornell University,dme65@cornell.edu,Scaling Gaussian Process Regression with Derivatives
neurips,2018,2,3437,Eric,Lee,cornell,Cornell University,ehl59@cornell.edu,Scaling Gaussian Process Regression with Derivatives
neurips,2018,3,3437,David,Bindel,cornell,Cornell University,bindel@cornell.edu,Scaling Gaussian Process Regression with Derivatives
neurips,2018,4,3437,Andrew,Wilson,cornell,Cornell University,andrew@cornell.edu,Scaling Gaussian Process Regression with Derivatives
neurips,2018,0,979,Shi,Pu,bupt,Beijing University of Posts and Telecommunications,pushi_519200@bupt.edu.cn,Deep Attentive Tracking via Reciprocative Learning
neurips,2018,1,979,Yibing,Song,bupt,Tencent AI Lab,zhhg@bupt.edu.cn,Deep Attentive Tracking via Reciprocative Learning
neurips,2018,2,979,Chao,Ma,gmail,University of Adelaide,dynamicstevenson@gmail.com,Deep Attentive Tracking via Reciprocative Learning
neurips,2018,3,979,Honggang,Zhang,sjtu,Beijing University of Posts and Telecommunications,chaoma@sjtu.edu.cn,Deep Attentive Tracking via Reciprocative Learning
neurips,2018,4,979,Ming-Hsuan,Yang,ucmerced,UC Merced / Google,mhyang@ucmerced.edu,Deep Attentive Tracking via Reciprocative Learning
neurips,2018,0,5877,Andrea,Tacchetti,mit,DeepMind,atacchet@mit.edu,Trading robust representations for sample complexity through self-supervised visual experience
neurips,2018,1,5877,Stephen,Voinea,mit,MIT,voinea@mit.edu,Trading robust representations for sample complexity through self-supervised visual experience
neurips,2018,2,5877,Georgios,Evangelopoulos,mit,"X, Alphabet Inc.",gevang@mit.edu,Trading robust representations for sample complexity through self-supervised visual experience
neurips,2018,0,602,Yanjun,Li,illinois,UIUC,yli145@illinois.edu,Global Geometry of Multichannel Sparse Blind Deconvolution on the Sphere
neurips,2018,1,602,Yoram,Bresler,illinois,University of Illinois,ybresler@illinois.edu,Global Geometry of Multichannel Sparse Blind Deconvolution on the Sphere
neurips,2018,0,2542,Tomoya,Murata,msi,NTT DATA Mathematical Systems Inc.,murata@msi.co.jp,Sample Efficient Stochastic Gradient Iterative Hard Thresholding Method for Stochastic Sparse Linear Regression with Limited Attribute Observation
neurips,2018,1,2542,Taiji,Suzuki,u-tokyo,The University of Tokyo/JST-PRESTO/RIKEN,taiji@mist.i.u-tokyo.ac.jp,Sample Efficient Stochastic Gradient Iterative Hard Thresholding Method for Stochastic Sparse Linear Regression with Limited Attribute Observation
neurips,2018,0,6497,Mitchell,Stern,berkeley,UC Berkeley,mitchell@berkeley.edu,Blockwise Parallel Decoding for Deep Autoregressive Models
neurips,2018,1,6497,Noam,Shazeer,google,Google,usz@google.com,Blockwise Parallel Decoding for Deep Autoregressive Models
neurips,2018,2,6497,Jakob,Uszkoreit,google,Google,noam@google.com,Blockwise Parallel Decoding for Deep Autoregressive Models
neurips,2018,0,1883,Ainesh,Bakshi,cmu,Carnegie Mellon University,abakshi@cs.cmu.edu,Sublinear Time Low-Rank Approximation of Distance Matrices
neurips,2018,1,1883,David,Woodruff,cmu,Carnegie Mellon University,dwoodruf@cs.cmu.edu,Sublinear Time Low-Rank Approximation of Distance Matrices
neurips,2018,0,4842,Bruno,Korbar,dartmouth,Dartmouth Collegue,bruno.18@dartmouth.edu,Cooperative Learning of Audio and Video Models from Self-Supervised Synchronization
neurips,2018,1,4842,Du,Tran,fb,Facebook,trandu@fb.com,Cooperative Learning of Audio and Video Models from Self-Supervised Synchronization
neurips,2018,2,4842,Lorenzo,Torresani,dartmouth,Dartmouth/Facebook,LT@dartmouth.edu,Cooperative Learning of Audio and Video Models from Self-Supervised Synchronization
neurips,2018,0,2101,Abram,Friesen,washington,University of Washington,afriesen@cs.washington.edu,"Submodular Field Grammars: Representation, Inference, and Application to Image Parsing"
neurips,2018,1,2101,Pedro,Domingos,washington,University of Washington,pedrod@cs.washington.edu,"Submodular Field Grammars: Representation, Inference, and Application to Image Parsing"
neurips,2018,0,636,Yixiao,Ge,,The Chinese University of Hong Kong,yxge@link,FD-GAN: Pose-guided Feature Distilling GAN for Robust Person Re-identification
neurips,2018,1,636,Zhuowan,Li,,Johns Hopkins University,hsli@ee,FD-GAN: Pose-guided Feature Distilling GAN for Robust Person Re-identification
neurips,2018,2,636,Haiyu,Zhao,cuhk,The Chinese University of Hong Kong,xgwang@ee.cuhk.edu.hk,FD-GAN: Pose-guided Feature Distilling GAN for Robust Person Re-identification
neurips,2018,3,636,Guojun,Yin,sensetime,University of Science and Technology of China,zhaohaiyu@sensetime.com,FD-GAN: Pose-guided Feature Distilling GAN for Robust Person Re-identification
neurips,2018,4,636,Shuai,Yi,sensetime,The Chinese University of Hong Kong,yishuai@sensetime.com,FD-GAN: Pose-guided Feature Distilling GAN for Robust Person Re-identification
neurips,2018,5,636,Xiaogang,Wang,jhu,The Chinese University of Hong Kong,zli110@jhu.edu,FD-GAN: Pose-guided Feature Distilling GAN for Robust Person Re-identification
neurips,2018,6,636,hongsheng,Li,ustc,cuhk,gjyin@mail.ustc.edu.cn,FD-GAN: Pose-guided Feature Distilling GAN for Robust Person Re-identification
neurips,2018,0,5238,Arman,Rahimzamani,uw,University of Washington,armanrz@uw.edu,Estimators for Multivariate Information Measures in General Probability Spaces
neurips,2018,1,5238,Himanshu,Asnani,uw,"University of Washington, Seattle",asnani@uw.edu,Estimators for Multivariate Information Measures in General Probability Spaces
neurips,2018,2,5238,Pramod,Viswanath,illinois,UIUC,pramodv@illinois.edu,Estimators for Multivariate Information Measures in General Probability Spaces
neurips,2018,3,5238,Sreeram,Kannan,uw,University of Washington,ksreeram@uw.edu,Estimators for Multivariate Information Measures in General Probability Spaces
neurips,2018,0,2991,Chongxuan,LI,tsinghua,Tsinghua University,licx14@mails.tsinghua.edu.cn,Graphical Generative Adversarial Networks
neurips,2018,1,2991,Max,Welling,uva,University of Amsterdam / Qualcomm AI Research,M.Welling@uva.nl,Graphical Generative Adversarial Networks
neurips,2018,2,2991,Jun,Zhu,tsinghua,Tsinghua University,dcszj@mail.tsinghua.edu.cn,Graphical Generative Adversarial Networks
neurips,2018,3,2991,Bo,Zhang,tsinghua,Tsinghua University,dcszb@mail.tsinghua.edu.cn,Graphical Generative Adversarial Networks
neurips,2018,0,3541,Priyank,Jaini,uwaterloo,University of Waterloo,pjaini@uwaterloo.ca,"Deep Homogeneous Mixture Models: Representation, Separation, and Approximation"
neurips,2018,1,3541,Pascal,Poupart,uwaterloo,University of Waterloo & RBC Borealis AI,ppoupart@uwaterloo.ca,"Deep Homogeneous Mixture Models: Representation, Separation, and Approximation"
neurips,2018,2,3541,Yaoliang,Yu,uwaterloo,University of Waterloo,yaoliang.yu@uwaterloo.ca,"Deep Homogeneous Mixture Models: Representation, Separation, and Approximation"
neurips,2018,0,347,Amit,Dhurandhar,ibm,IBM Research,adhuran@us.ibm.com,Explanations based on the Missing: Towards Contrastive Explanations with Pertinent Negatives
neurips,2018,1,347,Pin-Yu,Chen,ibm,IBM Research AI,pin-yu.chen@ibm.com,Explanations based on the Missing: Towards Contrastive Explanations with Pertinent Negatives
neurips,2018,2,347,Ronny,Luss,ibm,IBM Research,rluss@us.ibm.com,Explanations based on the Missing: Towards Contrastive Explanations with Pertinent Negatives
neurips,2018,3,347,Chun-Chen,Tu,umich,University of Michigan,timtu@umich.edu,Explanations based on the Missing: Towards Contrastive Explanations with Pertinent Negatives
neurips,2018,4,347,Paishun,Ting,umich,University of Michigan,paishun@umich.edu,Explanations based on the Missing: Towards Contrastive Explanations with Pertinent Negatives
neurips,2018,5,347,Karthikeyan,Shanmugam,ibm,"IBM Research, NY",karthikeyan.shanmugam2@ibm.com,Explanations based on the Missing: Towards Contrastive Explanations with Pertinent Negatives
neurips,2018,6,347,Payel,Das,ibm,IBM Research,daspa@us.ibm.com,Explanations based on the Missing: Towards Contrastive Explanations with Pertinent Negatives
neurips,2018,0,2637,Xiaowei,Chen,cuhk,The Chinese University of Hong Kong,1xwchen@cse.cuhk.edu.hk,Community Exploration: From Offline Optimization to Online Learning
neurips,2018,1,2637,Weiran,Huang,cuhk,Huawei Noah's Ark Lab,cslui@cse.cuhk.edu.hk,Community Exploration: From Offline Optimization to Online Learning
neurips,2018,2,2637,Wei,Chen,outlook,Microsoft Research,2huang.inbox@outlook.com,Community Exploration: From Offline Optimization to Online Learning
neurips,2018,3,2637,John C. S.,Lui,microsoft,The Chinese University of Hong Kong,3weic@microsoft.com,Community Exploration: From Offline Optimization to Online Learning
neurips,2018,0,6655,Donghoon,Lee,snu,Seoul National University,donghoon.lee@rllab.snu.ac.kr,Context-aware Synthesis and Placement of Object Instances
neurips,2018,1,6655,Sifei,Liu,nvidia,NVIDIA,sifeil@nvidia.com,Context-aware Synthesis and Placement of Object Instances
neurips,2018,2,6655,Jinwei,Gu,nvidia,Nvidia,jinweig@nvidia.com,Context-aware Synthesis and Placement of Object Instances
neurips,2018,3,6655,Ming-Yu,Liu,nvidia,NVIDIA,mingyul@nvidia.com,Context-aware Synthesis and Placement of Object Instances
neurips,2018,4,6655,Ming-Hsuan,Yang,ucmerced,UC Merced / Google,mhyang@ucmerced.edu,Context-aware Synthesis and Placement of Object Instances
neurips,2018,5,6655,Jan,Kautz,nvidia,NVIDIA,jkautz@nvidia.com,Context-aware Synthesis and Placement of Object Instances
neurips,2018,0,4881,Holden,Lee,duke,Princeton,rongge@cs.duke.edu,Beyond Log-concavity: Provable Guarantees for Sampling Multi-modal Distributions using Simulated Tempering Langevin Monte Carlo
neurips,2018,1,4881,Andrej,Risteski,princeton,MIT,holdenl@princeton.edu,Beyond Log-concavity: Provable Guarantees for Sampling Multi-modal Distributions using Simulated Tempering Langevin Monte Carlo
neurips,2018,2,4881,Rong,Ge,mit,Duke University,risteski@mit.edu,Beyond Log-concavity: Provable Guarantees for Sampling Multi-modal Distributions using Simulated Tempering Langevin Monte Carlo
neurips,2018,0,3410,Yelong,Shen,,"Microsoft Research, Redmond, WA",,M-Walk: Learning to Walk over Graphs using Monte Carlo Tree Search
neurips,2018,1,3410,Jianshu,Chen,,Tencent AI Lab,,M-Walk: Learning to Walk over Graphs using Monte Carlo Tree Search
neurips,2018,2,3410,Po-Sen,Huang,,Google DeepMind,,M-Walk: Learning to Walk over Graphs using Monte Carlo Tree Search
neurips,2018,3,3410,Yuqing,Guo,,Microsoft Research,,M-Walk: Learning to Walk over Graphs using Monte Carlo Tree Search
neurips,2018,4,3410,Jianfeng,Gao,,"Microsoft Research, Redmond, WA",,M-Walk: Learning to Walk over Graphs using Monte Carlo Tree Search
neurips,2018,0,6619,Hadi,Kazemi,wvu,WVU,hakazemi@mix.wvu.edu,Unsupervised Image-to-Image Translation Using Domain-Specific Variational Information Bound
neurips,2018,1,6619,Sobhan,Soleymani,wvu,West Virginia University,ssoleyma@mix.wvu.edu,Unsupervised Image-to-Image Translation Using Domain-Specific Variational Information Bound
neurips,2018,2,6619,Fariborz,Taherkhani,gmail,West Virginia University,fariborztaherkhani@gmail.com,Unsupervised Image-to-Image Translation Using Domain-Specific Variational Information Bound
neurips,2018,3,6619,Seyed,Iranmanesh,wvu,West Virginia University,seiranmanesh@mix.wvu.edu,Unsupervised Image-to-Image Translation Using Domain-Specific Variational Information Bound
neurips,2018,4,6619,Nasser,Nasrabadi,wvu,WVU,nasser.nasrabadi@mail.wvu.edu,Unsupervised Image-to-Image Translation Using Domain-Specific Variational Information Bound
neurips,2018,0,5313,Jan Eric,Lenssen,udo,TU Dortmund,janeric.lenssen@udo.edu,Group Equivariant Capsule Networks
neurips,2018,1,5313,Matthias,Fey,udo,TU Dortmund,matthias.fey@udo.edu,Group Equivariant Capsule Networks
neurips,2018,2,5313,Pascal,Libuschewski,udo,TU Dortmund,pascal.libuschewski@udo.edu,Group Equivariant Capsule Networks
neurips,2018,0,2341,Michael,Kim,stanford,Stanford University,mpk@cs.stanford.edu,Fairness Through Computationally-Bounded Awareness
neurips,2018,1,2341,Omer,Reingold,stanford,Stanford University,reingold@stanford.edu,Fairness Through Computationally-Bounded Awareness
neurips,2018,2,2341,Guy,Rothblum,mit,Weizmann Institute of Science,rothblum@alum.mit.edu,Fairness Through Computationally-Bounded Awareness
neurips,2018,0,722,Ofir,Lindenbaum,yale,Yale,ofir.lindenbaum@yale.edu,Geometry Based Data Generation
neurips,2018,1,722,Jay,Stanley,yale,Yale University,guy.wolf@yale.edu,Geometry Based Data Generation
neurips,2018,2,722,Guy,Wolf,yale,Yale University,jay.stanley@yale.edu,Geometry Based Data Generation
neurips,2018,3,722,Smita,Krishnaswamy,yale,Yale University,smita.krishnawamy@yale.edu,Geometry Based Data Generation
neurips,2018,0,5247,Liang-Chieh,Chen,,Google Inc.,,Searching for Efficient Multi-Scale Architectures for Dense Image Prediction
neurips,2018,1,5247,Maxwell,Collins,,Google Inc.,,Searching for Efficient Multi-Scale Architectures for Dense Image Prediction
neurips,2018,2,5247,Yukun,Zhu,,Google,,Searching for Efficient Multi-Scale Architectures for Dense Image Prediction
neurips,2018,3,5247,George,Papandreou,,Google,,Searching for Efficient Multi-Scale Architectures for Dense Image Prediction
neurips,2018,4,5247,Barret,Zoph,,Google Brain,,Searching for Efficient Multi-Scale Architectures for Dense Image Prediction
neurips,2018,5,5247,Florian,Schroff,,"Google Inc., Venice, CA",,Searching for Efficient Multi-Scale Architectures for Dense Image Prediction
neurips,2018,6,5247,Hartwig,Adam,,Google,,Searching for Efficient Multi-Scale Architectures for Dense Image Prediction
neurips,2018,7,5247,Jon,Shlens,,Google Research,,Searching for Efficient Multi-Scale Architectures for Dense Image Prediction
neurips,2018,0,3816,Rakshith,Shetty,,Max Planck Institute for Informatics,,Adversarial Scene Editing: Automatic Object Removal from Weak Supervision
neurips,2018,1,3816,Mario,Fritz,,CISPA Helmholtz Center i.G.,,Adversarial Scene Editing: Automatic Object Removal from Weak Supervision
neurips,2018,2,3816,Bernt,Schiele,,Max Planck Institute for Informatics,,Adversarial Scene Editing: Automatic Object Removal from Weak Supervision
neurips,2018,0,5144,Justin,Fu,berkeley,UC Berkeley,justinfu@berkeley.edu,Variational Inverse Control with Events: A General Framework for Data-Driven Reward Definition
neurips,2018,1,5144,Avi,Singh,berkeley,UC Berkeley,avisingh@berkeley.edu,Variational Inverse Control with Events: A General Framework for Data-Driven Reward Definition
neurips,2018,2,5144,Dibya,Ghosh,berkeley,UC Berkeley,dibyaghosh@berkeley.edu,Variational Inverse Control with Events: A General Framework for Data-Driven Reward Definition
neurips,2018,3,5144,Larry,Yang,berkeley,UC Berkeley,larrywyang@berkeley.edu,Variational Inverse Control with Events: A General Framework for Data-Driven Reward Definition
neurips,2018,4,5144,Sergey,Levine,berkeley,UC Berkeley,svlevine@berkeley.edu,Variational Inverse Control with Events: A General Framework for Data-Driven Reward Definition
neurips,2018,0,1106,Helena,Peic Tukuljac,epfl,École polytechnique fédérale de Lausanne,helena.peictukuljac@epfl.ch,MULAN: A Blind and Off-Grid Method for Multichannel Echo Retrieval
neurips,2018,1,1106,Antoine,Deleforge,inria,Inria,antoine.deleforge@inria.fr,MULAN: A Blind and Off-Grid Method for Multichannel Echo Retrieval
neurips,2018,2,1106,Remi,Gribonval,inria,INRIA,remi.gribonval@inria.fr,MULAN: A Blind and Off-Grid Method for Multichannel Echo Retrieval
neurips,2018,0,3429,Maya,Gupta,google,Google,mayagupta@google.com,Diminishing Returns Shape Constraints for Interpretability and Regularization
neurips,2018,1,3429,Dara,Bahri,google,Google AI,dbahri@google.com,Diminishing Returns Shape Constraints for Interpretability and Regularization
neurips,2018,2,3429,Andrew,Cotter,google,Google,acotter@google.com,Diminishing Returns Shape Constraints for Interpretability and Regularization
neurips,2018,3,3429,Kevin,Canini,google,Google,canini@google.com,Diminishing Returns Shape Constraints for Interpretability and Regularization
neurips,2018,0,3831,Sebastian,Flennerhag,turing,Alan Turing Institute,sennerhag@turing.ac.uk,Breaking the Activation Function Bottleneck through Adaptive Parameterization
neurips,2018,1,3831,Hujun,Yin,manchester,University of Manchester,hujun.yin@manchester.ac.uk,Breaking the Activation Function Bottleneck through Adaptive Parameterization
neurips,2018,2,3831,John,Keane,manchester,University of Manchester,john.keane@manchester.ac.uk,Breaking the Activation Function Bottleneck through Adaptive Parameterization
neurips,2018,3,3831,Mark,Elliot,manchester,University of Manchester,mark.elliot@manchester.ac.uk,Breaking the Activation Function Bottleneck through Adaptive Parameterization
neurips,2018,0,6764,Wei,Sun,,University of Miami Business School,,Sketching Method for Large Scale Combinatorial Inference
neurips,2018,1,6764,Junwei,Lu,,,,Sketching Method for Large Scale Combinatorial Inference
neurips,2018,2,6764,Han,Liu,,Northwestern,,Sketching Method for Large Scale Combinatorial Inference
neurips,2018,0,926,Xiaodan,Liang,gmail,Sun Yat-sen University,xdliang328@gmail.com,Symbolic Graph Reasoning Meets Convolutions
neurips,2018,1,926,Zhiting,Hu,cmu,Carnegie Mellon University,zhitingh@cs.cmu.edu,Symbolic Graph Reasoning Meets Convolutions
neurips,2018,2,926,Hao,Zhang,cmu,Petuum Inc.,hao@cs.cmu.edu,Symbolic Graph Reasoning Meets Convolutions
neurips,2018,3,926,Liang,Lin,cmu,Sun Yat-Sen University,epxing@cs.cmu.edu,Symbolic Graph Reasoning Meets Convolutions
neurips,2018,4,926,Eric,Xing,ieee,Petuum Inc. /  Carnegie Mellon University,linliang@ieee.org,Symbolic Graph Reasoning Meets Convolutions
neurips,2018,0,6978,Ankush,Mandal,gatech,Georgia Institute of Technology,ankush@gatech.edu,Topkapi: Parallel and Fast Sketches for Finding Top-K Frequent Elements
neurips,2018,1,6978,He,Jiang,rice,Rice University,anshumali@rice.edu,Topkapi: Parallel and Fast Sketches for Finding Top-K Frequent Elements
neurips,2018,2,6978,Anshumali,Shrivastava,rice,Rice University,cary.jiang@rice.edu,Topkapi: Parallel and Fast Sketches for Finding Top-K Frequent Elements
neurips,2018,3,6978,Vivek,Sarkar,gatech,Georgia Institute of Technology,vsarkar@gatech.edu,Topkapi: Parallel and Fast Sketches for Finding Top-K Frequent Elements
neurips,2018,0,8034,Samira,Samadi,gatech,Georgia Tech,ssamadi6@gatech.edu,The Price of Fair PCA: One Extra dimension
neurips,2018,1,8034,Uthaipon,Tantipongpipat,gatech,Georgia Tech,tao@gatech.edu,The Price of Fair PCA: One Extra dimension
neurips,2018,2,8034,Jamie,Morgenstern,gatech,Georgia Tech,jamiemmt.cs@gatech.edu,The Price of Fair PCA: One Extra dimension
neurips,2018,3,8034,Mohit,Singh,gmail,Georgia Tech,mohitsinghr@gmail.com,The Price of Fair PCA: One Extra dimension
neurips,2018,4,8034,Santosh,Vempala,gatech,Georgia Tech,vempala@cc.gatech.edu,The Price of Fair PCA: One Extra dimension
neurips,2018,0,5263,Hugh,Salimbeni,ic,Imperial College London,hrs13@ic.ac.uk,Orthogonally Decoupled Variational Gaussian Processes
neurips,2018,1,5263,Ching-An,Cheng,gatech,Georgia Tech,cacheng@gatech.edu,Orthogonally Decoupled Variational Gaussian Processes
neurips,2018,2,5263,Byron,Boots,gatech,Georgia Tech / Google Brain,bboots@gatech.edu,Orthogonally Decoupled Variational Gaussian Processes
neurips,2018,3,5263,Marc,Deisenroth,ic,Imperial College London,mpd37@ic.ac.uk,Orthogonally Decoupled Variational Gaussian Processes
neurips,2018,0,2621,Shivapratap,Gopakumar,,Deakin University,,Algorithmic Assurance: An Active Approach to Algorithmic Testing using Bayesian Optimisation
neurips,2018,1,2621,Sunil,Gupta,,Deakin University,,Algorithmic Assurance: An Active Approach to Algorithmic Testing using Bayesian Optimisation
neurips,2018,2,2621,Santu,Rana,,Deakin University,,Algorithmic Assurance: An Active Approach to Algorithmic Testing using Bayesian Optimisation
neurips,2018,3,2621,Vu,Nguyen,,Deakin University,,Algorithmic Assurance: An Active Approach to Algorithmic Testing using Bayesian Optimisation
neurips,2018,4,2621,Svetha,Venkatesh,,Deakin University,,Algorithmic Assurance: An Active Approach to Algorithmic Testing using Bayesian Optimisation
neurips,2018,0,549,An,Zhao,,Renmin University of China,,Domain-Invariant Projection Learning for Zero-Shot Recognition
neurips,2018,1,549,Mingyu,Ding,,Renmin University of China,,Domain-Invariant Projection Learning for Zero-Shot Recognition
neurips,2018,2,549,Jiechao,Guan,,Renmin University of China,,Domain-Invariant Projection Learning for Zero-Shot Recognition
neurips,2018,3,549,Zhiwu,Lu,,Renmin University of China,,Domain-Invariant Projection Learning for Zero-Shot Recognition
neurips,2018,4,549,Tao,Xiang,,"Samsung AI Centre, Cambridge",,Domain-Invariant Projection Learning for Zero-Shot Recognition
neurips,2018,5,549,Ji-Rong,Wen,,Renmin University of China,,Domain-Invariant Projection Learning for Zero-Shot Recognition
neurips,2018,0,922,Ilias,Zadik,mit,MIT,gamarnik@mit.edu,High Dimensional Linear Regression using Lattice Basis Reduction
neurips,2018,1,922,David,Gamarnik,mit,Massachusetts Institute of Technology,izadik@mit.edu,High Dimensional Linear Regression using Lattice Basis Reduction
neurips,2018,0,6491,Tatsunori,Hashimoto,stanford,Stanford,thashim@stanford.edu,A Retrieve-and-Edit Framework for Predicting Structured Outputs
neurips,2018,1,6491,Kelvin,Guu,stanford,Google,kguu@stanford.edu,A Retrieve-and-Edit Framework for Predicting Structured Outputs
neurips,2018,2,6491,Yonatan,Oren,stanford,Stanford,yonatano@stanford.edu,A Retrieve-and-Edit Framework for Predicting Structured Outputs
neurips,2018,3,6491,Percy,Liang,stanford,Stanford University,pliang@cs.stanford.edu,A Retrieve-and-Edit Framework for Predicting Structured Outputs
neurips,2018,0,2741,Nicholas,Roy,princeton,Princeton Neuroscience Institute,nroy@princeton.edu,Efficient inference for time-varying behavior during learning
neurips,2018,1,2741,Ji Hyun,Bak,princeton,KIAS,brody@princeton.edu,Efficient inference for time-varying behavior during learning
neurips,2018,2,2741,Athena,Akrami,princeton,Princeton University,pillow@princeton.edu,Efficient inference for time-varying behavior during learning
neurips,2018,3,2741,Carlos,Brody,re,Princeton University,jhbak@kias.re.kr,Efficient inference for time-varying behavior during learning
neurips,2018,4,2741,Jonathan,Pillow,ucl,Princeton University,athena.akrami@ucl.ac.uk,Efficient inference for time-varying behavior during learning
neurips,2018,0,1669,David,Balduzzi,,DeepMind,,Re-evaluating evaluation
neurips,2018,1,1669,Karl,Tuyls,,DeepMind,,Re-evaluating evaluation
neurips,2018,2,1669,Julien,Perolat,,DeepMind,,Re-evaluating evaluation
neurips,2018,3,1669,Thore,Graepel,,DeepMind,,Re-evaluating evaluation
neurips,2018,0,6687,Matthew,Riemer,,IBM Research AI,,Learning Abstract Options
neurips,2018,1,6687,Miao,Liu,,IBM,,Learning Abstract Options
neurips,2018,2,6687,Gerald,Tesauro,,IBM TJ Watson Research Center,,Learning Abstract Options
neurips,2018,0,5855,Rad,Niazadeh,stanford,Stanford University,rad@cs.stanford.edu,Optimal Algorithms for Continuous Non-monotone Submodular and DR-Submodular Maximization
neurips,2018,1,5855,Tim,Roughgarden,stanford,Stanford University,tim@cs.stanford.edu,Optimal Algorithms for Continuous Non-monotone Submodular and DR-Submodular Maximization
neurips,2018,2,5855,Joshua,Wang,google,Google,joshuawang@google.com,Optimal Algorithms for Continuous Non-monotone Submodular and DR-Submodular Maximization
neurips,2018,0,1023,Lu,Qi,cuhk,The Chinese University of Hong Kong,luqi@cse.cuhk.edu.hk,Sequential Context Encoding for Duplicate Removal
neurips,2018,1,1023,Shu,Liu,cuhk,Chinese University of Hong Kong,sliu@cse.cuhk.edu.hk,Sequential Context Encoding for Duplicate Removal
neurips,2018,2,1023,Jianping,Shi,cuhk,Sensetime Group Limited,leojia@cse.cuhk.edu.hk,Sequential Context Encoding for Duplicate Removal
neurips,2018,3,1023,Jiaya,Jia,sensetime,CUHK,shijianping@sensetime.com,Sequential Context Encoding for Duplicate Removal
neurips,2018,0,2253,Bianca,Dumitrascu,princeton,Princeton University,biancad@princeton.edu,PG-TS: Improved Thompson Sampling for Logistic Contextual Bandits
neurips,2018,1,2253,Karen,Feng,princeton,Princeton University,karenfeng@princeton.edu,PG-TS: Improved Thompson Sampling for Logistic Contextual Bandits
neurips,2018,2,2253,Barbara,Engelhardt,princeton,Princeton University,bee@princeton.edu,PG-TS: Improved Thompson Sampling for Logistic Contextual Bandits
neurips,2018,0,6442,Ellango,Jothimurugesan,cmu,CMU,ejothimu@cs.cmu.edu,Variance-Reduced Stochastic Gradient Descent on Streaming Data
neurips,2018,1,6442,Ashraf,Tahmasbi,cmu,Iowa State University,gibbons@cs.cmu.edu,Variance-Reduced Stochastic Gradient Descent on Streaming Data
neurips,2018,2,6442,Phillip,Gibbons,iastate,CMU,tahmasbi@iastate.edu,Variance-Reduced Stochastic Gradient Descent on Streaming Data
neurips,2018,3,6442,Srikanta,Tirthapura,iastate,Iowa State University,snt@iastate.edu,Variance-Reduced Stochastic Gradient Descent on Streaming Data
neurips,2018,0,500,Ju,Xu,pku,Peking University,xuju@pku.edu.cn,Reinforced Continual Learning
neurips,2018,1,500,Zhanxing,Zhu,pku,Peking University,zhanxing.zhu@pku.edu.cn,Reinforced Continual Learning
neurips,2018,0,2461,Mingchao,Yu,,University of Southern California,,GradiVeQ: Vector Quantization for Bandwidth-Efficient Gradient Aggregation in Distributed CNN Training
neurips,2018,1,2461,Zhifeng,Lin,,University of Southern California,,GradiVeQ: Vector Quantization for Bandwidth-Efficient Gradient Aggregation in Distributed CNN Training
neurips,2018,2,2461,Krishna,Narra,,University Of Southern California,,GradiVeQ: Vector Quantization for Bandwidth-Efficient Gradient Aggregation in Distributed CNN Training
neurips,2018,3,2461,Songze,Li,,University of Southern California,,GradiVeQ: Vector Quantization for Bandwidth-Efficient Gradient Aggregation in Distributed CNN Training
neurips,2018,4,2461,Youjie,Li,,UIUC,,GradiVeQ: Vector Quantization for Bandwidth-Efficient Gradient Aggregation in Distributed CNN Training
neurips,2018,5,2461,Nam Sung,Kim,,University of Illinois at Urbana-Champaign,,GradiVeQ: Vector Quantization for Bandwidth-Efficient Gradient Aggregation in Distributed CNN Training
neurips,2018,6,2461,Alexander,Schwing,,University of Illinois at Urbana-Champaign,,GradiVeQ: Vector Quantization for Bandwidth-Efficient Gradient Aggregation in Distributed CNN Training
neurips,2018,7,2461,Murali,Annavaram,,University of Southern California,,GradiVeQ: Vector Quantization for Bandwidth-Efficient Gradient Aggregation in Distributed CNN Training
neurips,2018,8,2461,Salman,Avestimehr,,University of Southern California,,GradiVeQ: Vector Quantization for Bandwidth-Efficient Gradient Aggregation in Distributed CNN Training
neurips,2018,0,5436,Xiaohan,Chen,tamu,Texas A&M University,chernxh@tamu.edu,Theoretical Linear Convergence of Unfolded ISTA and Its Practical Weights and Thresholds
neurips,2018,1,5436,Jialin,Liu,tamu,"University of California, Los Angeles (UCLA)",atlaswang@tamu.edu,Theoretical Linear Convergence of Unfolded ISTA and Its Practical Weights and Thresholds
neurips,2018,2,5436,Zhangyang,Wang,ucla,TAMU,liujl11@math.ucla.edu,Theoretical Linear Convergence of Unfolded ISTA and Its Practical Weights and Thresholds
neurips,2018,3,5436,Wotao,Yin,ucla,"University of California, Los Angeles",wotaoyin@math.ucla.edu,Theoretical Linear Convergence of Unfolded ISTA and Its Practical Weights and Thresholds
neurips,2018,0,259,Yaron,Singer,biu,Harvard University,avinatan@cs.biu.ac.il,Optimization for Approximate Submodularity
neurips,2018,1,259,Avinatan,Hassidim,harvard,Bar Ilan University,yaron@seas.harvard.edu,Optimization for Approximate Submodularity
neurips,2018,0,2388,Huan,Zhang,,UCLA,,Efficient Neural Network Robustness Certification with General Activation Functions
neurips,2018,1,2388,Tsui-Wei,Weng,,MIT,,Efficient Neural Network Robustness Certification with General Activation Functions
neurips,2018,2,2388,Pin-Yu,Chen,,IBM Research AI,,Efficient Neural Network Robustness Certification with General Activation Functions
neurips,2018,3,2388,Cho-Jui,Hsieh,,"UCLA, Google Research",,Efficient Neural Network Robustness Certification with General Activation Functions
neurips,2018,4,2388,Luca,Daniel,,MIT,,Efficient Neural Network Robustness Certification with General Activation Functions
neurips,2018,0,2394,Satoshi,Koide,tytlabs,Toyota Central R&D Labs.,koide@mosk.tytlabs.co.jp,Neural Edit Operations for Biological Sequences
neurips,2018,1,2394,Keisuke,Kawano,tytlabs,"Toyota Central R&D Labs., Inc",kawano@mosk.tytlabs.co.jp,Neural Edit Operations for Biological Sequences
neurips,2018,2,2394,Takuro,Kutsuna,tytlabs,Toyota Central R&D Labs. Inc.,kutsuna@mosk.tytlabs.co.jp,Neural Edit Operations for Biological Sequences
neurips,2018,0,75,Tyler,Scott,colorado,University of Colorado Boulder,tysc7237@colorado.edu,Adapted Deep Embeddings: A Synthesis of Methods for k-Shot Inductive Transfer Learning
neurips,2018,1,75,Karl,Ridgeway,colorado,"University of Colorado, Boulder",karl.ridgeway@colorado.edu,Adapted Deep Embeddings: A Synthesis of Methods for k-Shot Inductive Transfer Learning
neurips,2018,2,75,Michael,Mozer,colorado,Google Brain / U. Colorado,mozer@colorado.edu,Adapted Deep Embeddings: A Synthesis of Methods for k-Shot Inductive Transfer Learning
neurips,2018,0,5640,Bradly,Stadie,,Vector Institute,,The Importance of Sampling inMeta-Reinforcement Learning
neurips,2018,1,5640,Ge,Yang,,Berkeley,,The Importance of Sampling inMeta-Reinforcement Learning
neurips,2018,2,5640,Rein,Houthooft,,Happy Elements,,The Importance of Sampling inMeta-Reinforcement Learning
neurips,2018,3,5640,Peter,Chen,,covariant.ai,,The Importance of Sampling inMeta-Reinforcement Learning
neurips,2018,4,5640,Yan,Duan,,UC Berkeley,,The Importance of Sampling inMeta-Reinforcement Learning
neurips,2018,5,5640,Yuhuai,Wu,,University of Toronto,,The Importance of Sampling inMeta-Reinforcement Learning
neurips,2018,6,5640,Pieter,Abbeel,,UC Berkeley | Gradescope | Covariant,,The Importance of Sampling inMeta-Reinforcement Learning
neurips,2018,7,5640,Ilya,Sutskever,,OpenAI,,The Importance of Sampling inMeta-Reinforcement Learning
neurips,2018,0,2001,Moez,Draief,huawei,"Noah's Ark Labs, Huawei Research",moez.draief@huawei.com,KONG: Kernels for ordered-neighborhood graphs
neurips,2018,1,2001,Konstantin,Kutzkov,gmail,London School of Economics,kutzkov@gmail.com,KONG: Kernels for ordered-neighborhood graphs
neurips,2018,2,2001,Kevin,Scaman,huawei,"Noah's Ark Lab, Huawei Technologies",kevin.scaman@huawei.com,KONG: Kernels for ordered-neighborhood graphs
neurips,2018,3,2001,Milan,Vojnovic,lse,London School of Economics (LSE),m.vojnovic@lse.ac.uk,KONG: Kernels for ordered-neighborhood graphs
neurips,2018,0,6558,Durk,Kingma,,Google,,Glow: Generative Flow with Invertible 1x1 Convolutions
neurips,2018,1,6558,Prafulla,Dhariwal,,OpenAI,,Glow: Generative Flow with Invertible 1x1 Convolutions
neurips,2018,0,2034,Bei,Jia,,Element AI,,Efficient Projection onto the Perfect Phylogeny Model
neurips,2018,1,2034,Surjyendu,Ray,,Boston College,,Efficient Projection onto the Perfect Phylogeny Model
neurips,2018,2,2034,Sam,Safavi,,Boston College,,Efficient Projection onto the Perfect Phylogeny Model
neurips,2018,3,2034,José,Bento,,Boston College,,Efficient Projection onto the Perfect Phylogeny Model
neurips,2018,0,418,Moran,Feldman,openu,Open University of Israel,moranfe@openu.ac.il,"Do Less, Get More: Streaming Submodular Maximization with Subsampling"
neurips,2018,1,418,Amin,Karbasi,yale,Yale,amin.karbasi@yale.edu,"Do Less, Get More: Streaming Submodular Maximization with Subsampling"
neurips,2018,2,418,Ehsan,Kazemi,yale,"Yale Institute for Network Science, Yale",ehsan.kazemi@yale.edu,"Do Less, Get More: Streaming Submodular Maximization with Subsampling"
neurips,2018,0,6696,Lea,Duncker,ucl,"Gatsby Unit, UCL",duncker@gatsby.ucl.ac.uk,Temporal alignment and latent Gaussian process factor inference in population spike trains
neurips,2018,1,6696,Maneesh,Sahani,ucl,"Gatsby Unit, UCL",maneesh@gatsby.ucl.ac.uk,Temporal alignment and latent Gaussian process factor inference in population spike trains
neurips,2018,0,1790,Minshuo,Chen,gatech,Georgia Tech,1mchen393@gatech.edu,Dimensionality Reduction for Stationary Time Series via Stochastic Nonconvex Optimization
neurips,2018,1,1790,Lin,Yang,gatech,Princeton University,tourzhao@gatech.edu,Dimensionality Reduction for Stationary Time Series via Stochastic Nonconvex Optimization
neurips,2018,2,1790,Mengdi,Wang,princeton,Princeton University,2lin.yang@princeton.edu,Dimensionality Reduction for Stationary Time Series via Stochastic Nonconvex Optimization
neurips,2018,3,1790,Tuo,Zhao,princeton,Georgia Tech,mengdiw@princeton.edu,Dimensionality Reduction for Stationary Time Series via Stochastic Nonconvex Optimization
neurips,2018,0,296,Yunzhe,Tao,columbia,Columbia University,y.tao@columbia.edu,"Nonlocal Neural Networks, Nonlocal Diffusion and Nonlocal Modeling"
neurips,2018,1,296,Qi,Sun,columbia,CSRC & USTC & CU,qd2125@columbia.edu,"Nonlocal Neural Networks, Nonlocal Diffusion and Nonlocal Modeling"
neurips,2018,2,296,Qiang,Du,csrc,Columbia University,sunqi@csrc.ac.cn,"Nonlocal Neural Networks, Nonlocal Diffusion and Nonlocal Modeling"
neurips,2018,3,296,Wei,Liu,columbia,Tencent AI Lab,wl2223@columbia.edu,"Nonlocal Neural Networks, Nonlocal Diffusion and Nonlocal Modeling"
neurips,2018,0,932,Peter,Anderson,mq,Georgia Tech,p.anderson@mq.edu.au,Partially-Supervised Image Captioning
neurips,2018,1,932,Stephen,Gould,anu,ANU,stephen.gould@anu.edu.au,Partially-Supervised Image Captioning
neurips,2018,2,932,Mark,Johnson,mq,Macquarie University,mark.johnson@mq.edu.au,Partially-Supervised Image Captioning
neurips,2018,0,3083,Aaron,Mishkin,ubc,University of British Columbia,amishkin@cs.ubc.ca,SLANG: Fast Structured Covariance Approximations for Bayesian Deep Learning with Natural Gradient
neurips,2018,1,3083,Frederik,Kunstner,epfl,EPFL,frederik.kunstner@epfl.ch,SLANG: Fast Structured Covariance Approximations for Bayesian Deep Learning with Natural Gradient
neurips,2018,2,3083,Didrik,Nielsen,riken,DTU Compute,didrik.nielsen@riken.jp,SLANG: Fast Structured Covariance Approximations for Bayesian Deep Learning with Natural Gradient
neurips,2018,3,3083,Mark,Schmidt,ubc,University of British Columbia,schmidtm@cs.ubc.ca,SLANG: Fast Structured Covariance Approximations for Bayesian Deep Learning with Natural Gradient
neurips,2018,4,3083,Mohammad Emtiyaz,Khan,riken,"RIKEN, Tokyo",emtiyaz.khan@riken.jp,SLANG: Fast Structured Covariance Approximations for Bayesian Deep Learning with Natural Gradient
neurips,2018,0,377,Yi,Hao,ucsd,"University of California, San Diego",alon@ucsd.edu,On Learning Markov Chains
neurips,2018,1,377,Alon,Orlitsky,ucsd,"University of California, San Diego",yih179@ucsd.edu,On Learning Markov Chains
neurips,2018,2,377,Venkatadheeraj,Pichapati,ucsd,UC San Diego,dheerajpv7@ucsd.edu,On Learning Markov Chains
neurips,2018,0,2366,Chi,Jin,berkeley,"University of California, Berkeley",chijin@cs.berkeley.edu,Is Q-Learning Provably Efficient?
neurips,2018,1,2366,Zeyuan,Allen-Zhu,mit,Microsoft Research,zeyuan@csail.mit.edu,Is Q-Learning Provably Efficient?
neurips,2018,2,2366,Sebastien,Bubeck,microsoft,Microsoft Research,sebubeck@microsoft.com,Is Q-Learning Provably Efficient?
neurips,2018,3,2366,Michael,Jordan,berkeley,UC Berkeley,jordan@cs.berkeley.edu,Is Q-Learning Provably Efficient?
neurips,2018,0,4866,Yao-Xiang,Ding,nju,Nanjing University,dingyx@lamda.nju.edu.cn,Preference Based Adaptation for Learning Objectives
neurips,2018,1,4866,Zhi-Hua,Zhou,nju,Nanjing University,zhouzh@lamda.nju.edu.cn,Preference Based Adaptation for Learning Objectives
neurips,2018,0,1690,David,Reeb,bosch,Bosch Center for Artificial Intelligence (BCAI),david.reeb@de.bosch.com,Learning Gaussian Processes by Minimizing PAC-Bayesian Generalization Bounds
neurips,2018,1,1690,Andreas,Doerr,bosch,"BCAI, MPI-IS AMD",andreas.doerr3@de.bosch.com,Learning Gaussian Processes by Minimizing PAC-Bayesian Generalization Bounds
neurips,2018,2,1690,Sebastian,Gerwinn,bosch,Bosch Center for Artificial Intelligence,sebastian.gerwinn@de.bosch.com,Learning Gaussian Processes by Minimizing PAC-Bayesian Generalization Bounds
neurips,2018,3,1690,Barbara,Rakitsch,bosch,Bosch Center for Artificial Intelligence,barbara.rakitsch@de.bosch.com,Learning Gaussian Processes by Minimizing PAC-Bayesian Generalization Bounds
neurips,2018,0,6457,Mark,van der Wilk,prowler,PROWLER.io,mark@prowler.io,Learning Invariances using the Marginal Likelihood
neurips,2018,1,6457,Matthias,Bauer,cam,Max Planck Institute for Intelligent Systems,msb55@cam.ac.uk,Learning Invariances using the Marginal Likelihood
neurips,2018,2,6457,ST,John,prowler,PROWLER.io,st@prowler.io,Learning Invariances using the Marginal Likelihood
neurips,2018,3,6457,James,Hensman,prowler,PROWLER.io,james@prowler.io,Learning Invariances using the Marginal Likelihood
neurips,2018,0,1873,Zeyuan,Allen-Zhu,mit,Microsoft Research,zeyuan@csail.mit.edu,NEON2: Finding Local Minima via First-Order Oracles
neurips,2018,1,1873,Yuanzhi,Li,stanford,Princeton,yuanzhil@stanford.edu,NEON2: Finding Local Minima via First-Order Oracles
neurips,2018,0,879,Simyung,Chang,snu,Seoul National University,timelighter@snu.ac.kr,Genetic-Gated Networks for Deep Reinforcement Learning
neurips,2018,1,879,John,Yang,snu,Seoul National University,jaeseok.choi@snu.ac.kr,Genetic-Gated Networks for Deep Reinforcement Learning
neurips,2018,2,879,Jaeseok,Choi,snu,Seoul National University,yjohn@snu.ac.kr,Genetic-Gated Networks for Deep Reinforcement Learning
neurips,2018,3,879,Nojun,Kwak,snu,Seoul National University,nojunk@snu.ac.kr,Genetic-Gated Networks for Deep Reinforcement Learning
neurips,2018,0,1901,Aladin,Virmaux,huawei,Huawei,kevin.scaman@huawei.com,Lipschitz regularity of deep neural networks: analysis and efficient estimation
neurips,2018,1,1901,Kevin,Scaman,huawei,"Huawei Technologies, Noah's Ark",aladin.virmaux@huawei.com,Lipschitz regularity of deep neural networks: analysis and efficient estimation
neurips,2018,0,825,Robert,Gower,telecom-paristech,ParisTech,robert.gower@telecom-paristech.fr,Accelerated Stochastic Matrix Inversion:  General Theory and  Speeding up BFGS Rules for Faster Second-Order Optimization
neurips,2018,1,825,Filip,Hanzely,kaust,KAUST,filip.hanzely@kaust.edu.sa,Accelerated Stochastic Matrix Inversion:  General Theory and  Speeding up BFGS Rules for Faster Second-Order Optimization
neurips,2018,2,825,Peter,Richtarik,kaust,KAUST,peter.richtarik@kaust.edu.sa,Accelerated Stochastic Matrix Inversion:  General Theory and  Speeding up BFGS Rules for Faster Second-Order Optimization
neurips,2018,3,825,Sebastian,Stich,epfl,EPFL,sebastian.stich@epfl.ch,Accelerated Stochastic Matrix Inversion:  General Theory and  Speeding up BFGS Rules for Faster Second-Order Optimization
neurips,2018,0,6487,Ali,Ahmed,itu,Information Technology University,ali.ahmed@itu.edu.pk,Blind Deconvolutional Phase Retrieval via Convex Programming
neurips,2018,1,6487,Alireza,Aghasi,gsu,Institute for Insight,aaghasi@gsu.edu,Blind Deconvolutional Phase Retrieval via Convex Programming
neurips,2018,2,6487,Paul,Hand,northeastern,Northeastern University,p.hand@northeastern.edu,Blind Deconvolutional Phase Retrieval via Convex Programming
neurips,2018,0,3162,Jiaxuan,You,stanford,Stanford University,jiaxuan@stanford.edu,Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation
neurips,2018,1,3162,Bowen,Liu,stanford,Stanford University,liubowen@stanford.edu,Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation
neurips,2018,2,3162,Zhitao,Ying,stanford,Stanford University,rexying@stanford.edu,Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation
neurips,2018,3,3162,Vijay,Pande,stanford,Stanford,pande@stanford.edu,Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation
neurips,2018,4,3162,Jure,Leskovec,stanford,Stanford University and Pinterest,jure@cs.stanford.edu,Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation
neurips,2018,0,2257,Elad,Hazan,princeton,Princeton University,ehazan@cs.princeton.edu,Spectral Filtering for General Linear Dynamical Systems
neurips,2018,1,2257,Holden,Lee,princeton,Princeton,holdenl@princeton.edu,Spectral Filtering for General Linear Dynamical Systems
neurips,2018,2,2257,Karan,Singh,princeton,Princeton University,karans@cs.princeton.edu,Spectral Filtering for General Linear Dynamical Systems
neurips,2018,3,2257,Cyril,Zhang,princeton,Princeton University,cyril.zhang@cs.princeton.edu,Spectral Filtering for General Linear Dynamical Systems
neurips,2018,4,2257,Yi,Zhang,princeton,Princeton,y.zhang@cs.princeton.edu,Spectral Filtering for General Linear Dynamical Systems
neurips,2018,0,1534,Daya,Guo,,Sun Yat-Sen University,guody5@mail2,Dialog-to-Action: Conversational Question Answering Over a Large-Scale Knowledge Base
neurips,2018,1,1534,Duyu,Tang,sysu,Microsoft Research,issjyin@mail.sysu.edu.cn,Dialog-to-Action: Conversational Question Answering Over a Large-Scale Knowledge Base
neurips,2018,2,1534,Nan,Duan,microsoft,Microsoft Research,dutang@microsoft.com,Dialog-to-Action: Conversational Question Answering Over a Large-Scale Knowledge Base
neurips,2018,3,1534,Ming,Zhou,microsoft,Microsoft Research,nanduan@microsoft.com,Dialog-to-Action: Conversational Question Answering Over a Large-Scale Knowledge Base
neurips,2018,4,1534,Jian,Yin,microsoft,Sun Yat-Sen University,mingzhou@microsoft.com,Dialog-to-Action: Conversational Question Answering Over a Large-Scale Knowledge Base
neurips,2018,0,40,Seonghyeon,Nam,yonsei,Yonsei University,shnnam@yonsei.ac.kr,Text-Adaptive Generative Adversarial Networks: Manipulating Images with Natural Language
neurips,2018,1,40,Yunji,Kim,yonsei,Yonsei University,kim_yunji@yonsei.ac.kr,Text-Adaptive Generative Adversarial Networks: Manipulating Images with Natural Language
neurips,2018,2,40,Seon Joo,Kim,yonsei,Yonsei University,seonjookim@yonsei.ac.kr,Text-Adaptive Generative Adversarial Networks: Manipulating Images with Natural Language
neurips,2018,0,5327,Jungseul,Ok,illinois,UIUC,ockjs@illinois.edu,Exploration in Structured Reinforcement Learning
neurips,2018,1,5327,Alexandre,Proutiere,kth,KTH,alepro@kth.se,Exploration in Structured Reinforcement Learning
neurips,2018,2,5327,Damianos,Tranos,kth,KTH Royal Institute of Stockholm,tranos@kth.se,Exploration in Structured Reinforcement Learning
neurips,2018,0,1277,Xinyun,Chen,berkeley,UC Berkeley,xinyun.chen@berkeley.edu,Tree-to-tree Neural Networks for Program Translation
neurips,2018,1,1277,Chang,Liu,gmail,Citadel,liuchang2005acm@gmail.com,Tree-to-tree Neural Networks for Program Translation
neurips,2018,2,1277,Dawn,Song,berkeley,UC Berkeley,dawnsong@cs.berkeley.edu,Tree-to-tree Neural Networks for Program Translation
neurips,2018,0,980,Binghui,Chen,bupt,Beijing University of Posts and Telecommunications,chenbinghui@bupt.edu.cn,Virtual Class Enhanced Discriminative Embedding Learning
neurips,2018,1,980,Weihong,Deng,bupt,Beijing University of Posts and Telecommunications,whdeng@bupt.edu.cn,Virtual Class Enhanced Discriminative Embedding Learning
neurips,2018,2,980,Haifeng,Shen,didiglobal,"AI Labs, Didi Chuxing",shenhaifeng@didiglobal.com,Virtual Class Enhanced Discriminative Embedding Learning
neurips,2018,0,2010,Martin,Magill,uoit,University of Ontario Institute of Technology,martin.magill1@uoit.net,Neural Networks Trained to Solve Differential Equations Learn General Representations
neurips,2018,1,2010,Faisal,Qureshi,uoit,"University of Ontario Institute of Technology, Canada",faisal.qureshi@uoit.ca,Neural Networks Trained to Solve Differential Equations Learn General Representations
neurips,2018,2,2010,Hendrick,de Haan,uoit,University of Ontario Institute of Technology,hendrick.dehaan@uoit.ca,Neural Networks Trained to Solve Differential Equations Learn General Representations
neurips,2018,0,6726,Zhiting,Hu,,Carnegie Mellon University,,Deep Generative Models with Learnable Knowledge Constraints
neurips,2018,1,6726,Zichao,Yang,,,,Deep Generative Models with Learnable Knowledge Constraints
neurips,2018,2,6726,Russ,Salakhutdinov,,Carnegie Mellon University,,Deep Generative Models with Learnable Knowledge Constraints
neurips,2018,3,6726,LIANHUI,Qin,,,,Deep Generative Models with Learnable Knowledge Constraints
neurips,2018,4,6726,Xiaodan,Liang,,Sun Yat-sen University,,Deep Generative Models with Learnable Knowledge Constraints
neurips,2018,5,6726,Haoye,Dong,,Sun Yat-sen University,,Deep Generative Models with Learnable Knowledge Constraints
neurips,2018,6,6726,Eric,Xing,,Petuum Inc. /  Carnegie Mellon University,,Deep Generative Models with Learnable Knowledge Constraints
neurips,2018,0,345,Boris,Hanin,tamu,Texas A&M,bhanin@math.tamu.edu,How to Start Training: The Effect of Initialization and Architecture
neurips,2018,1,345,David,Rolnick,mit,University of Pennsylvania,drolnick@mit.edu,How to Start Training: The Effect of Initialization and Architecture
neurips,2018,0,603,Ting-Chun,Wang,nvidia,NVIDIA,tingchunw@nvidia.com,Video-to-Video Synthesis
neurips,2018,1,603,Ming-Yu,Liu,nvidia,NVIDIA,mingyul@nvidia.com,Video-to-Video Synthesis
neurips,2018,2,603,Jun-Yan,Zhu,nvidia,MIT,guilinl@nvidia.com,Video-to-Video Synthesis
neurips,2018,3,603,Guilin,Liu,nvidia,NVIDIA,atao@nvidia.com,Video-to-Video Synthesis
neurips,2018,4,603,Andrew,Tao,nvidia,Nvidia Corporation,jkautz@nvidia.com,Video-to-Video Synthesis
neurips,2018,5,603,Jan,Kautz,nvidia,NVIDIA,bcatanzaro@nvidia.com,Video-to-Video Synthesis
neurips,2018,6,603,Bryan,Catanzaro,mit,NVIDIA,junyanz@mit.edu,Video-to-Video Synthesis
neurips,2018,0,1595,Yining,Wang,,CMU,,Near-Optimal Policies for Dynamic Multinomial Logit Assortment Selection Models
neurips,2018,1,1595,Xi,Chen,,NYU,,Near-Optimal Policies for Dynamic Multinomial Logit Assortment Selection Models
neurips,2018,2,1595,Yuan,Zhou,,Indiana University Bloomington,,Near-Optimal Policies for Dynamic Multinomial Logit Assortment Selection Models
neurips,2018,0,2676,Stuart,Armstrong,gmail,Oxford University,soeren.mindermann@gmail.com,Occam's razor is insufficient to infer the preferences of irrational agents
neurips,2018,1,2676,Sören,Mindermann,ox,Vector Institute,stuart.armstrong@philosophy.ox.ac.uk,Occam's razor is insufficient to infer the preferences of irrational agents
neurips,2018,0,3615,Yi,Qi,tsinghua,Tsinghua University,qi-y16@mails.tsinghua.edu.cn,Bandit Learning with Implicit Feedback
neurips,2018,1,3615,Qingyun,Wu,tsinghua,University of Virginia,jietang@tsinghua.edu.cn,Bandit Learning with Implicit Feedback
neurips,2018,2,3615,Hongning,Wang,tsinghua,University of Virginia,sms@tsinghua.edu.cn,Bandit Learning with Implicit Feedback
neurips,2018,3,3615,Jie,Tang,virginia,Tsinghua University,qw2ky@virginia.edu,Bandit Learning with Implicit Feedback
neurips,2018,4,3615,Maosong,Sun,virginia,,hw5x@virginia.edu,Bandit Learning with Implicit Feedback
neurips,2018,0,5137,Sebastian,Lunz,,University of Cambridge,,Adversarial Regularizers in Inverse Problems
neurips,2018,1,5137,Ozan,Öktem,,KTH - Royal Institute of Technology,,Adversarial Regularizers in Inverse Problems
neurips,2018,2,5137,Carola-Bibiane,Schönlieb,,Cambridge University,,Adversarial Regularizers in Inverse Problems
neurips,2018,0,5723,Samuel,Ocko,,Stanford,,The emergence of multiple retinal cell types through efficient coding of natural movies
neurips,2018,1,5723,Jack,Lindsey,,Stanford University,,The emergence of multiple retinal cell types through efficient coding of natural movies
neurips,2018,2,5723,Surya,Ganguli,,Stanford,,The emergence of multiple retinal cell types through efficient coding of natural movies
neurips,2018,3,5723,Stephane,Deny,,Stanford,,The emergence of multiple retinal cell types through efficient coding of natural movies
neurips,2018,0,8002,Don,Dennis,microsoft,Microsoft Research,t-dodenn@microsoft.com,Multiple Instance Learning for Efficient Sequential Data Classification on Resource-constrained Devices
neurips,2018,1,8002,Chirag,Pabbaraju,microsoft,Microsoft Research,t-chpab@microsoft.com,Multiple Instance Learning for Efficient Sequential Data Classification on Resource-constrained Devices
neurips,2018,2,8002,Harsha Vardhan,Simhadri,microsoft,Microsoft Research India,harshasi@microsoft.com,Multiple Instance Learning for Efficient Sequential Data Classification on Resource-constrained Devices
neurips,2018,3,8002,Prateek,Jain,microsoft,Microsoft Research,prajain@microsoft.com,Multiple Instance Learning for Efficient Sequential Data Classification on Resource-constrained Devices
neurips,2018,0,2471,Zhihui,Zhu,jhu,Johns Hopkins University,zzhu29@jhu.edu,Dropping Symmetry for Fast Symmetric Nonnegative Matrix Factorization
neurips,2018,1,2471,Xiao,Li,cuhk,The Chinese University of Hong Kong,xli@ee.cuhk.edu.hk,Dropping Symmetry for Fast Symmetric Nonnegative Matrix Factorization
neurips,2018,2,2471,Kai,Liu,mines,Colorado School of Mines,kaliu@mines.edu,Dropping Symmetry for Fast Symmetric Nonnegative Matrix Factorization
neurips,2018,3,2471,Qiuwei,Li,mines,Colorado School of Mines,qiuli@mines.edu,Dropping Symmetry for Fast Symmetric Nonnegative Matrix Factorization
neurips,2018,0,2380,Chi,Jin,berkeley,"University of California, Berkeley",chijin@cs.berkeley.edu,On the Local Minima of the Empirical Risk
neurips,2018,1,2380,Lydia T.,Liu,berkeley,"University of California, Berk",lydiatliu@cs.berkeley.edu,On the Local Minima of the Empirical Risk
neurips,2018,2,2380,Rong,Ge,duke,Duke University,rongge@cs.duke.edu,On the Local Minima of the Empirical Risk
neurips,2018,3,2380,Michael,Jordan,berkeley,UC Berkeley,jordan@cs.berkeley.edu,On the Local Minima of the Empirical Risk
neurips,2018,0,1179,Shusen,Wang,stanford,UC Berkeley,pengxu@stanford.edu,GIANT: Globally Improved Approximate Newton Method for Distributed Optimization
neurips,2018,1,1179,Fred,Roosta,stevens,University of Queensland,shusen.wang@stevens.edu,GIANT: Globally Improved Approximate Newton Method for Distributed Optimization
neurips,2018,2,1179,Peng,Xu,uq,Stanford University,fred.roosta@uq.edu.au,GIANT: Globally Improved Approximate Newton Method for Distributed Optimization
neurips,2018,3,1179,Michael,Mahoney,berkeley,UC Berkeley,mmahoney@stat.berkeley.edu,GIANT: Globally Improved Approximate Newton Method for Distributed Optimization
neurips,2018,0,1520,Nilesh,Tripuraneni,berkeley,UC Berkeley,nilesh_tripuraneni@berkeley.edu,Stochastic Cubic Regularization for Fast Nonconvex Optimization
neurips,2018,1,1520,Mitchell,Stern,berkeley,UC Berkeley,mitchell@berkeley.edu,Stochastic Cubic Regularization for Fast Nonconvex Optimization
neurips,2018,2,1520,Chi,Jin,berkeley,"University of California, Berkeley",chijin@berkeley.edu,Stochastic Cubic Regularization for Fast Nonconvex Optimization
neurips,2018,3,1520,Jeffrey,Regier,berkeley,UC Berkeley,regier@berkeley.edu,Stochastic Cubic Regularization for Fast Nonconvex Optimization
neurips,2018,4,1520,Michael,Jordan,berkeley,UC Berkeley,jordan@cs.berkeley.edu,Stochastic Cubic Regularization for Fast Nonconvex Optimization
neurips,2018,0,1768,Yu,Liu,,Iowa State University,,Derivative Estimation in Random Design
neurips,2018,1,1768,Kris,De Brabanter,,ISU,,Derivative Estimation in Random Design
neurips,2018,0,3326,Asier,Mujika,ethz,ETH Zurich,asierm@inf.ethz.ch,Approximating Real-Time Recurrent Learning with Random Kronecker Factors
neurips,2018,1,3326,Florian,Meier,ethz,ETH Zurich,meierflo@inf.ethz.ch,Approximating Real-Time Recurrent Learning with Random Kronecker Factors
neurips,2018,2,3326,Angelika,Steger,ethz,ETH Zurich,steger@inf.ethz.ch,Approximating Real-Time Recurrent Learning with Random Kronecker Factors
neurips,2018,0,2562,Octavian,Ganea,,ETH Zurich,,Hyperbolic Neural Networks
neurips,2018,1,2562,Gary,Becigneul,,ETH Zürich & MPI Tübingen,,Hyperbolic Neural Networks
neurips,2018,2,2562,Thomas,Hofmann,,ETH Zurich,,Hyperbolic Neural Networks
neurips,2018,0,6802,Soumendu Sundar,Mukherjee,gmail,"University of California, Berkeley",soumendu041@gmail.com,Mean Field for the Stochastic Blockmodel: Optimization Landscape and Convergence Issues
neurips,2018,1,6802,Purnamrita,Sarkar,utexas,UT Austin,purna.sarkar@austin.utexas.edu,Mean Field for the Stochastic Blockmodel: Optimization Landscape and Convergence Issues
neurips,2018,2,6802,Y. X. Rachel,Wang,sydney,University of Sydney,rachel.wang@sydney.edu.au,Mean Field for the Stochastic Blockmodel: Optimization Landscape and Convergence Issues
neurips,2018,3,6802,Bowei,Yan,utexas,Jump Trading,boweiy@utexas.edu,Mean Field for the Stochastic Blockmodel: Optimization Landscape and Convergence Issues
neurips,2018,0,2695,Laming,Chen,hulu,Hulu LLC,laming.chen@hulu.com,Fast Greedy MAP Inference for Determinantal Point Process to Improve Recommendation Diversity
neurips,2018,1,2695,Guoxin,Zhang,kuaishou,Kwai Inc.,zhangguoxin@kuaishou.com,Fast Greedy MAP Inference for Determinantal Point Process to Improve Recommendation Diversity
neurips,2018,2,2695,Eric,Zhou,gmail,Facebook,ericzhouh@gmail.com,Fast Greedy MAP Inference for Determinantal Point Process to Improve Recommendation Diversity
neurips,2018,0,5727,Jie,Hu,momenta,Momenta,hujie@momenta.ai,Gather-Excite: Exploiting Feature Context in Convolutional Neural Networks
neurips,2018,1,5727,Li,Shen,ox,University of Oxford,lishen@robots.ox.ac.uk,Gather-Excite: Exploiting Feature Context in Convolutional Neural Networks
neurips,2018,2,5727,Samuel,Albanie,ox,Oxford University,albanie@robots.ox.ac.uk,Gather-Excite: Exploiting Feature Context in Convolutional Neural Networks
neurips,2018,3,5727,Gang,Sun,momenta,Momenta,sungang@momenta.ai,Gather-Excite: Exploiting Feature Context in Convolutional Neural Networks
neurips,2018,4,5727,Andrea,Vedaldi,ox,Facebook AI Research and University of Oxford,vedaldi@robots.ox.ac.uk,Gather-Excite: Exploiting Feature Context in Convolutional Neural Networks
neurips,2018,0,1262,Jack,Goetz,umich,University of Michigan,jrgoetz@umich.edu,Active Learning for Non-Parametric Regression Using Purely Random Trees
neurips,2018,1,1262,Ambuj,Tewari,umich,University of Michigan,tewaria@umich.edu,Active Learning for Non-Parametric Regression Using Purely Random Trees
neurips,2018,2,1262,Paul,Zimmerman,umich,University of Michigan,paulzim@umich.edu,Active Learning for Non-Parametric Regression Using Purely Random Trees
neurips,2018,0,1878,Robin,Manhaeve,kuleuven,KU Leuven,robin.manhaeve@cs.kuleuven.be,DeepProbLog:  Neural Probabilistic Logic Programming
neurips,2018,1,1878,Sebastijan,Dumancic,kuleuven,KU LEUVEN,sebastijan.dumancic@cs.kuleuven.be,DeepProbLog:  Neural Probabilistic Logic Programming
neurips,2018,2,1878,Angelika,Kimmig,cardiff,Cardiff University,KimmigA@cardiff.ac.uk,DeepProbLog:  Neural Probabilistic Logic Programming
neurips,2018,3,1878,Thomas,Demeester,ugent,Ghent University,thomas.demeester@ugent.be,DeepProbLog:  Neural Probabilistic Logic Programming
neurips,2018,4,1878,Luc,De Raedt,kuleuven,KU Leuven,luc.deraedt@cs.kuleuven.be,DeepProbLog:  Neural Probabilistic Logic Programming
neurips,2018,0,676,Abel,Gonzalez-Garcia,,Computer Vision Center,,Image-to-image translation for cross-domain disentanglement
neurips,2018,1,676,Joost,van de Weijer,,Computer Vision Center Barcelona,,Image-to-image translation for cross-domain disentanglement
neurips,2018,2,676,Yoshua,Bengio,,U. Montreal,,Image-to-image translation for cross-domain disentanglement
neurips,2018,0,2202,Yexiang,Xue,,Purdue University,,Expanding Holographic Embeddings for Knowledge Completion
neurips,2018,1,2202,Yang,Yuan,,Cornell University,,Expanding Holographic Embeddings for Knowledge Completion
neurips,2018,2,2202,Zhitian,Xu,,Shanghai Jiaotong University,,Expanding Holographic Embeddings for Knowledge Completion
neurips,2018,3,2202,Ashish,Sabharwal,,Allen Institute for AI,,Expanding Holographic Embeddings for Knowledge Completion
neurips,2018,0,2567,Qiang,Liu,utexas,UT Austin,lqiang@cs.utexas.edu,Breaking the Curse of Horizon: Infinite-Horizon Off-Policy Estimation
neurips,2018,1,2567,Lihong,Li,utexas,Google Inc.,ztang@cs.utexas.edu,Breaking the Curse of Horizon: Infinite-Horizon Off-Policy Estimation
neurips,2018,2,2567,Ziyang,Tang,google,The University of Texas at Austin,lihong@google.com,Breaking the Curse of Horizon: Infinite-Horizon Off-Policy Estimation
neurips,2018,3,2567,Dengyong,Zhou,google,Google,dennyzhou@google.com,Breaking the Curse of Horizon: Infinite-Horizon Off-Policy Estimation
neurips,2018,0,1947,Tor,Lattimore,,DeepMind,,TopRank: A practical algorithm for online stochastic ranking
neurips,2018,1,1947,Branislav,Kveton,,Google,,TopRank: A practical algorithm for online stochastic ranking
neurips,2018,2,1947,Shuai,Li,,The Chinese University of Hong Kong,,TopRank: A practical algorithm for online stochastic ranking
neurips,2018,3,1947,Csaba,Szepesvari,,University of Alberta,,TopRank: A practical algorithm for online stochastic ranking
neurips,2018,0,3451,Mathieu,Fehr,ens,École Normale Supérieure,mathieu.fehr@ens.fr,rho-POMDPs have Lipschitz-Continuous epsilon-Optimal Value Functions
neurips,2018,1,3451,Olivier,Buffet,loria,INRIA / LORIA,olivier.buffet@loria.fr,rho-POMDPs have Lipschitz-Continuous epsilon-Optimal Value Functions
neurips,2018,2,3451,Vincent,Thomas,loria,LORIA / INRIA,vincent.thomas@loria.fr,rho-POMDPs have Lipschitz-Continuous epsilon-Optimal Value Functions
neurips,2018,3,3451,Jilles,Dibangoye,inria,"INRIA, INSA Lyon",jilles.dibangoye@inria.fr,rho-POMDPs have Lipschitz-Continuous epsilon-Optimal Value Functions
neurips,2018,0,1906,Kaiyi,Ji,osu,The Ohio State University,ji.367@osu.edu,Minimax Estimation of Neural Net Distance
neurips,2018,1,1906,Yingbin,Liang,osu,The Ohio State University,liang.889@osu.edu,Minimax Estimation of Neural Net Distance
neurips,2018,0,6461,Tomas,Geffner,umass,"University of Massachusetts, Amherst",domke@cs.umass.edu,Using Large Ensembles of Control Variates for Variational Inference
neurips,2018,1,6461,Justin,Domke,umass,"University of Massachusetts, Amherst",tgeffner@cs.umass.edu,Using Large Ensembles of Control Variates for Variational Inference
neurips,2018,0,1973,Hao,Wu,,Freie Universität Berlin,,Deep Generative Markov State Models
neurips,2018,1,1973,Andreas,Mardt,,,,Deep Generative Markov State Models
neurips,2018,2,1973,Luca,Pasquali,,Freie Universitat Berlin,,Deep Generative Markov State Models
neurips,2018,3,1973,Frank,Noe,,FU Berlin,,Deep Generative Markov State Models
neurips,2018,0,1148,Ofir,Marom,,University of the Witwatersrand,,Zero-Shot Transfer with Deictic Object-Oriented Representation in Reinforcement Learning
neurips,2018,1,1148,Benjamin,Rosman,,University of the Witwatersrand / CSIR,,Zero-Shot Transfer with Deictic Object-Oriented Representation in Reinforcement Learning
neurips,2018,0,1568,Debarghya,Ghoshdastidar,uni-tuebingen,University of Tübingen,ghoshdas@informatik.uni-tuebingen.de,Practical Methods for Graph Two-Sample Testing
neurips,2018,1,1568,Ulrike,von Luxburg,uni-tuebingen,University of Tübingen,luxburg@informatik.uni-tuebingen.de,Practical Methods for Graph Two-Sample Testing
neurips,2018,0,7992,Anuj,Sharma,,Columbia University,,Point process latent variable models of larval zebrafish behavior
neurips,2018,1,7992,Robert,Johnson,,Harvard University,,Point process latent variable models of larval zebrafish behavior
neurips,2018,2,7992,Florian,Engert,,Harvard University,,Point process latent variable models of larval zebrafish behavior
neurips,2018,3,7992,Scott,Linderman,,Columbia University,,Point process latent variable models of larval zebrafish behavior
neurips,2018,0,1233,Piotr,Mirowski,,DeepMind,,Learning to Navigate in Cities Without a Map
neurips,2018,1,1233,Matt,Grimes,,DeepMind,,Learning to Navigate in Cities Without a Map
neurips,2018,2,1233,Mateusz,Malinowski,,DeepMind,,Learning to Navigate in Cities Without a Map
neurips,2018,3,1233,Karl Moritz,Hermann,,DeepMind,,Learning to Navigate in Cities Without a Map
neurips,2018,4,1233,Keith,Anderson,,DeepMind,,Learning to Navigate in Cities Without a Map
neurips,2018,5,1233,Denis,Teplyashin,,DeepMind,,Learning to Navigate in Cities Without a Map
neurips,2018,6,1233,Karen,Simonyan,,DeepMind,,Learning to Navigate in Cities Without a Map
neurips,2018,7,1233,koray,kavukcuoglu,,Google DeepMind,,Learning to Navigate in Cities Without a Map
neurips,2018,8,1233,Andrew,Zisserman,,DeepMind & University of Oxford,,Learning to Navigate in Cities Without a Map
neurips,2018,9,1233,Raia,Hadsell,,DeepMind,,Learning to Navigate in Cities Without a Map
neurips,2018,0,2297,Kaito,Fujii,u-tokyo,university of Tokyo,kaito_fujii@mist.i.u-tokyo.ac.jp,Fast greedy algorithms for dictionary selection with generalized sparsity constraints
neurips,2018,1,2297,Tasuku,Soma,u-tokyo,University of Tokyo,tasuku_soma@mist.i.u-tokyo.ac.jp,Fast greedy algorithms for dictionary selection with generalized sparsity constraints
neurips,2018,0,1896,Jun-Kun,Wang,gatech,Georgia Institute of Technology,jimwang@gatech.edu,Acceleration through Optimistic No-Regret Dynamics
neurips,2018,1,1896,Jacob,Abernethy,gatech,Georgia Institute of Technolog,prof@gatech.edu,Acceleration through Optimistic No-Regret Dynamics
neurips,2018,0,778,Yuan,Li,duke,Duke University,yl558@duke.edu,Hybrid Retrieval-Generation Reinforced Agent for Medical Image Report Generation
neurips,2018,1,778,Xiaodan,Liang,cmu,Sun Yat-sen University,xiaodan1@cs.cmu.edu,Hybrid Retrieval-Generation Reinforced Agent for Medical Image Report Generation
neurips,2018,2,778,Zhiting,Hu,cmu,Carnegie Mellon University,zhitingh@cs.cmu.edu,Hybrid Retrieval-Generation Reinforced Agent for Medical Image Report Generation
neurips,2018,3,778,Eric,Xing,cmu,Petuum Inc. /  Carnegie Mellon University,epxing@cs.cmu.edu,Hybrid Retrieval-Generation Reinforced Agent for Medical Image Report Generation
neurips,2018,0,2949,Oren,Mangoubi,gmail,EPFL,omangoubi@gmail.com,Dimensionally Tight Bounds for Second-Order Hamiltonian Monte Carlo
neurips,2018,1,2949,Nisheeth,Vishnoi,gmail,EPFL,nisheeth.vishnoi@gmail.com,Dimensionally Tight Bounds for Second-Order Hamiltonian Monte Carlo
neurips,2018,0,5878,Fangchang,Ma,,MIT,,Invertibility of Convolutional Generative Networks from Partial Measurements
neurips,2018,1,5878,Ulas,Ayaz,,Massachusetts Institute of Technology / Lyft,,Invertibility of Convolutional Generative Networks from Partial Measurements
neurips,2018,2,5878,Sertac,Karaman,,MIT,,Invertibility of Convolutional Generative Networks from Partial Measurements
neurips,2018,0,2233,Tianyu,Pang,tsinghua,Tsinghua University,pty17@mails.tsinghua.edu.cn,Towards Robust Detection of Adversarial Examples
neurips,2018,1,2233,Chao,Du,tsinghua,Tsinghua University,du-c14@mails.tsinghua.edu.cn,Towards Robust Detection of Adversarial Examples
neurips,2018,2,2233,Yinpeng,Dong,tsinghua,Tsinghua University,dyp17@mails.tsinghua.edu.cn,Towards Robust Detection of Adversarial Examples
neurips,2018,3,2233,Jun,Zhu,tsinghua,Tsinghua University,dcszj@mail.tsinghua.edu.cn,Towards Robust Detection of Adversarial Examples
neurips,2018,0,3652,Jaesik,Yoon,,SAP,,Bayesian Model-Agnostic Meta-Learning
neurips,2018,1,3652,Taesup,Kim,,Université de Montréal,,Bayesian Model-Agnostic Meta-Learning
neurips,2018,2,3652,Ousmane,Dia,,Element AI,,Bayesian Model-Agnostic Meta-Learning
neurips,2018,3,3652,Sungwoong,Kim,,Kakao Brain,,Bayesian Model-Agnostic Meta-Learning
neurips,2018,4,3652,Yoshua,Bengio,,U. Montreal,,Bayesian Model-Agnostic Meta-Learning
neurips,2018,5,3652,Sungjin,Ahn,,Rutgers University,,Bayesian Model-Agnostic Meta-Learning
neurips,2018,0,3669,Victor-Emmanuel,Brunel,mit,ENSAE,vebrunel@mit.edu,Learning Signed Determinantal Point Processes through the Principal Minor Assignment Problem
neurips,2018,0,1882,Yuhao,Wang,mit,MIT,yuhaow@mit.edu,Direct Estimation of Differences in Causal Graphs
neurips,2018,1,1882,Chandler,Squires,mit,Massachusetts Institute of Technology,csquires@mit.edu,Direct Estimation of Differences in Causal Graphs
neurips,2018,2,1882,Anastasiya,Belyaeva,mit,MIT,belyaeva@mit.edu,Direct Estimation of Differences in Causal Graphs
neurips,2018,3,1882,Caroline,Uhler,mit,Massachusetts Institute of Technology,cuhler@mit.edu,Direct Estimation of Differences in Causal Graphs
neurips,2018,0,233,Yunpeng,Chen,nus,National University of Singapore,chenyunpeng@u.nus.edu,A^2-Nets: Double Attention Networks
neurips,2018,1,233,Yannis,Kalantidis,fb,Facebook,yannisk@fb.com,A^2-Nets: Double Attention Networks
neurips,2018,2,233,Jianshu,Li,nus,National University of Singapore,jianshu@u.nus.edu,A^2-Nets: Double Attention Networks
neurips,2018,3,233,Shuicheng,Yan,nus,National University of Singapore,eleyans@nus.edu.sg,A^2-Nets: Double Attention Networks
neurips,2018,4,233,Jiashi,Feng,nus,National University of Singapore,elefjia@nus.edu.sg,A^2-Nets: Double Attention Networks
neurips,2018,0,3784,Nan Rosemary,Ke,,"MILA, University of Montreal",,Sparse Attentive Backtracking: Temporal Credit Assignment Through Reminding
neurips,2018,1,3784,Anirudh Goyal,ALIAS PARTH GOYAL,,Université de Montréal,,Sparse Attentive Backtracking: Temporal Credit Assignment Through Reminding
neurips,2018,2,3784,Olexa,Bilaniuk,,University of Montreal,,Sparse Attentive Backtracking: Temporal Credit Assignment Through Reminding
neurips,2018,3,3784,Jonathan,Binas,,"MILA, Montreal",,Sparse Attentive Backtracking: Temporal Credit Assignment Through Reminding
neurips,2018,4,3784,Michael,Mozer,,Google Brain / U. Colorado,,Sparse Attentive Backtracking: Temporal Credit Assignment Through Reminding
neurips,2018,5,3784,Chris,Pal,,"MILA, Polytechnique Montréal, Element AI",,Sparse Attentive Backtracking: Temporal Credit Assignment Through Reminding
neurips,2018,6,3784,Yoshua,Bengio,,U. Montreal,,Sparse Attentive Backtracking: Temporal Credit Assignment Through Reminding
neurips,2018,0,1243,Shannon,McCurdy,berkeley,Ancestry,smccurdy@berkeley.edu,Ridge Regression and Provable Deterministic Ridge Leverage Score Sampling
neurips,2018,0,6431,Elahe,Ghalebi,tuwien,TU Wien,eghalebi@cps.tuwien.ac.at,Dynamic Network Model from Partial Observations
neurips,2018,1,6431,Baharan,Mirzasoleiman,stanford,Stanford University,baharanm@cs.stanford.edu,Dynamic Network Model from Partial Observations
neurips,2018,2,6431,Radu,Grosu,tuwien,TU Wien,radu.grosu@tuwien.ac.at,Dynamic Network Model from Partial Observations
neurips,2018,3,6431,Jure,Leskovec,stanford,Stanford University and Pinterest,jure@cs.stanford.edu,Dynamic Network Model from Partial Observations
neurips,2018,0,1156,Mikhail,Belkin,,Ohio State University,,Overfitting or perfect fitting? Risk bounds for classification and regression rules that interpolate
neurips,2018,1,1156,Daniel,Hsu,,Columbia University,,Overfitting or perfect fitting? Risk bounds for classification and regression rules that interpolate
neurips,2018,2,1156,Partha,Mitra,,Cold Spring Harbor Laboratory,,Overfitting or perfect fitting? Risk bounds for classification and regression rules that interpolate
neurips,2018,0,1760,Sriram,Srinivasan,,Google,,Actor-Critic Policy Optimization in Partially Observable Multiagent Environments
neurips,2018,1,1760,Marc,Lanctot,,DeepMind,,Actor-Critic Policy Optimization in Partially Observable Multiagent Environments
neurips,2018,2,1760,Vinicius,Zambaldi,,Deepmind,,Actor-Critic Policy Optimization in Partially Observable Multiagent Environments
neurips,2018,3,1760,Julien,Perolat,,DeepMind,,Actor-Critic Policy Optimization in Partially Observable Multiagent Environments
neurips,2018,4,1760,Karl,Tuyls,,DeepMind,,Actor-Critic Policy Optimization in Partially Observable Multiagent Environments
neurips,2018,5,1760,Remi,Munos,,DeepMind,,Actor-Critic Policy Optimization in Partially Observable Multiagent Environments
neurips,2018,6,1760,Michael,Bowling,,DeepMind / University of Alberta,,Actor-Critic Policy Optimization in Partially Observable Multiagent Environments
neurips,2018,0,2187,Linfeng,Zhang,,Princeton University,,End-to-end Symmetry Preserving Inter-atomic Potential Energy Model for Finite and Extended Systems
neurips,2018,1,2187,Jiequn,Han,,Princeton University,,End-to-end Symmetry Preserving Inter-atomic Potential Energy Model for Finite and Extended Systems
neurips,2018,2,2187,Han,Wang,,Institute of Applied Physics and Computational Mathematics,,End-to-end Symmetry Preserving Inter-atomic Potential Energy Model for Finite and Extended Systems
neurips,2018,3,2187,Wissam,Saidi,,University of Pittsburgh,,End-to-end Symmetry Preserving Inter-atomic Potential Energy Model for Finite and Extended Systems
neurips,2018,4,2187,Roberto,Car,,Princeton University,,End-to-end Symmetry Preserving Inter-atomic Potential Energy Model for Finite and Extended Systems
neurips,2018,5,2187,Weinan,E,,Princeton University,,End-to-end Symmetry Preserving Inter-atomic Potential Energy Model for Finite and Extended Systems
neurips,2018,0,3634,Adam,Santoro,,DeepMind,,Relational recurrent neural networks
neurips,2018,1,3634,Ryan,Faulkner,,Deepmind,,Relational recurrent neural networks
neurips,2018,2,3634,David,Raposo,,DeepMind,,Relational recurrent neural networks
neurips,2018,3,3634,Jack,Rae,,"DeepMind, UCL",,Relational recurrent neural networks
neurips,2018,4,3634,Mike,Chrzanowski,,DeepMind,,Relational recurrent neural networks
neurips,2018,5,3634,Theophane,Weber,,DeepMind,,Relational recurrent neural networks
neurips,2018,6,3634,Daan,Wierstra,,DeepMind Technologies,,Relational recurrent neural networks
neurips,2018,7,3634,Oriol,Vinyals,,Google DeepMind,,Relational recurrent neural networks
neurips,2018,8,3634,Razvan,Pascanu,,Google DeepMind,,Relational recurrent neural networks
neurips,2018,9,3634,Timothy,Lillicrap,,Google DeepMind,,Relational recurrent neural networks
neurips,2018,0,4972,Xundong,Wu,,Hangzhou Dianzi University,,Improved Expressivity Through Dendritic Neural Networks
neurips,2018,1,4972,Xiangwen,Liu,,Hangzhou Dianzi University,,Improved Expressivity Through Dendritic Neural Networks
neurips,2018,2,4972,Wei,Li,,Hangzhou Dianzi University,,Improved Expressivity Through Dendritic Neural Networks
neurips,2018,3,4972,Qing,Wu,,Hangzhou Dianzi University,,Improved Expressivity Through Dendritic Neural Networks
neurips,2018,0,5750,Xun,Zheng,cmu,Carnegie Mellon University,xunzheng@cs.cmu.edu,DAGs with NO TEARS: Continuous Optimization for Structure Learning
neurips,2018,1,5750,Bryon,Aragam,cmu,Carnegie Mellon University,naragam@cs.cmu.edu,DAGs with NO TEARS: Continuous Optimization for Structure Learning
neurips,2018,2,5750,Pradeep,Ravikumar,cmu,Carnegie Mellon University,pradeepr@cs.cmu.edu,DAGs with NO TEARS: Continuous Optimization for Structure Learning
neurips,2018,3,5750,Eric,Xing,cmu,Petuum Inc. /  Carnegie Mellon University,epxing@cs.cmu.edu,DAGs with NO TEARS: Continuous Optimization for Structure Learning
neurips,2018,0,34,Guangrun,Wang,,Sun Yat-sen University,,Kalman Normalization: Normalizing Internal Representations Across Network Layers
neurips,2018,1,34,jiefeng,peng,,Sun Yat-sen University,,Kalman Normalization: Normalizing Internal Representations Across Network Layers
neurips,2018,2,34,Ping,Luo,,The Chinese University of Hong Kong,,Kalman Normalization: Normalizing Internal Representations Across Network Layers
neurips,2018,3,34,Xinjiang,Wang,,SenseTime Group Ltd.,,Kalman Normalization: Normalizing Internal Representations Across Network Layers
neurips,2018,4,34,Liang,Lin,,Sun Yat-Sen University,,Kalman Normalization: Normalizing Internal Representations Across Network Layers
neurips,2018,0,454,Hu,Liu,tsinghua,Tsinghua University,liuhu15@mails.tsinghua.edu.cn,Connectionist Temporal Classification with Maximum Entropy Regularization
neurips,2018,1,454,Sheng,Jin,tsinghua,Tsinghua University,js17@mails.tsinghua.edu.cn,Connectionist Temporal Classification with Maximum Entropy Regularization
neurips,2018,2,454,Changshui,Zhang,tsinghua,Tsinghua University,zcs@mail.tsinghua.edu.cn,Connectionist Temporal Classification with Maximum Entropy Regularization
neurips,2018,0,397,Mario,Lucic,,Google Brain,,Are GANs Created Equal? A Large-Scale Study
neurips,2018,1,397,Karol,Kurach,,Google Brain,,Are GANs Created Equal? A Large-Scale Study
neurips,2018,2,397,Marcin,Michalski,,Google,,Are GANs Created Equal? A Large-Scale Study
neurips,2018,3,397,Sylvain,Gelly,,Google Brain (Zurich),,Are GANs Created Equal? A Large-Scale Study
neurips,2018,4,397,Olivier,Bousquet,,Google Brain (Zurich),,Are GANs Created Equal? A Large-Scale Study
neurips,2018,0,3020,Seungryong,Kim,ewha,Yonsei University,dbmin@ewha.ac.kr,Recurrent Transformer Networks for Semantic Correspondence
neurips,2018,1,3020,Stephen,Lin,yonsei,Microsoft Research,srkim89@yonsei.ac.kr,Recurrent Transformer Networks for Semantic Correspondence
neurips,2018,2,3020,SANG RYUL,JEON,yonsei,Yonsei University,cheonjsr@yonsei.ac.kr,Recurrent Transformer Networks for Semantic Correspondence
neurips,2018,3,3020,Dongbo,Min,yonsei,Ewha Womans University,khsohn@yonsei.ac.kr,Recurrent Transformer Networks for Semantic Correspondence
neurips,2018,4,3020,Kwanghoon,Sohn,microsoft,Yonsei Univ.,stevelin@microsoft.com,Recurrent Transformer Networks for Semantic Correspondence
neurips,2018,0,695,Harshil,Shah,,UCL,,Generative Neural Machine Translation
neurips,2018,1,695,David,Barber,,University College London,,Generative Neural Machine Translation
neurips,2018,0,692,Chengyue,Gong,pku,Peking University,cygong@pku.edu.cn,FRAGE: Frequency-Agnostic Word Representation
neurips,2018,1,692,Di,He,pku,Peking University,di_he@pku.edu.cn,FRAGE: Frequency-Agnostic Word Representation
neurips,2018,2,692,Xu,Tan,microsoft,,xu.tan@microsoft.com,FRAGE: Frequency-Agnostic Word Representation
neurips,2018,3,692,Tao,Qin,microsoft,Microsoft Research,taoqin@microsoft.com,FRAGE: Frequency-Agnostic Word Representation
neurips,2018,4,692,Liwei,Wang,pku,Peking University,wanglw@cis.pku.edu.cn,FRAGE: Frequency-Agnostic Word Representation
neurips,2018,5,692,Tie-Yan,Liu,microsoft,Microsoft Research Asia,tie-yan.liu@microsoft.com,FRAGE: Frequency-Agnostic Word Representation
neurips,2018,0,772,Hung,Le,deakin,Deakin University,lethai@deakin.edu.au,Variational Memory Encoder-Decoder
neurips,2018,1,772,Truyen,Tran,deakin,Deakin University,truyen.tran@deakin.edu.au,Variational Memory Encoder-Decoder
neurips,2018,2,772,Thin,Nguyen,deakin,Deakin University,thin.nguyen@deakin.edu.au,Variational Memory Encoder-Decoder
neurips,2018,3,772,Svetha,Venkatesh,deakin,Deakin University,svetha.venkatesh@deakin.edu.au,Variational Memory Encoder-Decoder
neurips,2018,0,700,Hajin,Shim,,KAIST,,Joint Active Feature Acquisition and Classification with Variable-Size Set Encoding
neurips,2018,1,700,Sung Ju,Hwang,,"KAIST, AItrics",,Joint Active Feature Acquisition and Classification with Variable-Size Set Encoding
neurips,2018,2,700,Eunho,Yang,,Korea Advanced Institute of Science and Technology; AItrics,,Joint Active Feature Acquisition and Classification with Variable-Size Set Encoding
neurips,2018,0,1679,Ofir,Nachum,google,Google Brain,ofirnachum@google.com,Data-Efficient Hierarchical Reinforcement Learning
neurips,2018,1,1679,Shixiang (Shane),Gu,google,"Google Brain, University of Cambridge",honglak@google.com,Data-Efficient Hierarchical Reinforcement Learning
neurips,2018,2,1679,Honglak,Lee,google,Google Brain,shanegu@google.com,Data-Efficient Hierarchical Reinforcement Learning
neurips,2018,3,1679,Sergey,Levine,google,UC Berkeley,slevine@google.com,Data-Efficient Hierarchical Reinforcement Learning
neurips,2018,0,1247,Osbert,Bastani,mit,University of Pennsylvania,obastani@csail.mit.edu,Verifiable Reinforcement Learning via Policy Extraction
neurips,2018,1,1247,Yewen,Pu,mit,MIT,yewenpu@mit.edu,Verifiable Reinforcement Learning via Policy Extraction
neurips,2018,2,1247,Armando,Solar-Lezama,mit,MIT,asolar@csail.mit.edu,Verifiable Reinforcement Learning via Policy Extraction
neurips,2018,0,1695,Dmitry,Kovalev,,KAUST,,Stochastic Spectral and Conjugate Descent Methods
neurips,2018,1,1695,Peter,Richtarik,,KAUST,,Stochastic Spectral and Conjugate Descent Methods
neurips,2018,2,1695,Eduard,Gorbunov,,Moscow Institute of Physics and Technology,,Stochastic Spectral and Conjugate Descent Methods
neurips,2018,3,1695,Elnur,Gasanov,,MIPT,,Stochastic Spectral and Conjugate Descent Methods
neurips,2018,0,2665,Zhize,Li,tsinghua,Tsinghua University,zz-li14@mails.tsinghua.edu.cn,A Simple Proximal Stochastic Gradient Method for Nonsmooth Nonconvex Optimization
neurips,2018,1,2665,Jian,Li,tsinghua,Tsinghua University,lijian83@mail.tsinghua.edu.cn,A Simple Proximal Stochastic Gradient Method for Nonsmooth Nonconvex Optimization
neurips,2018,0,2332,Zhitao,Ying,stanford,Stanford University,rexying@stanford.edu,Hierarchical Graph Representation Learning with Differentiable Pooling
neurips,2018,1,2332,Jiaxuan,You,stanford,Stanford University,jiaxuan@stanford.edu,Hierarchical Graph Representation Learning with Differentiable Pooling
neurips,2018,2,2332,Christopher,Morris,udo,TU Dortmund University,christopher.morris@udo.edu,Hierarchical Graph Representation Learning with Differentiable Pooling
neurips,2018,3,2332,Xiang,Ren,usc,University of Southern California,xiangren@usc.edu,Hierarchical Graph Representation Learning with Differentiable Pooling
neurips,2018,4,2332,Will,Hamilton,stanford,McGill University / FAIR,wleif@stanford.edu,Hierarchical Graph Representation Learning with Differentiable Pooling
neurips,2018,5,2332,Jure,Leskovec,stanford,Stanford University and Pinterest,jure@cs.stanford.edu,Hierarchical Graph Representation Learning with Differentiable Pooling
neurips,2018,0,4902,Zhihao,Zheng,brandeis,Brandeis University,zhihaozh@brandeis.edu,Robust Detection of Adversarial Attacks by Modeling the Intrinsic Properties of Deep Neural Networks
neurips,2018,1,4902,Pengyu,Hong,brandeis,Brandeis University,hongpeng@brandeis.edu,Robust Detection of Adversarial Attacks by Modeling the Intrinsic Properties of Deep Neural Networks
neurips,2018,0,360,Zijun,Zhang,ucalgary,University of Calgary,zijun.zhang@ucalgary.ca,Removing the Feature Correlation Effect of Multiplicative Noise
neurips,2018,1,360,Yining,Zhang,ucalgary,University of Calgary,yining.zhang1@ucalgary.ca,Removing the Feature Correlation Effect of Multiplicative Noise
neurips,2018,2,360,Zongpeng,Li,whu,Wuhan University,zongpeng@whu.edu.cn,Removing the Feature Correlation Effect of Multiplicative Noise
neurips,2018,0,5672,Lingjiao,Chen,,University of Wisconsin-Madison,,The Effect of Network Width on the Performance of  Large-batch Training
neurips,2018,1,5672,Hongyi,Wang,,University of Wisconsin-Madison,,The Effect of Network Width on the Performance of  Large-batch Training
neurips,2018,2,5672,Jinman,Zhao,,University of Wisconsin-Madison,,The Effect of Network Width on the Performance of  Large-batch Training
neurips,2018,3,5672,Dimitris,Papailiopoulos,,UW-Madison,,The Effect of Network Width on the Performance of  Large-batch Training
neurips,2018,4,5672,Paraschos,Koutris,,University of Wisconsin-Madison,,The Effect of Network Width on the Performance of  Large-batch Training
neurips,2018,0,3599,Itay,Evron,gmail,Technion,evron.itay@gmail.com,Efficient Loss-Based Decoding on Graphs for Extreme Classification
neurips,2018,1,3599,Edward,Moroshko,gmail,Technion,edward.moroshko@gmail.com,Efficient Loss-Based Decoding on Graphs for Extreme Classification
neurips,2018,2,3599,Koby,Crammer,technion,Technion,koby@ee.technion.ac.il,Efficient Loss-Based Decoding on Graphs for Extreme Classification
neurips,2018,0,2468,Ron,Banner,gmail,Intel - Artificial Intelligence Products Group (AIPG),itayhubara@gmail.com,Scalable methods for 8-bit training of neural networks
neurips,2018,1,2468,Itay,Hubara,gmail,Technion,elad.hoffer@gmail.com,Scalable methods for 8-bit training of neural networks
neurips,2018,2,2468,Elad,Hoffer,gmail,Technion,daniel.soudry@gmail.com,Scalable methods for 8-bit training of neural networks
neurips,2018,3,2468,Daniel,Soudry,intel,Technion,ron.banner@intel.com,Scalable methods for 8-bit training of neural networks
neurips,2018,0,466,Christian,Kroer,,"Faceook, Core Data Science",,Solving Large Sequential Games with the Excessive Gap Technique
neurips,2018,1,466,Gabriele,Farina,,Carnegie Mellon University,,Solving Large Sequential Games with the Excessive Gap Technique
neurips,2018,2,466,Tuomas,Sandholm,,Carnegie Mellon University,,Solving Large Sequential Games with the Excessive Gap Technique
neurips,2018,0,1767,Kamil,Nar,,"University of California, Berkeley",,Step Size Matters in Deep Learning
neurips,2018,1,1767,Shankar,Sastry,,"Department of EECS, UC Berkeley",,Step Size Matters in Deep Learning
neurips,2018,0,4891,Matteo,Almanza,uniroma1,Sapienza University of Rome,almanza@di.uniroma1.it,A Reduction for Efficient LDA Topic Reconstruction
neurips,2018,1,4891,Flavio,Chierichetti,uniroma1,Sapienza University,flavio@di.uniroma1.it,A Reduction for Efficient LDA Topic Reconstruction
neurips,2018,2,4891,Alessandro,Panconesi,uniroma1,"Sapienza, University of Rome",ale@di.uniroma1.it,A Reduction for Efficient LDA Topic Reconstruction
neurips,2018,3,4891,Andrea,Vattani,ucsd,UC San Diego,avattani@cs.ucsd.edu,A Reduction for Efficient LDA Topic Reconstruction
neurips,2018,0,6666,Jessica,Finocchiaro,colorado,University of Colorado Boulder,jessica.finocchiaro@colorado.edu,Convex Elicitation of Continuous Properties
neurips,2018,1,6666,Rafael,Frongillo,colorado,CU Boulder,raf@colorado.edu,Convex Elicitation of Continuous Properties
neurips,2018,0,1614,Jiantao,Jiao,berkeley,"University of California, Berkeley",jiantao@berkeley.edu,The Nearest Neighbor Information Estimator is Adaptively Near Minimax Rate-Optimal
neurips,2018,1,1614,Weihao,Gao,illinois,UIUC,wgao9@illinois.edu,The Nearest Neighbor Information Estimator is Adaptively Near Minimax Rate-Optimal
neurips,2018,2,1614,Yanjun,Han,stanford,Stanford University,yjhan@stanford.edu,The Nearest Neighbor Information Estimator is Adaptively Near Minimax Rate-Optimal
neurips,2018,0,2384,Virag,Shah,stanford,Stanford,virag@stanford.edu,Bandit Learning with Positive Externalities
neurips,2018,1,2384,Jose,Blanchet,stanford,Stanford University,jblanche@stanford.edu,Bandit Learning with Positive Externalities
neurips,2018,2,2384,Ramesh,Johari,stanford,Stanford University,rjohari@stanford.edu,Bandit Learning with Positive Externalities
neurips,2018,0,1380,Jaeho,Lee,illinois,University of Illinois at Urbana-Champaign,jlee620@illinois.edu,Minimax Statistical Learning with Wasserstein distances
neurips,2018,1,1380,Maxim,Raginsky,illinois,University of Illinois at Urbana-Champaign,maxim@illinois.edu,Minimax Statistical Learning with Wasserstein distances
neurips,2018,0,4925,He,Zhao,,"Monash University, Australia",,Dirichlet belief networks for topic structure learning
neurips,2018,1,4925,Lan,Du,,Monash University,,Dirichlet belief networks for topic structure learning
neurips,2018,2,4925,Wray,Buntine,,Monash University,,Dirichlet belief networks for topic structure learning
neurips,2018,3,4925,Mingyuan,Zhou,,University of Texas at Austin,,Dirichlet belief networks for topic structure learning
neurips,2018,0,997,Pan,Zhou,nus,National University of Singapore,pzhou@u.nus.edu,Efficient Stochastic Gradient Hard Thresholding
neurips,2018,1,997,Xiaotong,Yuan,nuist,Nanjing University of Information Science and Technology,xtyuan@nuist.edu.cn,Efficient Stochastic Gradient Hard Thresholding
neurips,2018,2,997,Jiashi,Feng,nus,National University of Singapore,elefjia@nus.edu.sg,Efficient Stochastic Gradient Hard Thresholding
neurips,2018,0,102,Drew,Linsley,,Brown University,,Learning long-range spatial dependencies with horizontal gated recurrent units
neurips,2018,1,102,Junkyung,Kim,,Brown University,,Learning long-range spatial dependencies with horizontal gated recurrent units
neurips,2018,2,102,Vijay,Veerabadran,,"University of California, San Diego",,Learning long-range spatial dependencies with horizontal gated recurrent units
neurips,2018,3,102,Charles,Windolf,,Brown University,,Learning long-range spatial dependencies with horizontal gated recurrent units
neurips,2018,4,102,Thomas,Serre,,Brown University,,Learning long-range spatial dependencies with horizontal gated recurrent units
neurips,2018,0,1825,Jiecao,Chen,iu,Indiana University Bloomington,jiecchen@iu.edu,Tight Bounds for Collaborative PAC Learning via Multiplicative Weights
neurips,2018,1,1825,Qin,Zhang,indiana,Indiana University Bloomington,qzhangcs@indiana.edu,Tight Bounds for Collaborative PAC Learning via Multiplicative Weights
neurips,2018,2,1825,Yuan,Zhou,illinois,Indiana University Bloomington,yuanz@illinois.edu,Tight Bounds for Collaborative PAC Learning via Multiplicative Weights
neurips,2018,0,267,Haggai,Maron,weizmann,Weizmann Institute of Science,haggai.maron@weizmann.ac.il,(Probably) Concave Graph Matching
neurips,2018,1,267,Yaron,Lipman,weizmann,Weizmann Institute of Science,yaron.lipman@weizmann.ac.il,(Probably) Concave Graph Matching
neurips,2018,0,5246,Lazar,Valkov,ed,University of Edinburgh,L.Valkov@sms.ed.ac.uk,HOUDINI: Lifelong Learning as Program Synthesis
neurips,2018,1,5246,Dipak,Chaudhari,rice,Rice University,dipakc@rice.edu,HOUDINI: Lifelong Learning as Program Synthesis
neurips,2018,2,5246,Akash,Srivastava,ed,University of Edinburgh,Akash.Srivastava@ed.ac.uk,HOUDINI: Lifelong Learning as Program Synthesis
neurips,2018,3,5246,Charles,Sutton,google,Google,charlessutton@google.com,HOUDINI: Lifelong Learning as Program Synthesis
neurips,2018,4,5246,Swarat,Chaudhuri,rice,Rice University,swarat@rice.edu,HOUDINI: Lifelong Learning as Program Synthesis
neurips,2018,0,867,Jingwei,Xu,sjtu,Shanghai Jiao Tong University,xjwxjw@sjtu.edu.cn,Video Prediction via Selective Sampling
neurips,2018,1,867,Bingbing,Ni,sjtu,Shanghai Jiao Tong University,nibingbing@sjtu.edu.cn,Video Prediction via Selective Sampling
neurips,2018,2,867,Xiaokang,Yang,sjtu,Shanghai Jiao Tong University,xkyang@sjtu.edu.cn,Video Prediction via Selective Sampling
neurips,2018,0,3522,Anirvan,Sengupta,rutgers,Rutgers University,anirvans@physics.rutgers.edu,Manifold-tiling Localized Receptive Fields are Optimal in Similarity-preserving Neural Networks
neurips,2018,1,3522,Cengiz,Pehlevan,gmail,Flatiron Institute,alexander.genkin@gmail.com,Manifold-tiling Localized Receptive Fields are Optimal in Similarity-preserving Neural Networks
neurips,2018,2,3522,Mariano,Tepper,flatironinstitute,Intel Labs,mtepper@flatironinstitute.org,Manifold-tiling Localized Receptive Fields are Optimal in Similarity-preserving Neural Networks
neurips,2018,3,3522,Alexander,Genkin,flatironinstitute,"Neuroscience Institute, NYU Langone Health",cpehlevan@flatironinstitute.org,Manifold-tiling Localized Receptive Fields are Optimal in Similarity-preserving Neural Networks
neurips,2018,4,3522,Dmitri,Chklovskii,flatironinstitute,"Flatiron Institute, Simons Foundation",dchklovskii@flatironinstitute.org,Manifold-tiling Localized Receptive Fields are Optimal in Similarity-preserving Neural Networks
neurips,2018,0,185,Celestine,Dünner,ibm,IBM Research,cdu@zurich.ibm.com,Snap ML: A Hierarchical Framework for Machine Learning
neurips,2018,1,185,Thomas,Parnell,ibm,IBM Research,tpa@zurich.ibm.com,Snap ML: A Hierarchical Framework for Machine Learning
neurips,2018,2,185,Dimitrios,Sarigiannis,ibm,IBM Research,rig@zurich.ibm.com,Snap ML: A Hierarchical Framework for Machine Learning
neurips,2018,3,185,Nikolas,Ioannou,ibm,IBM Research,nio@zurich.ibm.com,Snap ML: A Hierarchical Framework for Machine Learning
neurips,2018,4,185,Andreea,Anghel,ibm,IBM Research,aan@zurich.ibm.com,Snap ML: A Hierarchical Framework for Machine Learning
neurips,2018,5,185,Gummadi,Ravi,ibm,IBM Systems,ravigumm@in.ibm.com,Snap ML: A Hierarchical Framework for Machine Learning
neurips,2018,6,185,Madhusudanan,Kandasamy,ibm,IBM Systems,madhusudanan@in.ibm.com,Snap ML: A Hierarchical Framework for Machine Learning
neurips,2018,7,185,Haralampos,Pozidis,ibm,IBM Research,hap@zurich.ibm.com,Snap ML: A Hierarchical Framework for Machine Learning
neurips,2018,0,1018,Will,Hamilton,stanford,McGill University / FAIR,wleif@stanford.edu,Embedding Logical Queries on Knowledge Graphs
neurips,2018,1,1018,Payal,Bajaj,stanford,Stanford University,pbajaj@stanford.edu,Embedding Logical Queries on Knowledge Graphs
neurips,2018,2,1018,Marinka,Zitnik,stanford,Stanford University,jurafsky@stanford.edu,Embedding Logical Queries on Knowledge Graphs
neurips,2018,3,1018,Dan,Jurafsky,stanford,Stanford University,jure@cs.stanford.edu,Embedding Logical Queries on Knowledge Graphs
neurips,2018,4,1018,Jure,Leskovec,stanford,Stanford University and Pinterest,marinka@cs.stanford.edu,Embedding Logical Queries on Knowledge Graphs
neurips,2018,0,1628,Mingyuan,Zhou,utexas,University of Texas at Austin,mingyuan.zhou@mccombs.utexas.edu,Parsimonious Bayesian deep networks
neurips,2018,0,5026,Jacob,Buckman,gmail,Johns Hopkins University,jacobbuckman@gmail.com,Sample-Efficient Reinforcement Learning with Stochastic Ensemble Value Expansion
neurips,2018,1,5026,Danijar,Hafner,danijar,Google Brain & UCL,mail@danijar.com,Sample-Efficient Reinforcement Learning with Stochastic Ensemble Value Expansion
neurips,2018,2,5026,George,Tucker,google,Google Brain,gjt@google.com,Sample-Efficient Reinforcement Learning with Stochastic Ensemble Value Expansion
neurips,2018,3,5026,Eugene,Brevdo,google,Google,ebrevdo@google.com,Sample-Efficient Reinforcement Learning with Stochastic Ensemble Value Expansion
neurips,2018,4,5026,Honglak,Lee,google,Google Brain,honglak@google.com,Sample-Efficient Reinforcement Learning with Stochastic Ensemble Value Expansion
neurips,2018,0,818,Yunhe,Wang,huawei,"Noahs Ark Laboratory, Huawei Technologies Co., Ltd.",yunhe.wang@huawei.com,Learning Versatile Filters for Efficient Convolutional Neural Networks
neurips,2018,1,818,Chang,Xu,sydney,The University of Sydney,c.xu@sydney.edu.au,Learning Versatile Filters for Efficient Convolutional Neural Networks
neurips,2018,2,818,Chunjing,XU,huawei,Huawei Technologies,xuchunjing@huawei.com,Learning Versatile Filters for Efficient Convolutional Neural Networks
neurips,2018,3,818,Chao,Xu,pku,Peking University,xuchao@cis.pku.edu.cn,Learning Versatile Filters for Efficient Convolutional Neural Networks
neurips,2018,4,818,Dacheng,Tao,sydney,"University of Technology, Sydney",dacheng.tao@sydney.edu.au,Learning Versatile Filters for Efficient Convolutional Neural Networks
neurips,2018,0,574,Tobias,Plötz,,TU Darmstadt,,Neural Nearest Neighbors Networks
neurips,2018,1,574,Stefan,Roth,,TU Darmstadt,,Neural Nearest Neighbors Networks
neurips,2018,0,1605,Kevin,Bello,purdue,Purdue University,jhonorio@purdue.edu,Learning latent variable structured prediction models with Gaussian perturbations
neurips,2018,1,1605,Jean,Honorio,purdue,Purdue University,kbellome@purdue.edu,Learning latent variable structured prediction models with Gaussian perturbations
neurips,2018,0,6905,Rachel,Cummings,gatech,Georgia Tech,rachelc@gatech.edu,Differentially Private Change-Point Detection
neurips,2018,1,6905,Sara,Krehbiel,richmond,University of Richmond,krehbiel@richmond.edu,Differentially Private Change-Point Detection
neurips,2018,2,6905,Yajun,Mei,gatech,Georgia Institute of Technology,ymei@gatech.edu,Differentially Private Change-Point Detection
neurips,2018,3,6905,Rui,Tuo,tamu,Texas A&M University,ruituo@tamu.edu,Differentially Private Change-Point Detection
neurips,2018,4,6905,Wanrong,Zhang,gatech,Georgia Institute of Technology,wanrongz@gatech.edu,Differentially Private Change-Point Detection
neurips,2018,0,4984,Debarun,Bhattacharjya,ibm,IBM Research,debarunb@us.ibm.com,Proximal Graphical Event Models
neurips,2018,1,4984,Dharmashankar,Subramanian,ibm,IBM Research,dharmash@us.ibm.com,Proximal Graphical Event Models
neurips,2018,2,4984,Tian,Gao,ibm,IBM Research AI,tgao@us.ibm.com,Proximal Graphical Event Models
neurips,2018,0,2641,Geneviève,Robin,polytechnique,École Polytechnique,genevieve.robin@polytechnique.edu,Low-rank Interaction with Sparse Additive Effects Model for Large Data Frames
neurips,2018,1,2641,Hoi-To,Wai,cuhk,The Chinese University of Hong Kong,htwai@se.cuhk.edu.hk,Low-rank Interaction with Sparse Additive Effects Model for Large Data Frames
neurips,2018,2,2641,Julie,Josse,polytechnique,École Polytechnique,julie.josse@polytechnique.edu,Low-rank Interaction with Sparse Additive Effects Model for Large Data Frames
neurips,2018,3,2641,Olga,Klopp,essec,Université Paris Ouest,klopp@essec.edu,Low-rank Interaction with Sparse Additive Effects Model for Large Data Frames
neurips,2018,4,2641,Eric,Moulines,polytechnique,Ecole Polytechnique,eric.moulines@polytechnique.edu,Low-rank Interaction with Sparse Additive Effects Model for Large Data Frames
neurips,2018,0,5289,Zhilu,Zhang,cornell,Cornell University,zz452@cornell.edu,Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels
neurips,2018,1,5289,Mert,Sabuncu,cornell,Cornell,msabuncu@cornell.edu,Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels
neurips,2018,0,2646,Zehong,Hu,ntu,Alibaba Group,HUZE0004@e.ntu.edu.sg,Inference Aided Reinforcement Learning for Incentive Mechanism Design in Crowdsourcing
neurips,2018,1,2646,Yitao,Liang,ucla,UCLA,yliang@cs.ucla.edu,Inference Aided Reinforcement Learning for Incentive Mechanism Design in Crowdsourcing
neurips,2018,2,2646,Jie,Zhang,ntu,Nanyang Technological University,ZhangJ@ntu.edu.sg,Inference Aided Reinforcement Learning for Incentive Mechanism Design in Crowdsourcing
neurips,2018,3,2646,Zhao,Li,alibaba-inc,Alibaba Group,lizhao.lz@alibaba-inc.com,Inference Aided Reinforcement Learning for Incentive Mechanism Design in Crowdsourcing
neurips,2018,4,2646,Yang,Liu,ucsc,Harvard University,yangliu@ucsc.edu,Inference Aided Reinforcement Learning for Incentive Mechanism Design in Crowdsourcing
neurips,2018,0,6892,Gagandeep,Singh,ethz,ETH Zurich,gsingh@inf.ethz.ch,Fast and Effective Robustness Certification
neurips,2018,1,6892,Timon,Gehr,ethz,ETH Zurich,timon.gehr@inf.ethz.ch,Fast and Effective Robustness Certification
neurips,2018,2,6892,Matthew,Mirman,ethz,ETH Zurich,matthew.mirman@inf.ethz.ch,Fast and Effective Robustness Certification
neurips,2018,3,6892,Markus,Püschel,ethz,ETH Zurich,pueschel@inf.ethz.ch,Fast and Effective Robustness Certification
neurips,2018,4,6892,Martin,Vechev,ethz,"DeepCode and ETH Zurich, Switzerland",martin.vechev@inf.ethz.ch,Fast and Effective Robustness Certification
neurips,2018,0,1877,Hippolyt,Ritter,,University College London,,Online Structured Laplace Approximations for Overcoming Catastrophic Forgetting
neurips,2018,1,1877,Aleksandar,Botev,,University College London,,Online Structured Laplace Approximations for Overcoming Catastrophic Forgetting
neurips,2018,2,1877,David,Barber,,University College London,,Online Structured Laplace Approximations for Overcoming Catastrophic Forgetting
neurips,2018,0,1544,Dimitris,Bertsimas,mit,Massachusetts Institute of Technology,dbertsim@mit.edu,Optimization over Continuous and Multi-dimensional Decisions with Observational Data
neurips,2018,1,1544,Christopher,McCord,mit,MIT,mccord@mit.edu,Optimization over Continuous and Multi-dimensional Decisions with Observational Data
neurips,2018,0,1012,Kirthevasan,Kandasamy,cmu,Carnegie Mellon University,kandasamy@cs.cmu.edu,Neural Architecture Search with Bayesian Optimisation and Optimal Transport
neurips,2018,1,1012,Willie,Neiswanger,cmu,Carnegie Mellon University,willie@cs.cmu.edu,Neural Architecture Search with Bayesian Optimisation and Optimal Transport
neurips,2018,2,1012,Jeff,Schneider,cmu,CMU,schneide@cs.cmu.edu,Neural Architecture Search with Bayesian Optimisation and Optimal Transport
neurips,2018,3,1012,Barnabas,Poczos,cmu,Carnegie Mellon University,bapoczos@cs.cmu.edu,Neural Architecture Search with Bayesian Optimisation and Optimal Transport
neurips,2018,4,1012,Eric,Xing,cmu,Petuum Inc. /  Carnegie Mellon University,epxing@cs.cmu.edu,Neural Architecture Search with Bayesian Optimisation and Optimal Transport
neurips,2018,0,2053,Shi,Dong,stanford,Stanford University,sdong15@stanford.edu,An Information-Theoretic Analysis for Thompson Sampling with Many Actions
neurips,2018,1,2053,Benjamin,Van Roy,stanford,Stanford University,bvr@stanford.edu,An Information-Theoretic Analysis for Thompson Sampling with Many Actions
neurips,2018,0,2078,Songtao,Wang,,Tsinghua University,,"BML: A High-performance, Low-cost Gradient Synchronization Algorithm for DML Training"
neurips,2018,1,2078,Dan,Li,,Tsinghua University,,"BML: A High-performance, Low-cost Gradient Synchronization Algorithm for DML Training"
neurips,2018,2,2078,Yang,Cheng,,Tsinghua University,,"BML: A High-performance, Low-cost Gradient Synchronization Algorithm for DML Training"
neurips,2018,3,2078,Jinkun,Geng,,Tsinghua University,,"BML: A High-performance, Low-cost Gradient Synchronization Algorithm for DML Training"
neurips,2018,4,2078,Yanshu,Wang,,Tsinghua Univeristy,,"BML: A High-performance, Low-cost Gradient Synchronization Algorithm for DML Training"
neurips,2018,5,2078,Shuai,Wang,,Tsinghua University,,"BML: A High-performance, Low-cost Gradient Synchronization Algorithm for DML Training"
neurips,2018,6,2078,Shu-Tao,Xia,,Tsinghua University,,"BML: A High-performance, Low-cost Gradient Synchronization Algorithm for DML Training"
neurips,2018,7,2078,Jianping,Wu,,Tsinghua University,,"BML: A High-performance, Low-cost Gradient Synchronization Algorithm for DML Training"
neurips,2018,0,3265,Shenyi,Zhao,nju,Nanjing University,zhaosy@lamda.nju.edu.cn,Proximal SCOPE for Distributed Sparse Learning
neurips,2018,1,3265,Gong-Duo,Zhang,nju,Nanjing University,zhanggd@lamda.nju.edu.cn,Proximal SCOPE for Distributed Sparse Learning
neurips,2018,2,3265,Ming-Wei,Li,nju,Nanjing University,limw@lamda.nju.edu.cn,Proximal SCOPE for Distributed Sparse Learning
neurips,2018,3,3265,Wu-Jun,Li,nju,Nanjing University,liwujun@nju.edu.cn,Proximal SCOPE for Distributed Sparse Learning
neurips,2018,0,1826,Maciej,Zieba,pwr,"Wroclaw University of Science and Technology, Tooploox",maciej.zieba@pwr.edu.pl,BinGAN: Learning Compact Binary Descriptors with a Regularized GAN
neurips,2018,1,1826,Piotr,Semberecki,pwr,"Wrocaw University of Science and Technology, Tooploox",piotr.semberecki@pwr.edu.pl,BinGAN: Learning Compact Binary Descriptors with a Regularized GAN
neurips,2018,2,1826,Tarek,El-Gaaly,voyage,Voyage,tarek@voyage.auto,BinGAN: Learning Compact Binary Descriptors with a Regularized GAN
neurips,2018,3,1826,Tomasz,Trzcinski,pw,Tooploox / Warsaw University of Technology,t.trzcinski@ii.pw.edu.pl,BinGAN: Learning Compact Binary Descriptors with a Regularized GAN
neurips,2018,0,3340,Shailee,Jain,utexas,The University of Texas at Austin,shailee@cs.utexas.edu,Incorporating Context into Language Encoding Models for fMRI
neurips,2018,1,3340,Alexander,Huth,utexas,The University of Texas at Austin,huth@cs.utexas.edu,Incorporating Context into Language Encoding Models for fMRI
neurips,2018,0,1817,Bayan,Saparbayeva,nd,University Notre Dame,bsaparba@nd.edu,Communication Efficient Parallel Algorithms for Optimization on Manifolds
neurips,2018,1,1817,Michael,Zhang,princeton,Princeton University,mz8@cs.princeton.edu,Communication Efficient Parallel Algorithms for Optimization on Manifolds
neurips,2018,2,1817,Lizhen,Lin,nd,The University of Notre Dame,lizhen.lin@nd.edu,Communication Efficient Parallel Algorithms for Optimization on Manifolds
neurips,2018,0,6474,Chen,Liang,gmail,Google Brain,crazydonkey200@gmail.com,Memory Augmented Policy Optimization for Program Synthesis and Semantic Parsing
neurips,2018,1,6474,Mohammad,Norouzi,google,Google Brain,mnorouzi@google.com,Memory Augmented Policy Optimization for Program Synthesis and Semantic Parsing
neurips,2018,2,6474,Jonathan,Berant,tau,Tel Aviv University,joberant@cs.tau.ac.il,Memory Augmented Policy Optimization for Program Synthesis and Semantic Parsing
neurips,2018,3,6474,Quoc,Le,google,Google,qvl@google.com,Memory Augmented Policy Optimization for Program Synthesis and Semantic Parsing
neurips,2018,4,6474,Ni,Lao,mosaix,Mosaix.ai,ni.lao@mosaix.ai,Memory Augmented Policy Optimization for Program Synthesis and Semantic Parsing
neurips,2018,0,2309,Raksha,Kumaraswamy,ualberta,University of Alberta,kumarasw@ualberta.ca,Context-dependent upper-confidence bounds for directed exploration
neurips,2018,1,2309,Matthew,Schlegel,ualberta,University of Alberta,mkschleg@ualberta.ca,Context-dependent upper-confidence bounds for directed exploration
neurips,2018,2,2309,Adam,White,google,University of Alberta; DeepMind,adamwhite@google.com,Context-dependent upper-confidence bounds for directed exploration
neurips,2018,3,2309,Martha,White,ualberta,University of Alberta,whitem@ualberta.ca,Context-dependent upper-confidence bounds for directed exploration
neurips,2018,0,2344,Mingrui,Liu,,The University of Iowa,,Adaptive Negative Curvature Descent with Applications in Non-convex Optimization
neurips,2018,1,2344,Zhe,Li,,Apple,,Adaptive Negative Curvature Descent with Applications in Non-convex Optimization
neurips,2018,2,2344,Xiaoyu,Wang,,NEC Labs America,,Adaptive Negative Curvature Descent with Applications in Non-convex Optimization
neurips,2018,3,2344,Jinfeng,Yi,,JD AI Research,,Adaptive Negative Curvature Descent with Applications in Non-convex Optimization
neurips,2018,4,2344,Tianbao,Yang,,The University of Iowa,,Adaptive Negative Curvature Descent with Applications in Non-convex Optimization
neurips,2018,0,3068,Yuki,Ono,sony,SONY,yuki.ono@sony.com,LF-Net: Learning Local Features from Images
neurips,2018,1,3068,Eduard,Trulls,epfl,EPFL,eduard.trulls@epfl.ch,LF-Net: Learning Local Features from Images
neurips,2018,2,3068,Pascal,Fua,epfl,"EPFL, Switzerland",pascal.fua@epfl.ch,LF-Net: Learning Local Features from Images
neurips,2018,3,3068,Kwang Moo,Yi,uvic,University of Victoria,kyi@uvic.ca,LF-Net: Learning Local Features from Images
neurips,2018,0,2482,Dalin,Guo,ucsd,UC San Diego,dag082@ucsd.edu,Why so gloomy? A Bayesian explanation of human pessimism bias in the multi-armed bandit task
neurips,2018,1,2482,Angela,Yu,ucsd,UC San Diego,ajyu@ucsd.edu,Why so gloomy? A Bayesian explanation of human pessimism bias in the multi-armed bandit task
neurips,2018,0,2815,Liheng,Zhang,,University of Central Florida,,CapProNet: Deep Feature Learning via Orthogonal Projections onto Capsule Subspaces
neurips,2018,1,2815,Marzieh,Edraki,,University of Central Florida,,CapProNet: Deep Feature Learning via Orthogonal Projections onto Capsule Subspaces
neurips,2018,2,2815,Guo-Jun,Qi,,"Futurewei Technologies, Inc.",,CapProNet: Deep Feature Learning via Orthogonal Projections onto Capsule Subspaces
neurips,2018,0,6793,Roie,Levin,cmu,Carnegie Mellon University,roiel@cs.cmu.edu,Robust Subspace Approximation in a Stream
neurips,2018,1,6793,Anish Prasad,Sevekari,cmu,Carnegie Mellon University,asevekar@andrew.cmu.edu,Robust Subspace Approximation in a Stream
neurips,2018,2,6793,David,Woodruff,cmu,Carnegie Mellon University,dwoodruf@cs.cmu.edu,Robust Subspace Approximation in a Stream
neurips,2018,0,450,Yangyan,Li,,Alibaba AI Labs,,PointCNN: Convolution On X-Transformed Points
neurips,2018,1,450,Rui,Bu,,Shandong University,,PointCNN: Convolution On X-Transformed Points
neurips,2018,2,450,Mingchao,Sun,,Shandong University,,PointCNN: Convolution On X-Transformed Points
neurips,2018,3,450,Wei,Wu,,Shandong University,,PointCNN: Convolution On X-Transformed Points
neurips,2018,4,450,Xinhan,Di,,Vivo Communication Technology Co.Ltd[Relative Work was done at Huawei Technology Co.Ltd],,PointCNN: Convolution On X-Transformed Points
neurips,2018,5,450,Baoquan,Chen,,Shandong University,,PointCNN: Convolution On X-Transformed Points
neurips,2018,0,5839,Jack,Umenberger,uu,Uppsala University,thomas.schon@it.uu.se,Learning convex bounds for linear quadratic control policy synthesis
neurips,2018,1,5839,Thomas,Schön,uu,Uppsala University,jack.umenberger@it.uu.se,Learning convex bounds for linear quadratic control policy synthesis
neurips,2018,0,2690,Alessandro,Rudi,inria,"INRIA, Ecole Normale Superieure",alessandro.rudi@inria.fr,Manifold Structured Prediction
neurips,2018,1,2690,Carlo,Ciliberto,imperial,Imperial College London,c.ciliberto@imperial.ac.uk,Manifold Structured Prediction
neurips,2018,2,2690,GianMaria,Marconi,iit,Italian Institute of Technology,gian.maria.marconi@iit.it,Manifold Structured Prediction
neurips,2018,3,2690,Lorenzo,Rosasco,mit,University of Genova- MIT - IIT,lrosasco@mit.edu,Manifold Structured Prediction
neurips,2018,0,3415,Corinna,Cortes,,Google Research,,Efficient Gradient Computation for Structured Output Learning with Rational and Tropical Losses
neurips,2018,1,3415,Vitaly,Kuznetsov,,Google,,Efficient Gradient Computation for Structured Output Learning with Rational and Tropical Losses
neurips,2018,2,3415,Mehryar,Mohri,,Courant Inst. of Math. Sciences & Google Research,,Efficient Gradient Computation for Structured Output Learning with Rational and Tropical Losses
neurips,2018,3,3415,Dmitry,Storcheus,,Google Research,,Efficient Gradient Computation for Structured Output Learning with Rational and Tropical Losses
neurips,2018,4,3415,Scott,Yang,,D. E. Shaw & Co.,,Efficient Gradient Computation for Structured Output Learning with Rational and Tropical Losses
neurips,2018,0,2132,Tatsuro,Kawamoto,go,National Institute of Advanced Industrial Science and Technology,kawamoto.tatsuro@aist.go.jp,Mean-field theory of graph neural networks in graph partitioning
neurips,2018,1,2132,Masashi,Tsubaki,go,National Institute of Advanced Industrial Science and Technology (AIST),tsubaki.masashi@aist.go.jp,Mean-field theory of graph neural networks in graph partitioning
neurips,2018,2,2132,Tomoyuki,Obuchi,titech,Tokyo Institute of Technology,obuchi@c.titech.ac.jp,Mean-field theory of graph neural networks in graph partitioning
neurips,2018,0,2434,Ludwig,Schmidt,,MIT,,Adversarially Robust Generalization Requires More Data
neurips,2018,1,2434,Shibani,Santurkar,,MIT,,Adversarially Robust Generalization Requires More Data
neurips,2018,2,2434,Dimitris,Tsipras,,MIT,,Adversarially Robust Generalization Requires More Data
neurips,2018,3,2434,Kunal,Talwar,,Google,,Adversarially Robust Generalization Requires More Data
neurips,2018,4,2434,Aleksander,Madry,,MIT,,Adversarially Robust Generalization Requires More Data
neurips,2018,0,2500,Mehdi S. M.,Sajjadi,,Max Planck Institute for Intelligent Systems and ETH Center for Learning Systems,,Assessing Generative Models via Precision and Recall
neurips,2018,1,2500,Olivier,Bachem,,Google AI (Brain team),,Assessing Generative Models via Precision and Recall
neurips,2018,2,2500,Mario,Lucic,,Google Brain,,Assessing Generative Models via Precision and Recall
neurips,2018,3,2500,Olivier,Bousquet,,Google Brain (Zurich),,Assessing Generative Models via Precision and Recall
neurips,2018,4,2500,Sylvain,Gelly,,Google Brain (Zurich),,Assessing Generative Models via Precision and Recall
neurips,2018,0,6751,Alexander,Matyasko,ntu,Nanyang Technological University,aliaksan001@ntu.edu.sg,Improved Network Robustness with Adversary Critic
neurips,2018,1,6751,Lap-Pui,Chau,ntu,Nanyang Technological University,elpchau@ntu.edu.sg,Improved Network Robustness with Adversary Critic
neurips,2018,0,6750,Steven,Hansen,google,DeepMind,stevenhansen@google.com,Fast deep reinforcement learning using online adjustments from the past
neurips,2018,1,6750,Alexander,Pritzel,google,Deepmind,psprechmann@google.com,Fast deep reinforcement learning using online adjustments from the past
neurips,2018,2,6750,Pablo,Sprechmann,google,DeepMind,apritzel@google.com,Fast deep reinforcement learning using online adjustments from the past
neurips,2018,3,6750,Andre,Barreto,google,DeepMind,andrebarreto@google.com,Fast deep reinforcement learning using online adjustments from the past
neurips,2018,4,6750,Charles,Blundell,google,DeepMind,cblundell@google.com,Fast deep reinforcement learning using online adjustments from the past
neurips,2018,0,1141,Jiecao,Chen,indiana,Indiana University Bloomington,jiecchen@indiana.edu,A Practical Algorithm for Distributed Clustering and Outlier Detection
neurips,2018,1,1141,Erfan,Sadeqi Azer,indiana,Indiana University,esadeqia@indiana.edu,A Practical Algorithm for Distributed Clustering and Outlier Detection
neurips,2018,2,1141,Qin,Zhang,indiana,Indiana University Bloomington,qzhangcs@indiana.edu,A Practical Algorithm for Distributed Clustering and Outlier Detection
neurips,2018,0,2671,Richard,Zhang,mit,"University of California, Berkeley",ryz@alum.mit.edu,How Much Restricted Isometry is Needed In Nonconvex Matrix Recovery?
neurips,2018,1,2671,Cedric,Josz,gmail,UC Berkeley,cedric.josz@gmail.com,How Much Restricted Isometry is Needed In Nonconvex Matrix Recovery?
neurips,2018,2,2671,Somayeh,Sojoudi,berkeley,"University of California, Berkeley",sojoudi@berkeley.edu,How Much Restricted Isometry is Needed In Nonconvex Matrix Recovery?
neurips,2018,3,2671,Javad,Lavaei,berkeley,"University of California, Berkeley",lavaei@berkeley.edu,How Much Restricted Isometry is Needed In Nonconvex Matrix Recovery?
neurips,2018,0,2171,Song,Zhou,cornell,Cornell University,sz557@cornell.edu,Limited Memory Kelley's Method Converges for Composite Convex and Submodular Objectives
neurips,2018,1,2171,Swati,Gupta,gatech,Georgia Institute of Technology,swatig@gatech.edu,Limited Memory Kelley's Method Converges for Composite Convex and Submodular Objectives
neurips,2018,2,2171,Madeleine,Udell,cornell,Cornell University,udell@cornell.edu,Limited Memory Kelley's Method Converges for Composite Convex and Submodular Objectives
neurips,2018,0,1861,Tianyi,Liu,gatech,Georgia Institute of Technolodgy,tliu341@gatech.edu,Towards Understanding Acceleration Tradeoff between Momentum and Asynchrony in Nonconvex Stochastic Optimization
neurips,2018,1,1861,Shiyang,Li,gmail,"University of California, Santa Barbara",lsydevin@gmail.com,Towards Understanding Acceleration Tradeoff between Momentum and Asynchrony in Nonconvex Stochastic Optimization
neurips,2018,2,1861,Jianping,Shi,sensetime,Sensetime Group Limited,shijianping@sensetime.com,Towards Understanding Acceleration Tradeoff between Momentum and Asynchrony in Nonconvex Stochastic Optimization
neurips,2018,3,1861,Enlu,Zhou,gatech,Georgia Institute of Technology,enlu.zhou@isye.gatech.edu,Towards Understanding Acceleration Tradeoff between Momentum and Asynchrony in Nonconvex Stochastic Optimization
neurips,2018,4,1861,Tuo,Zhao,gatech,Georgia Tech,tuo.zhao@isye.gatech.edu,Towards Understanding Acceleration Tradeoff between Momentum and Asynchrony in Nonconvex Stochastic Optimization
neurips,2018,0,1495,Isao,Ishikawa,riken,RIKEN AIP,isao.ishikawa@riken.jp,Metric on Nonlinear Dynamical Systems with Perron-Frobenius Operators
neurips,2018,1,1495,Keisuke,Fujii,riken,RIKEN AIP Center,keisuke.fujii.zh@riken.jp,Metric on Nonlinear Dynamical Systems with Perron-Frobenius Operators
neurips,2018,2,1495,Masahiro,Ikeda,riken,RIKEN AIP,masahiro.ikeda@riken.jp,Metric on Nonlinear Dynamical Systems with Perron-Frobenius Operators
neurips,2018,3,1495,Yuka,Hashimoto,keio,NTT Network Technology Laboratories,yukahashimoto@keio.jp,Metric on Nonlinear Dynamical Systems with Perron-Frobenius Operators
neurips,2018,4,1495,Yoshinobu,Kawahara,osaka-u,Osaka University / RIKEN,ykawahara@sanken.osaka-u.ac.jp,Metric on Nonlinear Dynamical Systems with Perron-Frobenius Operators
neurips,2018,0,2286,Malik,Magdon-Ismail,rpi,Rensselaer,magdon@cs.rpi.edu,A Mathematical Model For Optimal Decisions In A Representative Democracy
neurips,2018,1,2286,Lirong,Xia,rpi,RPI,xial@cs.rpi.edu,A Mathematical Model For Optimal Decisions In A Representative Democracy
neurips,2018,0,2786,Sean,Welleck,nyu,NYU,wellecks@nyu.edu,Loss Functions for Multiset Prediction
neurips,2018,1,2786,Zixin,Yao,nyu,New York University,zixin.yao@nyu.edu,Loss Functions for Multiset Prediction
neurips,2018,2,2786,Yu,Gai,nyu,New York University,yg1246@nyu.edu,Loss Functions for Multiset Prediction
neurips,2018,3,2786,Jialin,Mao,nyu,New York University,jialin.mao@nyu.edu,Loss Functions for Multiset Prediction
neurips,2018,4,2786,Zheng,Zhang,nyu,Shanghai New York Univeristy,zz@nyu.edu,Loss Functions for Multiset Prediction
neurips,2018,5,2786,Kyunghyun,Cho,nyu,NYU,kyunghyun.cho@nyu.edu,Loss Functions for Multiset Prediction
neurips,2018,0,1069,Filip,Hanzely,,KAUST,,SEGA: Variance Reduction via Gradient Sketching
neurips,2018,1,1069,Konstantin,Mishchenko,,KAUST,,SEGA: Variance Reduction via Gradient Sketching
neurips,2018,2,1069,Peter,Richtarik,,KAUST,,SEGA: Variance Reduction via Gradient Sketching
neurips,2018,0,3043,Ilias,Diakonikolas,usc,University of Southern California,diakonik@usc.edu,Sharp Bounds for Generalized Uniformity Testing
neurips,2018,1,3043,Daniel M.,Kane,ucsd,UCSD,dakane@ucsd.edu,Sharp Bounds for Generalized Uniformity Testing
neurips,2018,2,3043,Alistair,Stewart,gmail,University of Southern California,stewart.al@gmail.com,Sharp Bounds for Generalized Uniformity Testing
neurips,2018,0,860,Ding,Liu,illinois,Bytedance AI Lab,dingliu2@illinois.edu,Non-Local Recurrent Network for Image Restoration
neurips,2018,1,860,Bihan,Wen,illinois,University of Illinois at Urbana-Champaign,bwen3@illinois.edu,Non-Local Recurrent Network for Image Restoration
neurips,2018,2,860,Yuchen,Fan,illinois,"Image Formation and Processing (IFP) Group, University of Illinois at Urbana-Champaign",yuchenf4@illinois.edu,Non-Local Recurrent Network for Image Restoration
neurips,2018,3,860,Chen Change,Loy,illinois,Nanyang Technological University,t-huang1@illinois.edu,Non-Local Recurrent Network for Image Restoration
neurips,2018,4,860,Thomas,Huang,ntu,UIUC,ccloy@ntu.edu.sg,Non-Local Recurrent Network for Image Restoration
neurips,2018,0,2439,Gabriele,Farina,,Carnegie Mellon University,,Practical exact algorithm for trembling-hand equilibrium refinements in games
neurips,2018,1,2439,Nicola,Gatti,,Politecnico di Milano,,Practical exact algorithm for trembling-hand equilibrium refinements in games
neurips,2018,2,2439,Tuomas,Sandholm,,Carnegie Mellon University,,Practical exact algorithm for trembling-hand equilibrium refinements in games
neurips,2018,0,6787,Rui,Luo,,University College London,,Thermostat-assisted continuously-tempered Hamiltonian Monte Carlo for Bayesian learning
neurips,2018,1,6787,Jianhong,Wang,,UCL,,Thermostat-assisted continuously-tempered Hamiltonian Monte Carlo for Bayesian learning
neurips,2018,2,6787,Yaodong,Yang,,University College London,,Thermostat-assisted continuously-tempered Hamiltonian Monte Carlo for Bayesian learning
neurips,2018,3,6787,Jun,WANG,,UCL,,Thermostat-assisted continuously-tempered Hamiltonian Monte Carlo for Bayesian learning
neurips,2018,4,6787,Zhanxing,Zhu,,Peking University,,Thermostat-assisted continuously-tempered Hamiltonian Monte Carlo for Bayesian learning
neurips,2018,0,5296,Damian,Mrowca,,Stanford University,,Flexible neural representation for physics prediction
neurips,2018,1,5296,Chengxu,Zhuang,,Stanford University,,Flexible neural representation for physics prediction
neurips,2018,2,5296,Elias,Wang,,Stanford University,,Flexible neural representation for physics prediction
neurips,2018,3,5296,Nick,Haber,,Stanford University,,Flexible neural representation for physics prediction
neurips,2018,4,5296,Li,Fei-Fei,,Stanford University & Google,,Flexible neural representation for physics prediction
neurips,2018,5,5296,Josh,Tenenbaum,,MIT,,Flexible neural representation for physics prediction
neurips,2018,6,5296,Daniel,Yamins,,Stanford University,,Flexible neural representation for physics prediction
neurips,2018,0,5504,Gianluca,Detommaso,bath,University of Bath / The Alan Turing Institute,gd391@bath.ac.uk,A Stein variational Newton method
neurips,2018,1,5504,Tiangang,Cui,monash,Monash University,Tiangang.Cui@monash.edu,A Stein variational Newton method
neurips,2018,2,5504,Youssef,Marzouk,mit,Massachusetts Institute of Technology,spantini@mit.edu,A Stein variational Newton method
neurips,2018,3,5504,Alessio,Spantini,mit,MIT,ymarz@mit.edu,A Stein variational Newton method
neurips,2018,4,5504,Robert,Scheichl,uni-heidelberg,Heidelberg University,r.scheichl@uni-heidelberg.de,A Stein variational Newton method
neurips,2018,0,2847,Zunlei,Feng,zju,Zhejiang University,zunleifeng@zju.edu.cn,Dual Swap Disentangling
neurips,2018,1,2847,Xinchao,Wang,stevens,Stevens Institute of Technology,xinchao.wang@stevens.edu,Dual Swap Disentangling
neurips,2018,2,2847,Chenglong,Ke,zju,Zhejiang University,chenglongke@zju.edu.cn,Dual Swap Disentangling
neurips,2018,3,2847,An-Xiang,Zeng,taobao,Alibaba,renzhong@taobao.com,Dual Swap Disentangling
neurips,2018,4,2847,Dacheng,Tao,sydney,University of Sydney,dctao@sydney.edu.au,Dual Swap Disentangling
neurips,2018,5,2847,Mingli,Song,zju,Zhejiang University,brooksong@zju.edu.cn,Dual Swap Disentangling
neurips,2018,0,255,Simon,Du,,Carnegie Mellon University,,Algorithmic Regularization in Learning Deep Homogeneous Models: Layers are Automatically Balanced
neurips,2018,1,255,Wei,Hu,,Princeton University,,Algorithmic Regularization in Learning Deep Homogeneous Models: Layers are Automatically Balanced
neurips,2018,2,255,Jason,Lee,,University of Southern California,,Algorithmic Regularization in Learning Deep Homogeneous Models: Layers are Automatically Balanced
neurips,2018,0,2206,Yaodong,Yu,virginia,University of Virginia,yy8ms@virginia.edu,Third-order Smoothness Helps: Faster Stochastic Optimization Algorithms for Finding Local Minima
neurips,2018,1,2206,Pan,Xu,ucla,UCLA,panxu@cs.ucla.edu,Third-order Smoothness Helps: Faster Stochastic Optimization Algorithms for Finding Local Minima
neurips,2018,2,2206,Quanquan,Gu,ucla,UCLA,qgu@cs.ucla.edu,Third-order Smoothness Helps: Faster Stochastic Optimization Algorithms for Finding Local Minima
neurips,2018,0,5452,Abhinav,Gupta,,Facebook AI Research/CMU,,Robot Learning in Homes: Improving Generalization and Reducing Dataset Bias
neurips,2018,1,5452,Adithyavairavan,Murali,,Carnegie Mellon University Robotics Institute,,Robot Learning in Homes: Improving Generalization and Reducing Dataset Bias
neurips,2018,2,5452,Dhiraj Prakashchand,Gandhi,,Carnegie Mellon University Robotics Institute,,Robot Learning in Homes: Improving Generalization and Reducing Dataset Bias
neurips,2018,3,5452,Lerrel,Pinto,,Carnegie Mellon University,,Robot Learning in Homes: Improving Generalization and Reducing Dataset Bias
neurips,2018,0,2440,Tianyi,Chen,umn,University of Minnesota,chen3827@umn.edu,LAG: Lazily Aggregated Gradient for Communication-Efficient Distributed Learning
neurips,2018,1,2440,Georgios,Giannakis,umn,University of Minnesota,georgios@umn.edu,LAG: Lazily Aggregated Gradient for Communication-Efficient Distributed Learning
neurips,2018,2,2440,Tao,Sun,163,National university of defense technology,nudtsuntao@163.com,LAG: Lazily Aggregated Gradient for Communication-Efficient Distributed Learning
neurips,2018,3,2440,Wotao,Yin,ucla,"University of California, Los Angeles",wotaoyin@math.ucla.edu,LAG: Lazily Aggregated Gradient for Communication-Efficient Distributed Learning
neurips,2018,0,1851,Junzhe,Zhang,,Purdue University,,Equality of Opportunity in Classification: A Causal Approach
neurips,2018,1,1851,Elias,Bareinboim,,Purdue,,Equality of Opportunity in Classification: A Causal Approach
neurips,2018,0,1827,Matthew,Olson,upenn,The Voleon Group,ajw@wharton.upenn.edu,Modern Neural Networks Generalize on Small Data Sets
neurips,2018,1,1827,Abraham,Wyner,upenn,University of Pennsylvania,maolson@wharton.upenn.edu,Modern Neural Networks Generalize on Small Data Sets
neurips,2018,2,1827,Richard,Berk,upenn,,berkr@wharton.upenn.edu,Modern Neural Networks Generalize on Small Data Sets
